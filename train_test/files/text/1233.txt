Results from the Active for Life process evaluation:
program delivery fidelity and adaptations
Sarah F. Griffin1*, Sara Wilcox2, Marcia G. Ory3, Diana Lattimore4,
Laura Leviton5, Cynthia Castro6, Ruth Ann Carpenter7 and Carol Rheaume2
Abstract
Active for LifeÒ (AFL) was a large (n 5 8159)
translational initiative to increase physical ac-
tivity (PA) in midlife and older adults. Trans-
lational research calls for a shift in emphasis
from just understanding what works (efficacy)
to also understanding how it works in more `real
world' settings. This article describes the pro-
cess evaluation design and findings, discuss how
these findings were used to better understand
the translational process and provide a set of
process evaluation recommendations with com-
munity-based translational research. AFL com-
munity organizations across the United States
implemented one of two evidence-based PA
programs (Active Living Every Day--The Coo-
per Institute; Human Kinetics Inc. or Active
Choices--Stanford University). Both programs
were based on the transtheoretical model and
social cognitive theory. Overall, the process
evaluation revealed high-dose delivery and
implementation fidelity by quite varied commu-
nity organizations serving diverse adult popula-
tions. Findings reveal most variation occurred
for program elements requiring more partici-
pant engagement. Additionally, the results show
how a collaborative process allowed the organ-
izations to `fit' the programs to their specific
participant base while maintaining fidelity to
essential program elements.
Introduction
Physical activity (PA) plays a key role in promoting
health and quality of life as adults age [1­3]. Un-
fortunately, adults over the age of 50 are the least
physically active segment of the adult population
[4, 5]. Recent studies show that PA in older adults
can be increased through behavior change programs
[6, 7]. Individually adapted behavior change pro-
grams are strongly recommended as an approach to
increase PA [8]. However, little is known about
how these programs are implemented when taken
out of the controlled research environment and dis-
seminated for wider use in communities [9­11].
Translational research aids in understanding how
programs are adapted, if they are effective outside
of research settings, and what factors moderate their
effectiveness when implemented in less controlled
(real world) settings [12, 13].
Process evaluation is used to identify program-
matic and contextual moderators of effectiveness
and determine if a program was delivered as
designed [14]. It also aids in understanding of
how programs were developed and why programs
were (or were not) successfully implemented [15­
25]. The purpose of this manuscript is to describe
1Department of Public Health Sciences, Clemson University,
507 Edwards Hall, Clemson, SC 29634, USA, 2Department
of Exercise Science, University of South Carolina, Columbia,
SC, USA, 3School of Rural Public Health, Texas A & M
University, College Station, TX, USA, 4Department of
Exercise and Sports Science, University of San Francisco,
San Francisco, CA, USA, 5Research and Evaluation, Robert
Wood Johnson Foundation, Princeton, NJ, USA, 6Prevention
Research Center, Stanford University School of Medicine,
Stanford, CA, USA and 7Health Integrations, Dallas, TX,
USA
*Correspondence to: S. A. Griffin. E-mail:
sgriffi@clemson.edu
Ó The Author 2009. Published by Oxford University Press. All rights reserved.
For permissions, please email: journals.permissions@oxfordjournals.org
doi:10.1093/her/cyp017
HEALTH EDUCATION RESEARCH Vol.25 no.2 2010
Pages 325­342
Advance Access publication 26 March 2009
the process evaluation for Active for LifeÒ (AFL),
a large translational initiative aimed at increasing
PA in midlife and older adults, illustrate how it
captured program delivery and fidelity (defined as
the extent to which the intervention was delivered
as planned [16]) and present the major process eval-
uation findings and discuss how the findings from
AFL were used to better understand the transla-
tional process.
Description of AFL
AFL examined the translation of two programs
shown efficacious in increasing PA in controlled
research settings to non-research settings. Active
Living Every Day (ALED; The Cooper Institute
and Human Kinetics, Inc.) is delivered through 20
weekly classes [26, 27]. In response to interest by
the sites, a 12-week adaptation of ALED was tested
in AFLs the fourth year. Active Choices [AC; Stan-
ford University] provides one-on-one counseling
delivered through a face-to-face meeting followed
by eight telephone counseling calls over a 6-month
period [28­31]. More detailed descriptions of ses-
sion topics and activities for the programs are found
in Tables I and II. Both programs incorporate
behavior change strategies consistent with the
transtheoretical model [32] and social cognitive the-
ory [33]. According to the transtheoretical model,
people make changes gradually and in stages, and
the person's readiness for behavioral change should
be used to guide the types of intervention strategies
delivered. Social cognitive theory emphasizes the
reciprocal interactions between the person, environ-
ment and behavior. Key intervention components
from this theory include increasing self-efficacy and
enhancing self-regulatory skills (goal setting, self-
monitoring, problem solving and self-reward).
Organizations responded to a competitive re-
quest for proposals and indicated their preferences
for AC or ALED. Of the nine funded lead organ-
izations (listed in `Acknowledgements' section),
four selected AC and implemented it at five distinct
sites and five selected ALED and implemented it at
seven distinct sites from 2003 through 2007. AC
Table I. ALED session topics
Session topics and activities
Week 1: Getting started--thinking about successful habit changes; determining medical readiness
Week 2: Ready, set, go--identifying stage of readiness; conducting personal time study
Week 3: Making plans--2-min walk assessment; changing sedentary and light activity into moderate intensity
Week 4: Barriers and benefits--understanding barriers and benefits to an active life
Week 5: Over, under, around and through--problem-solving barriers; restaging
Week 6: Let us burn some calories--learning about different PA intensities; self-monitoring
Week 7: Setting goals
Week 8: Enlisting support--identify needed sources of support; learning to ask for help
Week 9: Gaining Confidence--cognitive restructuring; restaging
Week 10: Strengthening the foundation--reviewing earlier activities; stretching techniques
Week 11: Rewarding yourself--identifying rewards and incentives
Week 12: Avoiding pitfalls--relapse prevention training
Week 13: Defusing stress--stress management techniques; restaging
Week 14: Step by step--goal setting and self-monitoring using a step counter
Week 15: Managing your time--time management techniques
Week 16: Exploring new activities--identifying and trying PA options in the community and selecting in-home equipment
Week 17: Making lasting changes--celebrating accomplishments; trying new activities; restaging
Week 18: Becoming a hunter-gatherer--adding more activity into weekly schedule, including vigorous activity
Week 19: Positive planning--positive thinking; planning for high-risk situations
Week 20: Onward and upward--identifying personal success strategies
For the 12-week program, topics were combined and session length increased.
S. F. Griffin et al.
326
health educators at lead organizations were trained
and approved by program developers. These staff
became train-the-trainers and trained and approved
their own staff. ALED group facilitators were both
employees of lead organizations and, at some sites,
community members. They were trained via online
modules and a face-to-face or webcast workshop
and certified by Human Kinetics. At several ALED
sites, former participants became paid or volunteer
facilitators. The backgrounds of staff members var-
ied widely, and many had no prior experience with
PA programming. Program developers provided
programmatic technical assistance as needed. The
AFL National Program Office also provided tech-
nical assistance for program marketing, recruit-
ment, budget management and sustainability
planning. The lead organizations tailored recruit-
ment strategies to the communities it targeted.
The most common strategies were presentations,
direct mailing, brochures/flyers, advertisements
and media stories. Over the 4 years, organizations
relied on a similar set of recruitment strategies but
became more focused and targeted. A more detailed
description of AFL, the PA programs, the sites and
site-specific recruitment strategies are provided
elsewhere [34, 35] and at www.activeforlife.info.
Description of process evaluation
The process evaluation development (see Table III)
followed a multistep process [16]. Through this
process, program essential elements were identified
and descriptions of complete and acceptable deliv-
ery were developed for each program element (see
Table IV) [36, 37]. This manuscript focuses on the
dose and fidelity (full and complete implementa-
tion) data from an electronic reporting system. Fu-
ture manuscripts will provide a more in-depth
report of qualitative findings from site staff inter-
views to assess staff experiences implementing the
program and post-program survey questions to
assess participants' perceptions of the program.
Methods
Data collection
Program staff completed data entry worksheets
corresponding to essential elements (Table IV)
Table II. AC session topics and activities
Face-to-face session topics and activities
Establish rapport
Discuss program expectations and sign expectations agreement
Formulate goal plan for increasing PA
Set short- and long-term goals
Assess PA history and assess interests, benefits and barriers to PA
Provide PA safety and stretching tips
Provide pedometer and discuss self-monitoring of steps
Provide PA log/calendar and discuss self-monitoring of minutes of PA and intensity level
Provide and review local PA resource guide
Establish telephone call schedule
Phone call discussion topics and activities
Assess current health since last session
Assess current PA level (days per week/minutes per day/intensity); amount of strength building and stretching activity
Assess current types of PA
Assess recent step counts
Compare prior goals with current PA pattern
Discussion of any of the following counseling topics based on stage of readiness (as determined by amount of current PA and
intention to do more): goal setting, self-monitoring, pros/cons of PA, self-efficacy, benefits of PA, injury prevention, barriers to PA,
making PA enjoyable, previous PA experience, social support, rewards and reinforcements and relapse prevention
Establish new cognitive or behavioral goals or skills to try
Send follow-up material based on phone conversation topics
Process evaluation of physical activity program
327
after each encounter with participants and entered
these data into the electronic reporting system.
Program staff participated in multiple trainings
and discussions (via phone calls and annual in-
person meetings) regarding completing data
entry worksheets and data entry. Data were peri-
odically reviewed by the AFL evaluation team
for completeness and to identify outliers or
unlikely values, findings were discussed with
program staff, and corrections were made as
appropriate.
Data analysis
Descriptive statistics (means and frequencies) sum-
marized key process variables for each year sepa-
rately and across years combined. Some ALED
analyses were reported at the group or session level
(e.g. group size, check-ins, incentives). For ALED
variables involving participant-level engagement
(e.g. attendance), individual-weighted analyses were
conducted. Although we examined differences by
session for both types of analyses, results by session
were only reported if there were differences. Quali-
tative ALED data regarding session modifications
were clustered by site and type of modification.
For AC, all analyses were conducted at the par-
ticipant level. For analyses involving the face-to-
face sessions and analyses reporting number of calls
delivered, the sample size reflects the number of
participants. For all other AC analyses, the sample
size reflects the total number of calls delivered.
For both programs, site-specific dose and fidelity
results were compared (descriptive plots) to site-
specific PA effect sizes [35].
Results
Participants
Over the 4 years of ALED, 4689 individuals par-
ticipated (503, 1071, 1553 and 1562, respectively).
On average, ALED participants were 70.7 6 9.7
years of age and 83% were women. Whites com-
prised 61% of the sample, followed by African-
Americans (33%), Hispanics/Latinos (2%) and
other racial/ethnic groups (2%). Program and site-
specific demographics are provided in Table V.
Participants reported significant changes in PA
from pre-test to post-test [35]. For ALED, the effect
size for Moderate to Vigorous Physical Activity
(MVPA) [abc2] was d = 0.65 (site range: 0.41­
0.97) when all available data were used. When
baseline values were carried forward in cases of
missing post-test data, the effect size reduced to
d = 0.47 (site range: 0.28­0.70). For AC, the cor-
responding effect sizes were d = 0.68 for all avail-
able data (site range: 0.48­0.85) and d = 0.41 for
carry forward analyses (site range: 0.31­0.49) [35].
Active Living Every Day
Dose/attendance/participation
The ALED sites served 4689 participants in 328
groups. Attendance patterns (representing program
Table III. Multistep process evaluation
Step 1 d Work with program developers to obtain logic models
d Develop initial list of essential elements
Step 2 d Formative interviews with program developers to further define and describe complete and acceptable delivery of essential
elements for each program in terms of dose and fidelity
Step 3 Develop data collection methods for capturing
d Program implementation--dose and fidelity (captured through electronic reporting system)
d Site staff experiences with implementing the program--perceptions of challenges, successes and adaptations (captured
through quarterly site staff interviews)
d Participant impressions--perceptions about most/least helpful and most/least liked elements of program (captured through
post-program survey questions)
Step 4 d Program developers and site lead staff review data collection tools and provide feedback
d Edit data collection tools based on feedback
Step 5 d Data collection
d Revise data collection instruments as needed based on feedback from program staff and program developers
Step 6 d Review findings with program developers and site lead staff
S. F. Griffin et al.
328
Table IV. Description of the ALED and AC essential elements and how they were measured in the AFL evaluation
Process
evaluation
level
ALED AC
Essential
element
Measures of
essential element
Essential element Measures of essential element
Dose Attendance at
each session
Percent of participants
who attended each
group session
Face-to-face session
delivered
Percentage of participants who
received a face-to-face session
and the format of the session
(i.e. individual, small group,
other). Note: the face-to-face
session was required for all
participants
Face-to-face session
duration
Average length of face-to-face
session. Note: recommended
duration is 45­60 min for
individual sessions; 60­90 min
for small group sessions.
Calls delivered Percentage of calls completed
for each participant. Note:
completion of eight calls is
recommended
Call duration Average length of each phone
call; Average length of all calls
combined. Note: if all eight
calls are delivered and each is
the recommended 10­15 min,
total duration would be 80­120
min
Fidelity Completion of
10 steps in
face-to-face
session
Percentage of face-to-face
sessions in which staff covered
each of the 10 steps. Notes: all
steps are recommended for
every face-to-face session
Group size Range and average size
of each group. Note:
recommended size is
6­24 participants
per group
Deliver all 20
sessions
Percentage of sessions
delivered as intended as
opposed to combined
with other sessions.
Note: recommended
that each session be
delivered independently
and in order
Completion of
check-in
activity
Percentage of sessions that
included a check-in
activity. Note:
recommended for all
sessions
Process evaluation of physical activity program
329
Table IV. Continued
Process
evaluation
level
ALED AC
Essential
element
Measures of
essential element
Essential element Measures of essential element
Incentives
provided
Percentage of sessions that
included an incentive.
Note: recommended for
some but not all
sessions
Stage of
readiness
for change
Number of sessions
where participants
were assessed for
stage of readiness
for change as
scheduled. Note:
recommended in five
sessions (20-week
program) or three
sessions (12-week
program)
Stage of readiness
for change
Percentage of calls where
participants were assessed for
stage of readiness for change.
Note: recommended for each
call
Learning
activity
implementation
Number of recommended
learning activities
implemented in each
session. Note: each
session has a
recommended number
of learning activities
Goal setting activity
completed on call
Percentage of calls where
participants were assessed for
PA goals and assistance was
given to revise if necessary.
Note: recommended for each
call
Assessed for injury Percentage of
calls where
participants were
assessed for injury
since last call. Note:
recommended for
each call
Modifications
made to
session
Percentage of sessions
with modifications to
learning activities.
Note: recommended
use of only approved
modifications unless the
modification was
very minor
Home
assignments
given
Number of recommended
home assignments
given in each session.
Note: each session has
a recommended number
of home assignments
S. F. Griffin et al.
330
dose) were consistent across years. As shown in
Fig. 1, attendance declined initially and then pla-
teaued through the end of the program, with an
average attendance rate across years and session
of 65%. As shown in Fig. 2, participant attendance
only varied by 10% across the sites and no discern-
able pattern between PA effect size and attendance
is evident, possibly because of the lack of atten-
dance variation.
Fidelity to program model
Table VI reports the extent to which facilitators
adhered to ALED essential elements. An overall
high level of implementation fidelity was observed.
With respect to group size, the range was 4­33
participants per group. On average, groups con-
tained 15 participants (program developers' recom-
mendation: 6­24). Group size was fairly consistent
across sites.
One area that showed some departure was combi-
nation of sessions. Across years, 6% of sessions were
combined, although very few sessions (<1%) were
combined in Year 4 (12-week program) and there
was variability across organizations. Qualitative data
from the electronic reporting system showed that al-
though some session combinations were planned and
approved by program developers, many sessions
were combined because of inclement weather,
Table IV. Continued
Process
evaluation
level
ALED AC
Essential
element
Measures of
essential element
Essential element Measures of essential element
Home
assignments
completed
Percentage of participants
who completed home
assignments in each of t
he 20 sessions
Participant assessed
for activity level
Percentage of calls where
participants were assessed for
light or moderate/vigorous PA
in previous week. Note:
recommended for each call
Self-monitoring Percentage of participants
who tracked thoughts,
type of PA, days and
minutes of PA and
steps. Note: tracking
thoughts and type of PA
introduced in Session 6;
tracking days and minutes
of PA and steps
introduced in Session 14.
Participants could choose
preferred tracking method.
Participant assessed
for self-monitoring
Percentage of calls where
participants were assessed for
using pedometer and activity
log to track steps and minutes
of PA. Note: recommended for
each call
Topics discussed on
call
Percentage of topics discussed
according to participant's stage
of readiness for change. Note:
although health educators were
free to select topics that were
deemed most appropriate,
stage-specific
recommendations were
also made
Process evaluation of physical activity program
331
Table V. Site-specific participant demographics*
AC sites ALED sites
Site 1 Site 2 Site 3 Site 4 Site 5 Site 6 Site 7 Site 8 Site 9 Site 10 Site 11 Site 12
BS,
n = 804
SMB,
n = 216
SMSM,
n = 601
YMCA,
n = 922
CHC,
n = 926
JCA,
n = 1047
GDAHC,
n = 830
OASIS MO,
n = 382
OASIS PA,
n = 310
OASIS TX,
n = 337
FH,
n = 855
SWOHIO,
n = 927
Age, years (SD) 72.2
(7.3)
70.3
(10.2)
68.2
(10.4)
62.9
(31.6)
62.7
(9.3)
70.6
(9.5)
69.7
(10.8)
73.0
(10.3)
72.1
(8.0)
68.9
(8.9)
70.3
(9.7)
71.4
(9.2)
Race
White 67.5 54.4 38.1 48.3 14.0 75.3 3.7 43.7 76.4 64.7 78.4 82.3
Black 5.4 30.2 10.8 43.0 83.7 17.5 92.3 54.2 21.9 6.5 18.7 16.0
Hispanic 18.8 3.7 23.4 6.3 1.1 2.3 1.9 0.8 0.6 25.8 0.2 0.8
Other 8.3 11.6 27.7 2.5 1.2 4.9 2.5 1.3 1.0 3.0 2.7 1.0
Gender
Women 72.8 83.0 83.2 76.7 88.1 80.5 79.8 91.6 87.4 88.4 79.7 85.8
Men 27.2 17.1 16.8 23.3 11.9 19.5 20.2 8.4 12.6 11.6 20.3 14.2
Educationa
Less than high
school
13.5 4.3 26.4 4.4 17.8 2.3 23.5 27.0 8.3 6.6 14.2 11.5
High school
or GED
26.0 10.1 15.2 16.8 29.4 13.0 36.1 25.9 37.3 22.2 30.0 32.6
Some college
or college graduate
60.5 85.6 58.4 78.8 52.7 84.7 40.4 47.2 54.4 71.1 55.8 56.0
Marital statusa
Not married/partnered 53.5 75.5 47.3 59.1 66.1 52.2 76.9 67.1 66.2 50.9 41.0 57.4
Married/partnered 46.5 24.5 52.7 40.9 33.9 47.9 23.1 32.9 33.8 49.1 59.0 42.6
BMIa, kg/m2 (SD) 28.3
(6.1)
29.5
(7.2)
28.8
(6.9)
31.6
(7.6)
33.7
(7.6)
29.0
(6.6)
30.4
(6.6)
30.0
(7.1)
29.4
(6.3)
30.7
(6.5)
28.1
(6.1)
31.0
(7.3)
Weight statusa
Normal (BMI < 25) 31.4 27.0 34.4 16.5 11.5 29.4 19.0 26.7 22.7 19.2 32.0 19.6
Overweight
(25 < BMI < 30)
35.8 30.7 28.5 31.8 22.4 34.7 33.6 30.1 36.2 30.1 38.2 30.3
Obese (BMI > 30) 33.2 42.3 37.1 51.7 66.1 35.9 47.4 43.2 41.1 50.7 29.8 50.2
Health ratinga
Excellent or
very good
28.8 26.1 25.9 31.8 17.2 42.3 11.0 19.9 22.6 27.2 34.4 25.6
Good 47.6 46.4 45.6 47.0 53.6 48.1 57.6 46.3 55.8 50.2 43.7 57.3
Fair or poor 23.6 27.5 28.6 21.2 29.2 9.6 31.4 33.7 21.6 22.6 21.9 17.1
S. F. Griffin et al.
332
holidays and logistic barriers at the site. In these
instances, sites often conducted a longer session
(usually 90 min) to cover content from both sessions.
At the sites where 11% and 13% of sessions were
combined, the majority of combinations was planned
and combined because of less dense content in ses-
sions and at one site, the last week of the program
was used to conduct fitness assessments thereby ne-
cessitating a collapsing of several sessions.
Incentives (e.g. umbrellas, T-shirts, water bot-
tles) were given in half (52%) of the sessions. This
practice was consistent with the program developers'
recommendations to provide incentives in some but
not all sessions. Use of incentives, however, was
variable across sites. The ALED program sites also
had high fidelity for assessing participants for stage
of readiness for change. The ALED curriculum
calls for participants to be staged in 5 of the 20
sessions (20-week program) or 3 of the 12 sessions
(12-week program). On average, groups were
staged 4.6 times in Years 1­3 and 2.9 times in Year 4.
The ALED curriculum includes specific learning
activities for each group session. Activities per ses-
sion ranged from 1 to 8 and were higher for the 12-
week program. On average, 3.8 activities were
expected per session and 3.4 activities were com-
pleted. Sites reported making modifications to the
learning activities in 16% of the sessions. Modifi-
cations were made to session materials or activities.
Table V. Continued
AC sites ALED sites
Site 1 Site 2 Site 3 Site 4 Site 5 Site 6 Site 7 Site 8 Site 9 Site 10 Site 11 Site 12
BS,
n = 804
SMB,
n = 216
SMSM,
n = 601
YMCA,
n = 922
CHC,
n = 926
JCA,
n = 1047
GDAHC,
n = 830
OASIS MO,
n = 382
OASIS PA,
n = 310
OASIS TX,
n = 337
FH,
n = 855
SWOHIO,
n = 927
Meeting PA
recommendationsa
(BRFSS PA module)
Sedentary 42.9 37.2 55.9 66.2 55.8 37.6 47.4 49.2 39.6 38.8 31.0 30.7
Underactive 42.6 43.8 34.2 32.7 40.6 49.9 49.1 42.6 39.6 46.6 44.5 52.3
Regularly active 14.5 19.0 10.0 1.1 3.7 12.4 3.5 8.3 20.8 14.6 24.5 17.0
Effect size for PA
(CHAMPS)
Complete data 0.55 0.48 0.61 0.74 0.85 0.97 0.65 0.85 0.51 0.88 0.54 0.41
Carry forward 0.38 0.31 0.31 0.49 0.49 0.7 0.48 0.65 0.34 0.62 0.38 0.28
The sample size per site reflects the total number participating. Sample sizes may be less for specific variables due to missing data.
*BS, Blue Shield of California; SMB, San Mateo Berkley; SMSM, San Mateo San Mateo County; YMC, Young Men Christian Association of Metropolitan Chicago; JCA,
Jewish Council for the Aging of Great Washington DC; GDAHC, Greater Detroit Area Health Council; OASISMO, The OASIS Institute St. Louis, MO; OASIS PA, The
OASIS Institute of Pittsburg, PA; OASIS TX, The OASIS Institute of An Antonio, TX; FH, FirstHealth of the Carolinas; SWOHIO, Council on Aging of Southwest Ohio.
aIndicates that this measure was not available for participants taking part in AFL in Year 2. Percentages may not sum to 100% due to rounding.
Fig. 1. Average attendance (%) at ALED sessions, separately for
each year of program implementation.
Process evaluation of physical activity program
333
According to qualitative data from the electronic
reporting system, most modifications to session
materials were to improve literacy levels, add age
appropriate clip art or create handouts of overhead
materials. Most session activity modifications in-
cluded changes such as including short walks or
stretching sessions, completing homework in class,
modifying the scavenger hunt activity or having
a guest speaker. The majority of the changes were
because of site logistical issues or because sites
wanted to add components to make the program
more interactive/social, culturally and age appropri-
ate, fun or to be responsive to participant wishes for
content. Session 10, which focuses on finding a vari-
ety of fun ways to do moderate-intensity PA, had the
highest percentage of modifications (47%). This ses-
sion includes a scavenger hunt activity that was often
logistically difficult to conduct for many sites. There-
fore, sites often replaced or altered this activity.
Each session had corresponding homework
assigned. The number of homework assignments
for each session ranged from 2 to 10 and was higher
for the 12-week program. On average across years
and sessions, 6.7 homework assignments were
expected and 4.2 homework assignments were given.
We captured two measures of participant engage-
ment: completion of home assignments and partic-
ipation in self-monitoring activities. Of participants
who attended the session, 72% completed the home
assignments (average across years and sessions).
Completion of home assignments was somewhat
variable across sites. Participants may have strug-
gled with some of the writing or reading homework
assignments (reading assignments from program
manual, writing a letter to self or tracking activity)
because of not being accustomed to home assign-
ment and/or literacy issues.
Regarding self-monitoring, ALED offers partic-
ipants four methods of tracking PA (PA thoughts,
PA type, steps and PA minutes). Participants were
expected to try each of the methods and to select at
least one method that best matched their interests
and goals. As seen in Table VII, participants who
attended sessions were most likely to track their
steps (63%). Tracking thoughts and tracking steps
increased over the years. Participants and staff
questioned the importance of tracking thoughts in
the first year so program developers provided
a stronger rationale to the program sites. In addi-
tion, during the first year of the program, the PA
tracking forms were modified to be more user-
friendly and accommodate tracking light activity.
There was a great deal of site variability in the
percentage of participants engaging in the four
0
0.2
0.4
0.6
0.8
1
1.2
50.0 55.0 60.0 65.0 70.0 75.0 80.0
Percentage of Participants Attending
Effect Size (d) for sqrt MVPA
ES
ES - Intent-to-Tx
Site 6
Site 6
Site 7
Site 7
Site 8
Site 8
Site 9
Site 9
Site 10
Site 10
Site 11
Site 11
Site 12
Site 12
Fig. 2. The association between site-level ALED attendance and site-level PA outcomes [effect sizes (ES)]. ES refer to the change in
moderate- to vigorous-intensity PA from pre-test to post-test, as measured by the CHAMPS PA survey. The ES measured was used.
Analyses were conducted using SAS PROC MIXED and controlled for site clustering. Intent-to-treat (Intent-to-Tx) ES carry forward
baseline values in instances where post-test surveys are not returned.
S. F. Griffin et al.
334
tracking methods. For the last 3 years of AFL, we
were able to compute the percentage of participants
who attended sessions who used any of the recom-
mended tracking forms. These rates were similar
across years and averaged 68%.
ALED sites distributed participant evaluations at
the end of each session. These evaluations were
uniformly positive, with an overwhelming majority
of the sessions (93%) being rated as `just right' for
speed and facilitators being rated an average of 4.9
(5 = most favorable rating) in terms of prepared-
ness, organization, moving the session along and
effectively answering questions.
Plots showing the relationship between site
implementation fidelity and outcome (PA effect
size) did not show any consistent patterns. The lack
of a clear relationship could be because there was
relatively little variation in some fidelity measures
(e.g. participant staging or group size), and most
adaptations were minor and did not jeopardize the
program. In the case of fidelity measures that were
more variable, the adaptations may have been mi-
nor enough to not impact effect size.
Active Choices
Dose/attendance/participation
Face-to-face session For AC, dose was assessed
by tracking the percentage of participants receiving
the initial face-to-face session and each of the eight
planned telephone calls, as well as by the duration
of each of these. Because the completion of the
face-to-face session was deemed necessary to be
enrolled in the program, 100% of AC participants
Table VI. Implementation of ALED essential elements, by year
Program essential element Year 1
(20 weeks),
37 groups
Year 2
(20 weeks),
80 groups
Year 3
(20 weeks),
105 groups
Year 4,
(12 weeks),
106 groups
All years
combined,
328 groups
Group size
Mean (SD) across sites combined 13.5 (5.1) 13.5 (4.6) 15.0 (5.2) 15.0 (4.7) 14.5 (4.9)
Range across sites 6.8­20.0 11.0­15.1 11.1­17.6 10.9­20.0 12.4­16.4
Combined sessions, % of sessions
% across sites combined 6.4 5.4 9.2 0.5 7.0
Range across sites 0.0­16.3 0.0­15.7 0.0­20.0 0.0­2.4 0.3­16.0
Check-in completed, % of sessions
% across sites combined 96.3 96.3 96.3 93.5 95.7
Range across sites 93.8­98.3 82.9­99.1 88.1­100 92.1­99.0 88.9­99.1
Incentives provided, % of sessions
% across sites combined 59.1 42.3 51.9 59.2 51.7
Range across sites 19.0­100 6.4­100 11.1­99.4 29.0­99.0 14.7­99.6
Sessions staged
Mean (SD) across sites combined 4.8 (0.4) 4.6 (0.7) 4.7 (0.6) 2.9 (0.6) 4.1 (1.1)
Range across sites 4.3­5.0 4.1­5.0 4.3­5.0 2.2­3.0 3.8­4.3
Learning activities per session
Mean (SD) across sites combined 2.9 (1.3) 3.0 (1.2) 3.1 (1.2) 4.9 (1.7) 3.4 (1.6)
Range across sites 2.6­3.1 2.8­3.2 2.9­3.3 4.6­5.2 3.3­3.6
Learning modifications, % of sessions
% across sites combined 18.8 24.8 10.8 11.0 15.8
Range across sites 0.7­46.9 0.0­53.3 3.8­19.2 0.0­23.2 1.7­26.6
Home assignments given per session
Mean (SD) across sites combined 2.6 (1.5) 3.9 (1.6) 3.8 (1.6) 6.1 (1.7) 4.2 (2.0)
Range across sites 1.8­3.5 2.1­4.5 2.9­4.6 5.4­6.6 3.3­4.6
Means (SD) and percentages are for all sessions. Staging was recommended in five sessions in Years 1­3 and three sessions in Year 4.
Values for learning activities and home assignments refer to sessions that are not combined. A higher number of learning activities and
home assignments were part of the Year 4 curriculum compared with Years 1­3.
Process evaluation of physical activity program
335
received this session. Across years, 66% of face-to-
face sessions were delivered individually, 34%
were delivered in small groups (generally 3­10
participants) and <1% were delivered in some other
mode (e.g. by telephone). Two sites delivered the
face-to-face sessions individually on average 97
and 99% of the time, while another site delivered
only 18% of the face-to-face sessions individually
and the remainder in small group formats.
The recommended length of time for the initial
face-to-face session was 45­60 min (individual for-
mat). The average length of the initial face-to-face
counseling was 73.3 min for individual sessions
and 108.8 min for small group sessions. The aver-
age length of the face-to-face session varied greatly
by site (individual: 34.3­102.7 min; small group:
50.8­127.7 min). Several organizations used the
face-to-face session to also provide an orientation
to their organization and/or complete pre-program
evaluation information thus increasing the length.
Telephone-based counseling sessions On aver-
age, participants received 5.4 of the recommended
eight telephone counseling calls. Figure 3 presents
call completion data. Overall, 7% of participants
received no calls, 19% received one to three calls,
44% receive four to seven calls and 31% received
all eight calls. Call completion patterns were con-
sistent across years. Average call completion rates
were generally similar across sites (5.3­5.9 calls)
but were notably lower at one site (3.3 calls).
Table VII. Participant engagement in ALED, by year
Participant engagement Year 1
(20 weeks)
Year 2
(20 weeks)
Year 3
(20 weeks)
Year 4
(12 weeks)
All years
combined
Homework completion,
% of participants
% across sites combined 67.5 67.3 77.0 72.6 72.2
Range across sites 49.5­92.7 48.5­82.1 55.9­91.9 56.9­82.5 52.9­83.3
Tracking PA (self-monitoring)
Tracking thoughts,
% of participants
% across sites combined 15.4 35.7 42.7 44.6 38.3
Range across sites 1.8­68.9 1.5­62.0 1.9­65.4 16.1­71.9 8.9­62.1
Tracking activity by type
of activity, % of participants
% across sites combined 41.4 50.2 48.2 48.0 47.9
Range across sites 14.8­81.1 2.8­63.5 0.5­66.6 20.4­73.3 8.9­64.5
Tracking steps, % of participants
% across sites combined 57.2 56.3 69.7 62.4 62.8
Range across sites 39.9­82.9 25.3­80.2 12.9­87.4 26.4­78.5 34.6­78.1
Tracking activity by days and
minutes of activity, % of
participants
% across sites combined 32.3 24.7 30.7 22.3 27.1
Range across sites 0.0­68.1 0.6­50.9 0.5­69.8 7.1­45.3 6.7­50.2
Any type of tracking, % of participants
% across sites combined Unavailable 63.7 69.7 68.6 67.6
Range across sites 16.3­76.3 7.7­88.1 53.8­84.2 28.2­80.2
Percentages in this table are based on participants who attended the group sessions. Participants who did not attend the sessions were
not included in the denominator. For tracking thoughts and activity by type of activity, the percentages represent averages for Sessions
7­20 for the 20-week program (Years 1­3) and Sessions 3­12 for the 12-week program (Year 4). For tracking steps and activity by days
and minutes of activity, the percentages represent averages for Sessions 15­20 for the 20-week program (Years 1­3) and Sessions 9­12
for the 12-week program (Year 4). For any type of tracking, the percentages represent whether any of the four tracking types were done
in sessions where tracking was recommended and are averages for all applicable sessions.
S. F. Griffin et al.
336
The recommended call duration was 10­15 min.
Actual duration was 13.5 min, and this average
decreased across years. On average, participants
received 72.7 total minutes of telephone counsel-
ing, with the same site delivering fewer calls also
having a lower total duration (39.2 versus 64.5­
86.9 min). Sites with higher call duration (Fig. 4)
and call completion rates (Fig. 5) tended to have
larger PA effect sizes than sites with lower rates.
The site with the fewest call completion and dura-
tion rates served the most ethnically diverse popu-
lation. This site experienced more early senior level
staff changes than others and served a population
that was culturally not accustomed to making
appointments, particularly for telephone sessions.
Fidelity to program model
Face-to-face session Implementation fidelity was
high in the AC program. Site completion of each of
10 key steps in the initial face-to-face counseling
session (see Table II) was generally 98­100%. The
only face-to-face activity reported in <96% of ses-
sions was providing a local resource guide (89% in
Year 1). It took AC sites more time than expected in
the first year to develop and/or identify a suitable
PA resource guide specifically for older adults. This
percentage increased to 99% in remaining years.
Telephone-based counseling This pattern of high
completion rates of recommended activities was
also evident in the content of telephone calls (see
Table VIII). Stage of readiness for change was
assessed on 98% of calls, progress toward their PA
goal on 96% of calls and the assessment of injuries
limiting PA since the last call on 96% of calls.
AC is designed to increase moderate-intensity
PA; however, many participants were completely
sedentary on study entry and therefore had to begin
with light activity. Therefore, in the first year of
0.0
10.0
20.0
30.0
40.0
50.0
60.0
70.0
80.0
90.0
100.0
Call 1 Call 2 Call 3 Call 4 Call 5 Call 6 Call 7 Call 8
Call Number
Percentage Receiving Call
Fig. 3. Percentage of AC participants receiving each telephone
call. 0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
20 30 40 50 60 70 80 90 100
Duration in Minutes
Effect size (d) for sqrt MVPA
ES ES Intent-to-Tx Site 5
Site 5
Site 4
Site 4
Site 3
Site 3
Site 2
Site 2
Site 1
Site 1
Fig. 4. The association between site-level AC call duration and
site-level PA outcomes [effect sizes (ES)]. ES refer to the change
in moderate- to vigorous-intensity PA from pre-test to post-test,
as measured by the CHAMPS PA survey. The ES measured was
used. Analyses were conducted using SAS PROC MIXED and
controlled for site clustering. Intent-to-treat (Intent-to-Tx) ES
carry forward baseline values in instances where post-test
surveys are not returned.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
2 2.5 3 3.5 4 4.5 5 5.5 6 6.5
ES ES Intent-to-Tx
Site 3 Site 2
Site 1
Sites 4 & 5
Site 3
Site 2
Site 5
Site 4
Site 1
Number of calls in
Effect size (d) for sqrt MVPA
Fig. 5. The association between site-level AC number of calls
completed and site-level PA outcomes [effect sizes (ES)]. ES
refer to the change in moderate- to vigorous-intensity PA from
pre-test to post-test, as measured by the CHAMPS PA survey.
The ES measured was used. Analyses were conducted using SAS
PROC MIXED and controlled for site clustering. Intent-to-treat
(Intent-to-Tx) ES carry forward baseline values in instances
where post-test surveys are not returned.
Process evaluation of physical activity program
337
implementation, the program was adapted to in-
clude an assessment of light-intensity PA. Health
educators used their own discretion regarding
which type of PA to assess (light or moderate in-
tensity) and PA was assessed in 97% of calls.
Health educators also assessed whether participants
were using pedometers to track PA on 84% of calls.
The AC program model includes discussion
topic recommendations based on a participant's
stage of readiness for change. Health educators se-
lect discussion topics based on the participant's
stage as well as participant's interests and stated
areas of concern. Table IX lists call topics and the
percentage of calls during which each was dis-
cussed. Health educators consistently discussed
barriers and benefits of PA with participants across
all five stages of readiness to change. In pre-
contemplation, contemplation and preparation, the
recommended topics were generally the most com-
monly discussed. In action and maintenance, where
a higher number of topics are suggested for discus-
sion, there was more variability in topics discussed.
Previous exercise experience among those in prep-
aration and relapse prevention among those in
action were topics discussed less than expected.
Plots showing the relationships between site
implementation fidelity and outcome (PA effect
size) revealed no consistent patterns, likely due to
the lack of site variation in fidelity.
Limitations
There were several limitations of the AFL process
evaluation. First, all data were self-report. Several
steps were taken to minimize errors in reporting.
These include training staff, ensuring reporting con-
fidentiality, building rapport with the program staff
via frequent conference calls and meeting face-to-
face annually. However, there is still an inherent
risk of inaccuracy. Additionally, potential impor-
tant factors such as staff quality and participant
characteristics were not assessed.
Discussion
AFL presented a unique opportunity to exam-
ine implementation fidelity of two well-defined
evidence-based PA programs when implemented
into real world settings. Measures of dose delivered
(attendance and call completion) revealed a slight
Table VIII. Implementation of AC essential elements, by year
Program essential element Year 1
(2174 calls)
Year 2
(4384 calls)
Year 3
(6311 calls)
Year 4
(5816 calls)
All years
(18 685 calls)
Staged for readiness for
change, % of calls
% across sites combined 98.2 99.0 98.7 97.5 98.3
Range across sites 96.0­99.4 98.3­99.6 94.5­99.6 88.2­99.6 92.8­99.3
Assessed for PA goals, % of calls
% across sites combined 97.7 98.6 96.6 92.9 96.0
Range across sites 96.1­98.5 94.8­99.6 92.0­97.7 88.9­95.5 91.9­97.0
Assessed for injury, % of calls
% across sites combined 96.6 89.9 96.7 100 96.1
Range across sites 92.1­100 70.3­99.6 85.0­100 100­100 86.3­99.8
Assessed for light- or moderate-intensity
PA, % of calls
% across sites combined 98.6 97.8 95.6 96.2 96.6
Range across sites 96.9­100 96.5­99.0 83.0­99.5 85.9­99.2 90.7­99.0
Assessed for use of pedometer,
% of calls
90.9 92.2 82.0 78.2 84.2
% across sites combined
Range across sites 81.1­98.7 68.8­98.3 72.0­91.4 27.8­92.0 63.0­87.6
S. F. Griffin et al.
338
reduction in participation initially followed by a pla-
teau. At the site level, dose appeared to be related to
PA for the AC program. Staff implementation of the
programs' essential elements was high for both AC
and ALED sites. However, participant engagement
was somewhat lower. Sites made some modifica-
tions; however, the sites and program developers
found a balance between intervention fidelity and
adaptation through a process whereby sites could
request `permission' to make adaptations and
requests were approved as long as they adhered to
the program's essential elements.
This study demonstrated that community organi-
zations successfully delivered the two evidence-
based programs to a large diverse group of partici-
pants in community settings and were able to `bend'
the program models while still having high dose and
fidelity levels for most essential elements. This find-
ing is particularly noteworthy because recruitment
levels doubled from Year 1 to Year 2 and increased
again for Years 3 and 4. Also, many organizations
increasingly reached out to more diverse populations.
These findings of high adherence to essential ele-
ments are consistent with process evaluation findings
from other large multisite interventions [19, 20, 25]
and with the primary outcomes of AFL which
showed large and meaningful increases in PA [35].
We did not detect a clear relationship between fidel-
ity and outcome, possibly due to lack of variation,
potential ceiling effects or small site sample size.
Future manuscripts will further explore relationships
between the implementation levels, individual level
dose, fidelity and outcomes for the AFL project.
Community-based organizations may initially
`question' the value of standardized intervention
protocols. AFL's approach of allowing sites to se-
lect the program to implement, initially implement-
ing the protocols as written (after minor adaptations
related to literacy and cultural tailoring) followed
by sites proposing adaptations, appeared to be ben-
eficial. This is notable given the complexity of the
program models, diversity of the organizations, as
well as the diverse geographic regions and diverse
participant demographics they served.
Intervention dose (group attendance and call
completion rates) in both programs had an initial
drop followed by a plateau. This pattern is similar to
that reported in other studies [38­41]. Several fac-
tors could contribute to participate attrition, includ-
ing illness, unexpected family or personal issues or
for some participants, quickly discovering the
program was not a `good fit'. If the program was
Table IX. Percentage of AC calls in which cognitive and behavioral topics were discussed, by stage of readiness for change
Precontemplation Contemplation Preparation Action Maintenance
Call topics
Number of calls (n) 652 5495 8481 3360 88
Barriers and benefits, % 94.8 96.2 94.2 91.4 86.4
PA enjoyment, % 18.4 25.7 54.6 56.1 76.1
FITT* plan, % 18.1 46.9 50.3 41.7 21.6
Goal setting, % 54.6 68.2 69.3 58.3 75.0
Injury prevention, % 33.9 55.1 62.6 55.2 63.6
Long-term goals, % 5.7 11.5 13.9 30.2 69.3
Motivation, % 23.3 30.5 30.2 38.3 72.7
Other topics, % 44.0 30.8 22.7 21.2 11.4
Previous exercise experience, % 8.4 10.8 16.7 13.2 9.1
Relapse prevention, % 4.3 5.1 5.9 14.4 61.4
Reward and reinforcement, % 5.1 5.5 24.2 21.9 51.1
Self-efficacy, % 19.2 51.2 52.2 48.8 58.0
Social support, % 21.2 28.8 55.4 52.5 73.9
Tracking progress, % 22.6 43.4 68.9 60.9 60.2
Shading indicates a recommended cognitive/behavioral topic for that stage of change.
*FITT, Frequency, Intensity, Time and Type of physical activity.
Process evaluation of physical activity program
339
not well received, it is likely we would have either
seen a continued decline over the delivery period or
a more steep initial decline [32]. Interestingly, for
AC but not ALED, site dose appeared related to the
site PA effect sizes reported in the AFL outcome
evaluation. However, for both programs, even the
site with the lowest dose had a robust PA effect
size. Several factors could explain the lack of asso-
ciation for ALED. First, it may be that the program
is robust enough to not be negatively impacted by
small to moderate adaptations. Second, variation in
attendance may not have been large enough across
sites to show a relationship with PA. Third, the site
sample size (seven sites) might not have been large
enough to detect a relationship.
Variations were seen for program elements re-
quiring more participant involvement such as track-
ing PA and completing homework assignments
(ALED). Conversely, program elements that were
under greater control of the sites, such as staging
participants (ALED and AC), completing session
check-ins and learning activities (ALED), and com-
pleting face-to-face and call steps (AC) predomi-
nately had consistently high levels of full and
complete implementation. Participant involvement
increased over the years for most program ele-
ments. Emphasizing the importance of participant
involvement (such as homework and tracking) in
staff training may have contributed to the improved
participation levels in the later years. Additionally,
allowing participants a choice in how they self-
monitor and having lower literacy options for
self-monitoring and homework assignments may
have been a key factor in the successful overall
participation in this program element. These find-
ings may indicate a need for continued training re-
garding participant engagement and targeted
attention for participants showing decreased partic-
ipation early on, either by not completing program
activities or not attending sessions.
Some program elements were adapted during
implementation. However, maintaining open com-
munication between the sites, program developers,
national program office and evaluation team helped
facilitate high fidelity to the essential elements of
each program. Adaptations noteworthy for discus-
sion include combining ALED sessions and alter-
ing the AC program to assess light activity, which
influenced call topics. Although program develop-
ers recommended against combining ALED ses-
sions, sessions were combined with some
regularity, particularly at two of the sites. Most of-
ten the combined sessions were extended in dura-
tion so that core learning could be adequately
covered. Furthermore, telephone topics were ini-
tially determined based on each participant's stage
of change according to moderate-intensity PA;
however, health educators began basing topics on
changes made with light activity. This change was
accepted by the program developers with the un-
derstanding that moderate-intensity activity
remains the primary long-term goal.
AFL's success, in terms of outcomes and fidelity,
has led us to offer the following best practice rec-
ommendations for conducting process evaluations
of community-based translational research. First,
evaluation should be framed and proceed as an in-
teractive process. Second, essential elements should
be identified at the beginning of the program and
the extent to which any proposed adaptations de-
viate from the essential elements of the program
should be indicated. Third, process data should be
built into existing data collection efforts, and data
should be collected and examined over the course of
the study to examine whether there is departure in
fidelity over time and across sites. It is important
that all interested parties understand and embrace
these essential elements at the outset. What might
be gained and/or lost by a particular modification
should be fully considered before making a decision
regarding the modification. Finally, it is important
to recognize that each delivery site may want to
personalize or tailor the intervention as a way of
enhancing their identity and attracting a specific cli-
ent base. Thus, clear guidelines and open commu-
nication between stakeholders regarding what can
be adapted and how it can be adapted are critical.
Funding
Robert Wood Johnson Foundation (grant nos.
43723, 046322, 052927 & 57814).
S. F. Griffin et al.
340
Acknowledgements
We gratefully acknowledge many participants who
took part in the AFL program and evaluation. We
also acknowledge the involvement and significant
contribution of staff from the following organiza-
tions involved in AFL. AC sites: Berkeley Public
Health Department (Berkeley, CA), Blue Shield of
California (Woodland Hills, CA), Church Health
Center (Memphis, TN), San Mateo County Health
Department (San Mateo, CA) and YMCA of Met-
ropolitan Chicago (Chicago, IL); ALED sites:
Council on Aging of Southwestern Ohio (Cincin-
nati, OH), FirstHealth of the Carolinas (Pinehurst,
NC), Greater Detroit Area Health Council (Detroit,
MI), Jewish Council for the Aging of Greater
Washington (Rockville, MD) and The OASIS In-
stitute (St Louis, MO; Pittsburgh, PA; San Antonio,
TX). We thank the National Advisory Committee
for its valuable contributions to AFL. Finally, we
thank the coalitions, partnering organizations and
advisory boards at each of the sites for their mean-
ingful contributions and support of the program.
Conflict of interest statement
None declared.
References
1. Cress ME, Buchner DM, Prohaska T et al. Physical activity
programs and behavior counseling in older adult popula-
tions. Med Sci Sports Exerc 2004; 36: 1997­2003.
2. Mazzero RS, Cavanagh P, Evans J et al. American College
of Sports Medicine. Position stand: exercise and physical
activity for older adults. Med Sci Sports Exerc 1998; 30:
992­1008.
3. Rejeski WJ, Mihalko SL. Physical activity and quality of life
in older adults. J Gerontol A Biol Sci Med Sci 2001; 56:
23­35(Spec. No. 2).
4. Centers for Disease Control and Prevention. Behavioral Risk
Factor Surveillance System Survey Data. Atlanta, GA: U.S.
Department of Health and Human Services, Centers for
Disease Control and Prevention, 2006.
5. Schoenborn CA, Vickerie JL, Powell-Griner E. Health
Characteristics of Adults 55 Years of Age and Over: United
States, 2000­2003 Advance Data: From Vital and Health
Statistics. No 370. Hyattsville, MD: US Department of
Health and Human Services, CDC, National Center for
Health Statistics, 2006. Available at:http://www.cdc.gov/
nchs/data/ad/ad370.pdf. Accessed: 15 May 2008.
6. King AC, Rejeski WJ, Buchner DM. Physical activity inter-
ventions targeting older adults. A critical review and recom-
mendations. Am J Prev Med 1998; 15: 316­33.
7. van der Big AK, Laurant MG, Wensign M. Effectiveness of
physical activity interventions for older adults: a review. Am
J Prev Med 2002; 22: 120­33.
8. Task Force on Community Preventive Services. Recommen-
dations to increase physical activity in communities. Am J
Prev Med 2002; 22: 67­72.
9. Lorig KR, Hurwicz M, Soble D et al. A national dissemina-
tion of an evidence-based self-management program: a pro-
cess evaluation study. Patient Educ Couns 2005; 59: 69­79.
10. Glasgow RE, Lichtenstein E, Marcus AC. Why don't we see
more translation of health promotion research to practice?
Rethinking the efficacy-effectiveness transition. Am J Public
Health 2003; 93: 1261­7.
11. Dzewaltowski DA, Estabrooks PA, Glasgow RE. The future
of physical activity behavior change research: what is
needed to improve translation of research into health pro-
motion practice? Exerc Sport Sci Rev 2004; 32: 57­63.
12. Estabrooks PA, Glassgow RE. Translating effective clinic-
based physical activity interventions into practice. Am J
Prev Med 2006; 31(Suppl): 45­6.
13. Green LW. From research to ``best practice'' in other set-
tings and populations. Am J Health Behav 2001; 25: 165­78.
14. Baranowski T, Stables G. Process evaluation of the 5-a-day
projects. Health Educ Behav 2000; 27: 157­66.
15. Scheirer MA, Shediac MC, Cassidy CE. Measuring the
implementation of health promotion programs: the case of
the Breast and Cervical-Cancer Program in Maryland.
Health Educ Res 1995; 10: 11­25.
16. Saunders RP, Evans MH, Praphul J. Developing a process-
evaluation plan for assessing health promotion program
implementation: a how to guide. Health Promot Pract
2005; 6: 134­47.
17. Bouffard JA, Taxman FS, Silverman R. Improving process
evaluations of correlational programs by using a comprehen-
sive evaluation methodology. Eval Program Plann 2003;
26: 149­61.
18. Harachi TW, Abott RD, Catalano RF et al. Opening the
black box: using process evaluation measures to assess
implementation and theory building. Am J Community
Psychol 1999; 27: 711­31.
19. Young DR, Steckler A, Cohen S et al. Process evaluation
results from a school-and community-linked intervention:
the Trial of Activity for Adolescent Girls (TAAG). Health
Educ Res. 2008; 23: 976­86.
20. Campbell MK, Resnicow K, Carr C et al. Process evaluation
of an effective church-based diet intervention: body and
soul. Health Educ Behav 2008; 34: 864­80.
21. Berkowitz J, Huhman M, Heitzer CD et al. Overview of for-
mative, process, and outcome evaluation methods used in the
VERBä Campaign. Am J Prev Med 2008; 34(6S): S222­9.
22. Jancey JM, Clark A, Howat P et al. A physical activity
program to mobilize older people: a practical and sustainable
approach. Gerontologist 2008; 48: 251­7.
23. Burke J, Howat P, Lee AH et al. Development of a nutrition
and physical activity booklet to engage seniors. BMC Res
Notes 2008; 1: 1­7.
Process evaluation of physical activity program
341
24. Two Feathers J, Kieffer EC, Palmison G et al. The develop-
ment, implementation, and process evaluation of the
REACH Detroit partnership's diabetes lifestyle intervention.
The Diabetes Educ 2007; 33: 509­520.
25. Escoffery C, Glanz K, Elliott T. Process evaluation of the
Pool Cool Diffusion Trial for skin cancer prevention across
2 years. Health Educ Res 2007; 23: 732­43.
26. Dunn AL, Marcus BH, Kampert JB et al. Reduction in
cardiovascular disease risk factors: 6-month results from
Project Active. Prev Med 1997; 26: 883­92.
27. Dunn AL, Marcus BH, Kampert JB et al. Comparison of
lifestyle and structured interventions to increase physical
activity and cardiorespiratory fitness: a randomized trial.
JAMA 1999; 281: 327­34.
28. King AC, Haskell WL, Young DR et al. Long-term effects
of varying intensities and formats of physical activity on
participation rates, fitness, and lipoproteins in men
and women aged 50 to 65 years. Circulation 1995; 91:
2596­604.
29. King AC, Baumann K, O'Sullivan P et al. Effects of mod-
erate-intensity exercise on physiological, behavioral, and
emotional responses to family care giving: a randomized
controlled trial. J Gerontol A Biol Sci Med Sci 2002; 57:
M26­M36.
30. King AC, Pruitt LA, Phillips W et al. Comparative effects of
two physical activity programs on measured and perceived
physical functioning and other health-related quality of life
outcomes in older adults. J Gerontol A Biol Sci Med Sci
2000; 55: M74­M83.
31. Stewart AL, Mills KM, Sepsis PG et al. Evaluation of
CHAMPS, a physical activity promotion program for older
adults. Ann Behav Med 1997; 19: 353­61.
32. Prochaska JO, DiClemente CC, Norcross JC. In search of
how people change. Applications to addictive behaviors. Am
Psychol 1992; 47: 1102­14.
33. Bandura A. Social Foundations of Thought and Action: A
Social Cognitive Theory. Englewood Cliffs, NJ: Prentice-
Hall, 1986.
34. Wilcox S, Dowda M, Griffin SF et al. Results of the first
year of Active for Life: translation of two evidence-based
physical activity programs for older adults into community
settings. Am J Public Health 2006; 96: 1201­9.
35. Wilcox S, Dowda D, Leviton L et al. The Active for Life
initiative: final results of translating two evidence based
physical activity programs into practice. Am J Prev Med
2008; 35: 340­51.
36. Basen-Engquist K. The effects of two types of teacher train-
ing on implementation of smart choices: a tobacco preven-
tion curriculum. J Sch Health 1994; 64: 334­9.
37. Steckler A, Linnan L. Process Evaluation for Public Health
Interventions and Research. San Francisco, CA: Jossey-
Bass, 2002.
38. Watkins AJ, Kligman EW. Attendance patterns of older
adults in a health promotion program. Public Health Rep
1993; 108: 86­90.
39. Dishman RK, Sallis JF, Orenstin DR. The determinants of
physical activity and exercise. Public Health Rep 1985; 100:
158­71.
40. Heesch KC, Masse LC, Dunn AL et al. Does adherence to
a lifestyle physical activity intervention predict change in
physical activity. J Behav Med 2003; 24: 333­48.
41. Heesch K, Masse LC, Frankowski RF et al. Adherence
within and between lifestyle physical activity groups in Pro-
ject PRIME. J Phys Act Health 2004; 1: 29­44.
Received on August 11, 2008; accepted on February 23, 2009
S. F. Griffin et al.
342
