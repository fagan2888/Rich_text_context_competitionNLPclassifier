Evolutionary Psychology
www.epjournal.net ­ 2014. 12(3): 534-548
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
Original Article
Dangerous Animals Capture and Maintain Attention in Humans
Jessica L. Yorzinski, Center for Cognitive Neuroscience, Duke University, Durham, NC, USA. Email:
jly5@duke.edu (Corresponding author).
Michael J. Penkunas, Department of Psychology, University of California, Davis, CA, USA.
Michael L. Platt, Duke Institute for Brain Sciences, Center for Cognitive Neuroscience, and Department of
Neurobiology, Duke University, Durham, NC, USA.
Richard G. Coss, Department of Psychology, University of California, Davis, CA, USA.
Abstract: Predation is a major source of natural selection on primates and may have
shaped attentional processes that allow primates to rapidly detect dangerous animals.
Because ancestral humans were subjected to predation, a process that continues at very low
frequencies, we examined the visual processes by which men and women detect dangerous
animals (snakes and lions). We recorded the eye movements of participants as they
detected images of a dangerous animal (target) among arrays of nondangerous animals
(distractors) as well as detected images of a nondangerous animal (target) among arrays of
dangerous animals (distractors). We found that participants were quicker to locate targets
when the targets were dangerous animals compared with nondangerous animals, even when
spatial frequency and luminance were controlled. The participants were slower to locate
nondangerous targets because they spent more time looking at dangerous distractors, a
process known as delayed disengagement, and looked at a larger number of dangerous
distractors. These results indicate that dangerous animals capture and maintain attention in
humans, suggesting that historical predation has shaped some facets of visual orienting and
its underlying neural architecture in modern humans.
Keywords: attention, humans, delayed disengagement, eye-tracking, predation, predator
detection
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
Introduction
Predation has been an important source of natural selection on primates. A variety
of predators, such as snakes and felids (Hart and Sussman, 2005; Isbell, 2006; Stanford,
2002), have preyed upon primates for millions of years. Humans are no exception, as their
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -535-
hominin ancestors also suffered from predation, and they continue to experience predation
from large-bodied felids and snakes in rural areas (Coss, Fitzhugh, Schmid-Holmes,
Kenyon, and Etling, 2009; Coss and Moore, 2002; Hart and Sussman, 2005; Headland and
Greene, 2011; Treves and Palmqvist, 2007). The ability of primates to rapidly respond to
potential danger is critical to their survival (Caro, 2005). Before individuals can respond to
potential danger and engage in defensive action, they must first detect the threat by
directing their attention (covertly or overtly) toward it (Cronin, 2005; Dukas and Kamil,
2000; Huijding, Mayer, and Koster, 2011; Yorzinski, Patricelli, Babcock, Pearson, and
Platt, 2013; Yorzinski and Platt, 2014).
It is possible that our long evolutionary history with predators has shaped our visual
system to quickly detect dangerous animals (Coss, 2003; Isbell, 2006). Visual-search
experiments have found that children, including infants as young as 8-months, and adults,
are faster to detect threatening animals, including snakes, spiders, and lions, compared with
nonthreatening animals (Blanchette, 2006; Brosch and Sharma, 2005; Flykt, 2005; LoBue
and DeLoache, 2008, 2010; Öhman, Flykt, and Esteves, 2001; Penkunas and Coss,
2013a,b; Rosa, Gamito, Oliveira, Morais, and Saraiva, 2011; Waters, Lipp, and Spence,
2004). Ontogenetic experiences with threats also influence detection performance
(Blanchette, 2006; Fox, Griggs, and Mouchlianitis, 2007). People are faster to detect
contemporary threats (such as guns and syringes) compared to neutral stimuli even though
these contemporary threats are too recent to have influenced our evolutionary history. The
perceptual processes responsible for this rapid detection of threats are largely unknown.
Based on studies that directly measure visual attention (using eye-trackers to
monitor eye movements), threatening stimuli are often better at attracting and holding
attention compared to nonthreatening stimuli. Humans are faster at detecting images of
dangerous people and people experiencing threat than people who are not threatened
(Nummenmaa, Hyona, and Calvo, 2006). Furthermore, humans, especially high-anxious
individuals, are slower to disengage their attention when viewing angry faces compared
with happy or neutral faces (Belopolsky, Devue, and Theeuwes, 2012; Reinholdt-Dunne et
al., 2012). Similarly, people often detect spider and snake images faster than neutral images
(Gerdes, Pauli, and Alpers 2009; Rosa et al., 2011).
The purpose of this study was to examine the processes of visual scanning that
guide humans' abilities to detect dangerous animals rapidly. The eye movements of adult
participants were recorded as they located a single image of a dangerous animal (target)
embedded in an array of nondangerous animals (distractors) or detected a nondangerous
animal (target) embedded in an array of dangerous animals (distractors). The participants
were presented with color images and images in which low-level features were minimized
(spatial frequency and luminance were controlled). We tested whether dangerous animals:
(i) maintain attention or "delay disengagement" during visual search (Fox, Russo, and
Dutton, 2002) and/or (ii) exogenously attract attention through low-level features (e.g.,
luminance or contrast; Simons, 2000). If dangerous animals are effective at maintaining
attention, we predicted that humans would spend more time looking at distractors when the
distractors were dangerous animals compared with nondangerous animals. If dangerous
animals capture attention through low-level features, we predicted that humans would look
at a larger number of distractors when the distractors were dangerous animals compared
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -536-
with nondangerous animals.
Materials and Methods
Participants
Thirty men and 30 women participated in this study at Duke University from
November 2012 through March 2013. They were all of European heritage and between the
ages of 18 and 30 years old (M = 21.4, SE = 0.33 years). Flyers and emails were used to
recruit participants, and they were told that they would be participating in a study that
explored predator recognition. They earned $15 for their participation. The Institutional
Review Board of Duke University (#7646) approved this study; written consent was
obtained from all participants.
Animal images
We created two sets of 96 matrices that displayed images of dangerous and
nondangerous animals. One set showed images of lions (Panthera leo) and impalas
(Aepyceros melampus), and the other set showed images of snakes (Serpentes) and lizards
(Lacertilia). Each set included four treatment blocks of 24 matrices.
In the first set, the first treatment block (Target Lion) consisted of 24 matrices that
were created from 24 images of lions and impalas. Each matrix consisted of a 3 × 3 array in
which one lion image (target) and seven impala images (distractors) were displayed (the
middle matrix position was left empty; see Figure 1a). Each matrix was 1280 × 1024 pixels
(dpi = 96) and filled the entire screen. Images within the matrices were 293 × 208 pixels
(approximately 7.4 degrees wide and 5.2 degrees high); 100 pixels separated images from
each other and from the edges of the matrices. Lion images appeared three times in each of
the eight possible positions across the 24 matrices, and a different lion photograph was
used in each matrix. Impala images appeared in pseudo-randomized positions within each
matrix such that each image appeared seven times across the 24 matrices but was never in
the same matrix position more than once and only appeared one time within the same
matrix. The lion and impala images consisted of adult males with manes and adult females,
respectively, and displayed animals that were standing with all four legs on the ground and
not looking directly at the camera. The images depicted each animal in a natural scene and
none of the animals were displaying obviously threatening or defensive postures; the
images were obtained from online sources.
A second treatment block (Target Lion Low Level Control) was created using the
24 matrices that were generated in the first treatment block; the matrices were processed
using the SHINE toolbox (default settings; Willenbockel et al., 2010) in MATLAB to
minimize low-level confounds (images within a matrix were matched for luminance and
spatial frequency; see Figure 1b). The SHINE toolbox first matches the Fourier amplitude
spectra of the images (spatial frequency matching) and then matches the luminance
histograms (Willenbockel et al., 2010); the low-level features of the resulting images are
therefore minimized (because they have the same luminance and spatial frequency) but not
entirely eliminated since the toolbox does not match other low-level features (such as edges
or orientation).
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -537-
Figure 1. Examples of scanpaths from one male participant on matrices from the four
treatment blocks of the lion and impala set
Note. (a) Target Lion; (b) Target Lion Low Level Control; (c) Target Impala; (d) Target Impala Low Level
Control. The size of the black circles indicates the amount of time the participant spent looking at each
location. Gaze begins in the middle of the image and ends on the target animal.
The process used to create images in the first and second treatment blocks was
repeated to generate the third and fourth treatment blocks (Target Impala and Target Impala
Low Level Control) except that one impala image (target) and seven lion images
(distractors) were used in each image. Therefore, there were a total of 96 matrices in the
Target Lion, Target Lion Low Level Control, Target Impala, and Target Impala Low Level
Control treatment blocks.
The second set of 96 matrices was created using the same procedure that we used to
create the first set except that we used images of snakes and lizards. The snake and lizard
images were the same as those used in previous studies (see Penkunas and Coss, 2013a,b).
The images were used to create the Target Snake, Target Snake Low Level Control, Target
Lizard, and Target Lizard Low Level Control blocks.
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -538-
Eye-tracker
We used a Tobii T60 eye-tracker along with Tobi Studio 3.1 and 3.2 (Tobii
Technology, Inc., Sweden) to present our images and record the gaze of participants
(accuracy: 0.5 degrees; data rate: 60 Hz; binocular tracking). Participants were told that we
were measuring the size of their pupils but were not told that their eye movements were
being monitored until after they completed the trial. The images were displayed using Tobii
StudioTM software (version 3.1 or 3.2) on a 1280 × 1024 pixel monitor (43.18 cm diagonal).
Participants were positioned approximately 60 cm from the screen and were unrestrained
(i.e., no bite bar or chin rest was used). The equipment was calibrated (9 points) before
each trial began. We used the Tobii Velocity-Threshold Identification filter (I-VT filter;
gap fill-in: 75 ms; eye selection: average; noise reduction: median; noise reduction
samples: 7; velocity calculator window: 20 ms; I-VT classifier threshold: 30 degrees/sec;
merge adjacent time: 75 ms; merge adjacent angle: 0.5 degrees; discard short fixations: 60
ms) to classify fixations and saccades. This filter classifies eye movements as fixations or
saccades based upon the velocity of eye movements; eye movements below and above the
velocity threshold (30 degrees/sec, in this study) are classified as fixations and saccades,
respectively. Eye-tracking data consisted of coordinates of where participants were known
to be looking during each sampling point.
Experimental procedure
The experimenter (JLY) first asked participants to perform two practice trials so
they could become familiar with the procedure. In the first practice trial, participants were
asked to fixate a black dot that appeared in the center of the screen for 1 sec. They were
then presented with a 3 × 3 matrix that consisted of one image of a dog and seven images
of cats (arranged in the same manner as described above for the predator and nonpredator
matrices). They were instructed to press the space bar on the keyboard as soon as they
located the dog image within the matrix. Once they pressed the space bar, the matrix
disappeared and the fixation dot reappeared. They repeated this process for 10 matrices.
The second practice trial was similar to the first except that the 10 matrices of the dogs and
cats were altered to minimize low-level confounds (see above).
After completing the two practice trials, participants were then presented with the
first set of 24 matrices. As in the practice trials, they were instructed to fixate a central dot;
when a matrix appeared, they were asked to press the space bar as soon as they found the
target animal. Because the participants fixated this central dot, the middle position of the
matrices was left empty (see animal images above) to ensure that participants had to search
for the target. They performed this task for each of the four blocks of matrices within the
set (the order of the blocks was randomized across participants). This process was repeated
a second time with the second set of matrices (the order of the sets was randomized across
participants). Therefore, a participant would perform the search task on eight blocks of
matrices: Target Lion, Target Impala, Target Lion Low Level Control, Target Impala Low
Level Control, Target Snake, Target Lizard, Target Snake Low Level Control, and Target
Lizard Low Level Control, with the order of the blocks and sets randomized across
participants.
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -539-
Measurements and statistical analysis
Using a customized MATLAB program, we drew rectangular regions of interest
(ROI) around each target and distractor. All target and distractor images were the same size
(293 × 208 pixels; see Animal Images above) and their ROIs included the entire rectangular
region of each image. For each fixation coordinate, we determined which ROI it fell within
to determine whether the participant was looking at the target image, distractor images, or
neither the target nor distractor images. We calculated four metrics: the amount of time that
elapsed before participants fixated on the target (Latency to Fixate Target Animal), the
amount of time that elapsed before participants manually responded by pressing the space
bar to indicate they detected the target (Latency to Manual Response), the number of
different distractors the participants fixated (No. of Different Distractors Fixated), and the
average time that participants spent looking at each distractor, only including distractors
that were fixated (Time Viewing Distractors). For each participant, we calculated the mean
value of the metrics within each of the eight treatment blocks (Target Lion, Target Impala,
Target Lion Low Level Control, Target Impala Low Level Control, Target Snake, Target
Lizard, Target Snake Low Level Control, and Target Lizard Low Level Control). In
matrices where the data indicated a participant never fixated the target, it was not possible
to determine whether (i) participants did not fixate the target (and therefore did not
correctly perform the task) or (ii) whether the eye-tracker failed to record the participants'
gaze when they were fixating the target. We therefore excluded a given matrix from the
analysis if a participant's fixations never fell within the target or if more than 10% of the
gaze data was missing; only 4.6% of the matrices were discarded due to this restriction.
We analyzed our data using linear mixed-effects models with repeated measures
and an unstructured covariance structure (PROC MIXED) in SAS (SAS Institute Inc.,
Cary, NC). We examined whether the latency to fixate the target animal, latency to
manually respond, number of different distractor images fixated, and time viewing each
distractor image were influenced by the sex of the participant (male or female), animal
class of the target (mammal vs. reptile), danger level of the target (dangerous vs. not
dangerous), type of image (natural image vs. image that controlled for low-level features),
and their interactions; we included participant identity as a random effect. Because sex of
the participant was nonsignificant in all models (ps > 0.2), we dropped this term from the
models. We made a priori predictions regarding differences among treatment blocks and
created contrasts to evaluate these differences; we performed eight comparisons and used a
Bonferroni correction to evaluate significance. Means ± SEs are provided in the Results
section to illustrate effect sizes.
Results
The latency to locate the target image (fixate and manual response), number of
different distractor images fixated, and time viewing each distractor image varied
depending on the animal class (see Table 1A), danger level (see Table 1B), image type (see
Table 1C), and some of the interactions among these variables (see Table 1D-G).
Participants were faster to fixate the target when the target was a dangerous animal (lion
and snake) compared to when it was a nondangerous animal (impala and lizard) in both the
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -540-
natural matrices (lion: 621 ± 11 ms; impala: 773 ± 15 ms; snake: 733 ± 18 ms; lizard: 836 ±
20 ms; see Latency to Fixate Target Animal, Table 1H and J) and matrices that minimized
low-level features (lion: 801 ± 16 ms; impala: 969 ± 23 ms; snake: 941 ± 24 ms; lizard:
1071 ± 18 ms; see Latency to Fixate Target Animal, Table 1I and K); however, participants
were slower to fixate a given target in the low-level matrices compared with the natural
matrices (see Latency to Fixate Target Animal, Table 1L-O; see Figure 2a).
Participants were also faster to detect the target via manual response when the target
was a dangerous animal (lion and snake) compared to when it was a nondangerous animal
(impala and lizard) in both the natural matrices (lion: 980 ± 22 ms; impala: 1182 ± 25 ms;
snake: 1174 ± 32 ms; lizard: 1381 ± 44 ms; see Latency to Manual Response, Table 1H and
J) and matrices that minimized low-level features (lion: 1250 ± 27 ms; impala: 1511 ± 34
ms; snake: 1608 ± 60 ms; lizard: 1868 ± 56 ms; see Latency to Manual Response, Table 1I
and K); however, participants were slower to detect a given target in the low-level matrices
compared with the natural matrices (see Latency to Manual Response, Table 1L-O; see
Figure 2b). Participants were faster to visually fixate the target than indicate they had
detected the target via a manual response (paired t-test: t = 44.1, p < 0.0001).
In both the natural matrices and the matrices that minimized low-level features,
participants looked at a greater number of distractor images (see No. of Different
Distractors Fixated, Table 1H-K; see Figure 3) and spent more time looking at each
distractor image (see Time Viewing Distractors, Table 1H-K; see Figure 4) when the
distractors were dangerous animals compared with nondangerous animals. Participants
looked at fewer distractors (see No. of Different Distractors Fixated, Table 1L-O; see
Figure 3) and spent less time looking at each distractor (see Time Viewing Distractors,
Table 1L-O; see Figure 4) for a given target in the natural matrices compared with the
matrices matched for luminance and spatial frequency.
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -541-
Table 1. The effect of animal class, danger level, and image type on the latency to locate
the target (via fixations and manual responses), number of different distractors fixated, and
time viewing each distractor
Latency to
Fixate Target
Animal
Latency to
Manual
Response
No. of Different
Distractors
Fixated
Time
Viewing
Distractors
Overall
Model
A
Animal Class 52.1* 74.9* 44.1* 68.2*
B
Danger Level 207.9* 284.6* 222.4* 135.7*
C
Image Type 474.5* 353.5* 464.9* 458.2*
D Animal Class ×
Danger Level
4.5 (0.04) 0.01 (0.93) 0.39 (0.53) 1.5 (0.23)
E Animal Class ×
Image Type
3.3 (0.08) 33.2* 0.70 (0.41)
15.2
(0.0003)
F Danger Level ×
Image Type
1.4 (0.24) 3.6 (0.06) 0.02 (0.89) 7.27 (0.009)
G Animal Class ×
Danger Level ×
Image Type
0.09 (0.76) 0.01 (0.94) 0.01 (0.92) 0.15 (0.70)
Comparisons
H
Lion vs. Impala 10.5* [1.49] 12.4* [1.12] 9.0* [0.96] 6.0* [0.48]
I Lion Low Level
Control vs. Impala
Low Level Control
8.2* [1.10] 11.1* [1.08] 8.1* [0.96] 6.0* [0.76]
J
Snake vs. Lizard 5.7* [0.70] 6.7* [0.70] 7.5* [0.92] 6.9* [0.68]
K Snake Low Level
Control vs. Lizard
Low Level Control
6.3* [0.79] 6.8* [0.58] 6.5* [0.91] 6.9* [0.73]
L Lion vs. Lion Low
Level Control
11.8* [1.70] 13.7* [1.41] 11.4* [1.40] 8.5* [1.10]
M Impala vs. Impala
Low Level Control
10.5* [1.30] 13.3* [1.41] 13.0* [1.25] 13.6* [1.29]
N Snake vs. Snake
Low Level Control
12.3* [1.27] 10.8* [1.17] 10.3* [1.26] 12.7* [1.37]
O Lizard vs. Lizard
Low Level Control
11.1* [1.57] 12.4* [1.25] 9.9* [1.21] 16.2* [1.65]
Note. F values are displayed; p-values are indicated in parentheses unless the result is highly statistically
significant (p < 0.0001) and thus indicated with an asterisk. Effect size (Cohen's d) is reported in brackets.
The numerator degrees of freedom is 1 and the denominator degrees of freedom is 59 in all tests.
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -542-
Figure 2. The latency to (a) first fixate the target animal and (b) manually respond (key
press) after detecting the target animal
a.
b.
Note. Means and standard-error bars are shown; horizontal lines indicate planned comparisons and all
comparisons were statistically significant (p < 0.0001).
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -543-
Figure 3. Number of dangerous and nondangerous animal distractors fixated
Note. The number of different distractors fixated with respect to the treatment block is displayed. Means and
standard-error bars are shown; horizontal lines indicate planned comparisons and all comparisons were
statistically significant (p < 0.0001).
Figure 4. Duration of time spent looking at animal distractors
Note. The amount of time spent looking at each distractor with respect to the treatment block is displayed.
Means and standard-error bars are shown; horizontal lines indicate planned comparisons and all comparisons
were statistically significant (p < 0.0001).
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -544-
Discussion
We found that participants visually detected dangerous animals (snakes and lions)
faster than nondangerous animals (lizards and impalas). These results are consistent with
previous studies showing that humans (including infants, children, and adults) are quicker
to detect dangerous compared with nondangerous animals (Blanchette, 2006; Brosch and
Sharma, 2005; Flykt, 2005; LoBue and DeLoache, 2008, 2010; Öhman et al., 2001;
Penkunas and Coss, 2013a,b; Rosa et al., 2011; Waters et al., 2004). Unlike these previous
studies (but see LoBue and DeLoache, 2010; Rosa et al., 2011), we quantified detection
based on eye movements as well as manual responses (a key press). Eye movements are a
more ecologically valid method of assessing attention than manual responses. When
humans detect potentially dangerous situations, they orient their eyes to the danger before
they respond manually (Bannerman, Milders, de Gelder, and Sahraie, 2009). Indeed, the
latency to detect animals, both dangerous and nondangerous, in our study was at least 52%
faster based on eye movement patterns compared to manual responses.
In addition, we found that adults were quicker to detect dangerous animals even
when some low-level features of the images (spatial frequency and luminance) were
controlled. Low-level features can influence attention through bottom-up processing, in
which properties of the image exogenously capture attention (James, 1890). For example,
spatial frequency (large changes in intensity; Mannan, Ruddock, and Wooding, 1997),
color, form, and luminance (Turatto and Galfano, 2000) can automatically attract attention.
Because the participants in our study were faster to detect dangerous animals compared
with nondangerous animals, even after controlling for spatial frequency and luminance,
these low-level features were not driving the ability of humans to detect danger rapidly.
Similarly, previous studies also reported that adults and children detected dangerous
animals faster than nondangerous animals even when the images were gray-scale (Flykt,
2005; Hayakawa, Kawai, and Masataka, 2011). Importantly, we found that humans were
slower to detect both dangerous and nondangerous animals when these low-level features
were controlled, suggesting that these low-level features can generally aid in detection but
are not specific to detecting dangerous animals.
The perceptual processes by which humans rapidly detect danger in natural settings
are largely unexplored. One hypothesis is that dangerous objects are particularly effective
at maintaining attention or "delaying disengagement" during visual search (Fox et al.,
2002). In further support of this hypothesis, studies generally find that fearful and angry
faces attract more attention than neutral or happy ones (Bannerman et al., 2009; Belopolsky
et al., 2012). Our results provide support for the delayed-disengagement hypothesis. We
found that adults detected nondangerous animals slower than dangerous animals because
they spent more time looking at each of the dangerous (distractor) images (i.e., they were
slower to disengage their attention from the dangerous animals). This suggests that it is
critical for humans to fixate dangerous animals so that they can assess levels of threat.
A second hypothesis explaining why humans rapidly detect danger is that
dangerous animals exogenously attract attention based on their low-level features (Öhman,
1986; Simons, 2000). Although our results indicated that some low-level features (spatial
frequency and luminance) do not affect humans' ability to detect dangerous animals (see
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -545-
above), additional low-level features may influence detection. For example, the shape of
some dangerous animals may exogenously draw attention. LoBue and DeLoache (2011)
found that the coiled shape of snakes facilitated detection. Our results are in agreement
with this attentional-capture hypothesis because participants looked at a larger number of
dangerous (distractor) animals when searching for nondangerous animals, indicating that
the dangerous animals drew attention even though the participants were searching for
nondangerous animals. Therefore, in the context of the current study presenting animal
images, humans appear to assess levels of danger rapidly in their surroundings because they
(i) spend more time looking at dangerous animals (delayed disengagement) and (ii) detect
dangerous animals through salient visual features.
Because primates, including humans, have experienced predation for millions of
years, selection has likely shaped their antipredator behaviors (Coss and Ramakrishnan,
2000; Hart and Sussman, 2005; Isbell, 2006; Stanford, 2002). Primates exhibit intense
antipredator responses that involve emitting alarm calls, increasing vigilance levels,
avoidance, piloerection, and mobbing or attacking predators (Caro, 2005; Isbell, 1994).
Individuals sometimes display these antipredator behaviors in response to predators that
they have never even seen before (reviewed in Yorzinski, 2010). In particular, humans
often react with fear and increase their attention toward dangerous animals, a process that is
mediated by the amygdala and hippocampus and then modulated by cortical areas for
regulating action (Lovett-Barron et al., 2014; Öhman, 2005). It is likely beneficial for
animals, including humans, to increase their attention toward potential threats so they can
respond appropriately (Cresswell, Butler, Whittingham, and Quinn, 2008). Future eye-
tracking experiments could examine the relationship between visual attention and predator
detection in children to better understand the development of visual biases in humans.
Acknowledgements: We thank the Department of Psychology and Neuroscience at Duke
University for letting us use the eye-tracker and Matt Mielke for technical assistance. This
research was supported by RGC as part of a series on predator recognition in different
species.
Received 07 March 2014; Revision submitted 21 April 2014; Accepted 21 April 2014
References
Bannerman, R. L., Milders, M., de Gelder, B., and Sahraie, A. (2009). Orienting to threat:
Faster localization of fearful facial expressions and body postures revealed by
saccadic eye movements. Proceedings of the Royal Society B, 276, 1635-1641.
Belopolsky, A. V., Devue, C., and Theeuwes, J. (2012). Angry faces hold the eyes. Visual
Cognition, 19, 27-36.
Blanchette, I. (2006). Snakes, spiders, guns, and syringes: How specific are evolutionary
constraints on the detection of threatening stimuli? Quarterly Journal of
Experimental Psychology, 59, 1484-1504.
Brosch, T., and Sharma, D. (2005). The role of fear-relevant stimuli in visual search: A
comparison of phylogenetic and ontogenetic stimuli. Emotion, 5, 360-364.
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -546-
Caro, T. (2005). Antipredator defenses in birds and mammals. Chicago: University of
Chicago Press.
Coss, R. G. (2003). The role of evolved perceptual biases in art and design. In E. Voland
and K. Grammer (Eds.), Evolutionary aesthetics (pp. 69-130). Heidelberg:
Springer-Verlag.
Coss, R. G., Fitzhugh, E. L., Schmid-Holmes, S., Kenyon, M. W., and Etling, K. (2009).
The effects of human age, group composition, and behavior on the likelihood of
being injured by attacking pumas. Anthrozoös, 22, 77-87.
Coss, R. G., and Moore, M. (2002). Precocious knowledge of trees as antipredator refuge in
preschool children: An examination of aesthetics, attributive judgments, and relic
sexual dinichism. Ecological Psychology, 14, 181-222.
Coss, R. G., and Ramakrishnan, U. (2000). Perceptual aspects of leopard recognition by
wild bonnet macaques (Macaca radiata). Behaviour, 137, 315-335.
Cresswell, W., Butler, S., Whittingham, M. J., and Quinn, J. L. (2008). Very short delays
prior to escape from potential predators may function efficiently as adaptive risk-
assessment periods. Behaviour, 146, 795-813.
Cronin, T. W. (2005). The visual ecology of predator-prey interactions. In Ecology of
predator-prey interactions. New York: Oxford University Press.
Dukas, R. and Kamil, A. C. (2000). The cost of limited attention in blue jays. Behavioral
Ecology, 11, 502-506.
Flykt, A. (2005). Visual search with biological threat stimuli: Accuracy, reaction times, and
heart rate changes. Emotion, 5, 349-353.
Fox, E., Griggs, L., and Mouchlianitis, E. (2007). The detection of fear-relevant stimuli:
Are guns noticed as quickly as snakes? Emotion, 7, 691-696.
Fox, E., Russo, R., and Dutton, K. (2002). Attentional basis for threat: Evidence for
delayed disengagement from emotional faces. Cognition and Emotion, 16, 355-379.
Gerdes, A. B. M., Pauli, P., and Alpers, G. W. (2009). Toward and away from spiders: Eye-
movements in spider-fearful participants. Journal of Neural Transmission, 116,
725-733.
Hart, D., and Sussman, R. W. (2005). Man the hunted: Primates, predators, and human
evolution. New York: Westview Press.
Hayakawa, S., Kawai, N., and Masataka, N. (2011). The influence of color on snake
detection in visual search in human children. Scientific Reports, 1, 1-4.
Headland, T. N., and Greene, H. W. (2011). Hunter­gatherers and other primates as prey,
predators, and competitors of snakes. Proceedings of the National Academy of
Sciences, 108, E1470­E1474.
Huijding, J., Mayer, B., and Koster, E. H. W. (2011). To look or not to look: An eye
movement study of hypervigilance during change detection in high and low spider
fearful students. Emotion, 11, 666-674.
Isbell, L. A. (1994). Predation on primates: Ecological patterns and evolutionary
consequences. Evolutionary Anthropology, 3, 61-71.
Isbell, L. A. (2006). Snakes as agents of evolutionary change in primate brains. Journal of
Human Evolution, 51, 1-35.
James, W. (1890). The principles of psychology. Cambridge: Harvard University Press.
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -547-
LoBue, V., and DeLoache, J. S. (2008). Detecting the snake in the grass: Attention to fear-
relevant stimuli by adults and young children. Psychological Science, 19, 284-289.
LoBue, V., and DeLoache, J. S. (2010). Superior detection of threat-relevant stimuli in
infancy. Developmental Science, 13, 221-228.
LoBue, V., and DeLoache, J. S. (2011). What's so special about slithering serpents?
Children and adults rapidly detect snakes based on their simple features. Visual
Cognition, 19, 129-143.
Lovett-Barron, M., Kaifosh, P., Kheirbek, M. A., Danielson, N., Zaremba, J. D., Reardon,
T. R., . . . Losonczy, A. (2014). Dendritic inhibition in the hippocampus supports
fear learning. Science, 343, 857-863.
Mannan, S. K., Ruddock, K. H., and Wooding, D. S. (1997). Fixation patterns made during
brief examination of two-dimensional images. Perception, 26, 1059-1072.
Nummenmaa, L., Hyona, J., and Calvo, M. G. (2006). Eye movement assessment of
selective attentional capture by emotional pictures. Emotion, 6, 257-268.
Öhman, A. (1986). Face the beast and fear the face: Animal and social fears as prototypes
for evolutionary analyses of emotion. Psychophysiology, 23, 123-145.
Öhman, A. (2005). The role of the amygdala in human fear: Automatic detection of threat.
Psychoneuroendocrinology, 30, 953-958.
Öhman, A., Flykt, A., and Esteves, F. (2001). Emotion drives attention: Detecting the snake
in the grass. Journal of Experimental Psychology: General, 130, 466-478.
Penkunas, M. J., and Coss, R. G. (2013a). Rapid detection of visually provocative animals
by preschool children and adults. Journal of Experimental Child Psychology, 114,
522-536.
Penkunas, M. J., and Coss, R. G. (2013b). A comparison of rural and urban Indian
children's visual detection of threatening and nonthreatening animals.
Developmental Science, 16, 463-475.
Reinholdt-Dunne, M. L., Mogg, K., Benson, V., Bradley, B. P., Hardin, M. G., Liversedge,
S. P., . . . Ernst, M. (2012). Anxiety and selective attention to angry faces: An
antisaccade study. Journal of Cognitive Psychology, 24, 54-65.
Rosa, P. J., Gamito, P., Oliveira, J., Morais, D., and Saraiva, T. (2011). Attentional
orienting to biologically fear-relevant stimuli: Data from eye tracking using the
continual alternation flicker paradigm. Journal of Eyetracking, Visual Cognition
and Emotion, 1, 22-29.
Simons, D. J. (2000). Attentional capture and inattentional blindness. Trends in Cognitive
Sciences, 4, 147-155.
Stanford, C. B. (2002). Avoiding predators: Expectations and evidence in primate
antipredator behavior. International Journal of Primatology, 23, 741-757.
Treves, A., and Palmqvist, P. (2007). Reconstructing hominin interactions with mammalian
carnivores (6.0­1.8 Ma). In K. A. I. Nekaris and S. L. Gursky (Eds.), Primates and
their predators (pp. 355-381). New York: Springer.
Turatto, M., and Galfano, G. (2000). Color, form, and luminance capture attention in visual
search. Vision Research, 40, 1639-1643.
Waters, A. M., Lipp, O. V., and Spence, S. H. (2004). Attentional bias toward fear-related
stimuli: An investigation with nonselected children and adults and children with
Human attention to dangerous animals
Evolutionary Psychology ­ ISSN 1474-7049 ­ Volume 12(3). 2014. -548-
anxiety disorders. Journal of Experimental Child Psychology, 89, 320-337.
Willenbockel, V., Sadr, J., Fiset, D., Horne, G. O., Gosselin, F., and Tanaka, J. W. (2010).
Controlling low-level image properties: The SHINE toolbox. Behaviour Research
Methods, 42, 671-684.
Yorzinski, J. L. (2010). Predator recognition in the absence of selection. In S. Gursky-
Doyen and J. Supriatna (Eds.), Indonesian primates, developments in primatology:
Progress and prospects. New York: Springer.
Yorzinski, J. L., Patricelli, G. L., Babcock, J., Pearson, J. M., and Platt, M. L. (2013).
Through their eyes: Selective attention in peahens during courtship. Journal of
Experimental Biology, 216, 3035-3046.
Yorzinski, J. L., and Platt, M. L. (2014). Selective attention in peacocks during predator
detection. Animal Cognition, 17, 767-777.
