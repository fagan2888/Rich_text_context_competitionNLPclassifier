Research and Politics
October-December 2014: 1
­10
© The Author(s) 2014
DOI: 10.1177/2053168014559094
rap.sagepub.com
Creative Commons NonCommercial-NoDerivs CC-BY-NC-ND: This article is distributed under the terms of the Creative
Commons Attribution-NonCommercial-NoDerivs 3.0 License (http://www.creativecommons.org/licenses/by-nc-nd/3.0/) which
permits non-commercial use, reproduction and distribution of the work as published without adaptation or alteration, without further permission
provided the original work is attributed as specified on the SAGE and Open Access pages (http://www.uk.sagepub.com/aboutus/openaccess.htm).
Introduction
The impact of regime type on welfare outcomes is a topic
of great importance. Against the prevailing consensus, a
recent study finds "little evidence that the rise of democ-
racy contributed to the fall in infant and child mortality
rates" in the period between 1970 and 2000 (Ross, 2006:
872).1 According to the study, the negative association
between democracy and infant and child mortality reported
in previous studies disappears once corrections are made
for additive, time-invariant, unobserved heterogeneity;
common time trends; and selection bias from listwise dele-
tion. Here, I report results from a procedural replication of
this finding. I show this null result is an artifact of a highly
restrictive dynamic specification. I also find that concerns
about selection bias in previous studies may have been
overstated. Finally, I document sources of errors and omis-
sions in a checklist that scholars can use to assess the reli-
ability of new or existing studies, guide editorial reviews,
and make scientific knowledge production more reliable.
Ross's (2006) null finding has wide ranging theoretical,
policy, and practical implications. It questions core theories of
representation, electoral accountability, and redistribution
(Boix, 2003; Bueno de Mesquita et al., 2003b; Lake and Baum,
2001; Meltzer and Richard, 1983); and it questions democra-
cy's constructive and direct roles in the conceptualization and
satisfaction of needs (Sen, 2000). It also provides evidence
against the desirability of political conditionality in foreign aid
(Alesina and Dollar, 2000; Crawford, 1997). Moreover, by ton-
ing down the perceived accomplishments of democracy, it can
also influence the very process of democratization via problem
definition (Rochefort and Cobb, 1993), preference formation
(Druckman and Lupia, 2000), and political persuasion (Cobb
and Kuklinski, 1997).As a testament to this importance, Ross's
(2006) study has been cited over 300 times.2
Replication studies remain highly controversial. One rea-
son for this is that social scientists disagree on what constitutes
a replication study, how they are done, and for what purpose
(Anderson et al., 2008; Berthon et al., 2002; Bueno de
Mesquita et al., 2003a; Burman et al., 2010; Gelman, 2013;
Herrnson, 1995; Ishiyama, 2014; King, 1995; McCullough
et al., 2008; Schmidt, 2009). For example, many scholars are
adamant that replication studies should make a substantive ­
as opposed to procedural ­ contribution. In this view
replications are completely uninteresting unless accompanied
Democracy is good for the poor: A
procedural replication of Ross (2006)
Fernando Martel García
Abstract
Here I propose procedural replication as a method for diagnosing errors and omissions and identifying research artifacts
in published studies. The goal of procedural replication is not to make substantive contributions so much as improve
research practice, or how scientists go about doing science. This is accomplished by generating checklists of lessons
learned that scholars can use to assess the reliability of new or existing studies, guide editorial reviews, and make
scientific knowledge production more reliable. I demonstrate the method by implementing a procedural replication of
Michael Ross's controversial finding that democracy has no effect on child mortality. I find this null finding is an artifact
of the way five-year averages were computed and the static nature of the preferred model. I demonstrate, using causal
diagrams, how concerns about listwise deletion and selection bias affecting previous studies may have been overstated.
I also provide a checklist with lessons learned.
Keywords
procedural replication, experimental artifact, procedural errors, checklists, scientific standards, causal inference,
observational studies, democracy, infant mortality
Manager, Cambridge Social Science Decision Lab Inc. Washington, DC, USA
Corresponding author:
Fernando Martel García, Manager, Cambridge Social Science Decision Lab
Inc. 2020 Pennsylvania Ave. N.W., #820 Washington D.C. 20006, USA.
Email: fmg229@nyu.edu
559094
RAP0010.1177/2053168014559094Research & PoliticsMartel García
research-article2014
Research Article
2 Research and Politics 
by a new discovery. Yet from the point of view of research
practice, or the study of how scientists do science, a primary
goal of replication studies is to identify research artifacts, diag-
nose sources of errors and omissions, and document lessons
learned through checklists, guidelines, and assessment scales.3
It is a mistake to think all replication studies should make
a substantive contribution. First, such replication studies often
struggle with the question of where the replication ends, and
a new study begins.After all, most scientific studies are noth-
ing but replication studies with extensions and new findings
(King, 2006: 1). Second, replication studies that aim to make
a substantive contribution often relegate the details of the rep-
lication ­ what went wrong and lessons learned ­ to a foot-
note, thus forsaking an opportunity to inform and improve
research practice. Third, these studies often focus on conten-
tious solutions rather than on diagnosing errors and omis-
sions, yet diagnosis is central to prevention and remediation.
For example, procedural checklists can help bring problem-
atic areas to the attention of researchers and reviewers, whilst
avoiding contentious debates about specific solutions that are
best resolved in the context of specific applications.
Here I introduce procedural replication, a formal
method to diagnose errors and omissions, identify research
artifacts, and contribute new (or improved) checklists that
scholars can use to inform future research, streamline edi-
torial reviews, and improve research practice. The replica-
tion proceeds in two steps. First, I conduct a pure replication
to infer the exact procedures and technologies, or scientific
standard, used in producing the original study outputs.
Second, I undertake a critical evaluation of the inferred
standard, including a checklist to prevent future errors and
omissions. The focus of the evaluation step is on "what to
look out for," not what an ideal study would do; and on
problematic areas rather than contentious solutions.
Standard replication studies aim to make substantive con-
tributions by changing data, model specifications, estima-
tors or inference procedures. By contrast, procedural
replications aim to improve research practice and the reli-
ability of scientific knowledge production by reporting
sources of errors and omissions.
This case-study in research practice proceeds as follows.
The section titled "Data" describes the data in the replica-
tion file. "Pure replication" presents results from a pure
replication, including inferences about the scientific stand-
ard used in the original study. "Diagnosing errors and omis-
sions in the inferred scientific standard" demonstrates how
a minor change to the way quinquennial averages are com-
puted is enough to reverse the null finding, and how con-
cerns about selection bias from listwise deletion may be
overblown. The article ends with "Conclusion."
Data
In response to a request for replication materials for Ross's
(2006) study "Is democracy good for the poor?" the author
kindly provided the following: (1) a raw annual frequency
data set; (2) a quinquennial frequency data set used in the
analysis (the dependent variable is only available every five
to 10 years so all annual data are collapsed to quinquennial
frequency); and (3) five quinquennial frequency multiply
imputed data sets. The estimation results using the quin-
quennial frequency data and the multiply imputed data
were sourced from the published manuscript. The original
computer code, random seed for multiple imputation, and
other elements of the procedures used to generate the esti-
mates could not be obtained. Even so, judging from infor-
mation in the published paper and replication file I infer
that the principal software platforms used were Stata, R (R
Core Team, 2013), and Amelia I (King et al., 2001). The
exact version of each could not be determined.
Pure replication
The objective of a pure replication is to infer the exact pro-
cedures and technologies used in the original article and to
document potential errors and omissions. These are then
diagnosed further at the evaluation stage (see "Diagnosing
errors..."). The pure replication was done in three steps.
First, I reproduced the quinquennial frequency estimation
data from the raw annual data using the exact same proce-
dures reported in the original article. Next, I tried to repro-
duce the listwise deleted estimation results. Finally, I did
the same with multiply imputed data and results. I report
the findings from each step below.
Replicating the estimation dataset
First,theavailablereplicationdataareincomplete.Collapsing
the raw annual data into quinquennia by computing five-year
averages I was unable to replicate the key measure of
democracy ­ the polity variable ­ in the quinquennial estima-
tion data set.4 In addition, the adult HIV prevalence and dem-
ocratic years variables were both missing from the annual
dataset, so I could not replicate their quinquennial averages
in the estimation dataset. All other variables in the original
quinquennial frequency dataset could be replicated from the
annual data with the exception of real GDP (gross domestic
product) per capita, where I found minor differences for the
UK, Greece, Ireland and Thailand between the quinquennial
data in the replication file, and the corresponding five-year
averages I computed from the annual data.
Second, the original study computes quinquennial data
using a forward average. As shown in "Diagnosing
errors..." this can severely dampen the estimated effect of
democracy on child and infant mortality. For example,
mortality data for the 1970 quinquennium refers to mortal-
ity in the year 1970. These data are regressed on the Polity
data for the 1965 quinquennium. However, the latter is
computed as a forward average for the years 1965­1969,
which is centered in 1967, and not the centered average for
the years 1963­1967, which centered in 1965. This is closer
to a three year than a five year lag.
Martel García 3
Third, the original study's criteria for defining the pop-
ulation of interest ­ sovereign countries having a popula-
tion larger than 200,000 ­ are ambiguous. In effect the
study uses an artificially balanced panel of 169 countries
for the quinquennia 1970, 1975, ..., 2000 (see Table 1).
This panel excludes extinct countries (like the USSR) and
includes extrapolations for non-sovereign country years
(like Ukraine prior to 1989). As a result, the original study
sample contains 14% more annual "observations" than
Przeworski et al.'s (2000) unbalanced panel of sovereign
country years, which, by recording history as it happened,
avoids extrapolations and includes deceased entities. As
shown in "Diagnosing errors...," the extra observations in
artificially balanced panels can inadvertently deflate stand-
ard errors.5
Fourth, the original study did not use the available
data efficiently or consistently. With two exceptions, all
annual data prior to 1970 were discarded before comput-
ing the quinquennial averages and their lagged values.6
Consequently all lagged values for the 1970 quinquennia,
which refer to 1965­1969, are missing even if annual
data are available for these years. Some of these observa-
tions were then imputed manually before multiple impu-
tation (see Table 2).
Using the quinquennial data in the replication file, I was
able to replicate exactly the listwise deleted results reported
in Table 3 of the original study (Ross, 2006: 869). However,
I found both the R2 and dependent variable are misreported.
The reported R2 measures the overall as opposed to the
within-country variation.7 Furthermore, the dependent vari-
able used in Tables 3 and 4 of the original study is not
UNICEF's child mortality rate (Ross, 2006: 866), but rather
the World Bank's under-five mortality rate, which has the
most missing cells.
Replicating the multiply imputed estimates
I could not replicate exactly the multiply imputed data and
estimates because the replication file does not include a
random seed for the imputations. Even so, I found missing
data were imputed inconsistently. For example, quinquen-
nial averages were computed ignoring missing observa-
tions (a form of imputation); lagged values of the dependent
variable in the first period were manually imputed using the
actual observation in that period; and the key independent
variable, polity, was never included in the imputation
model.8 Moreover, the imputation software available at the
time ignored time dependency (King et al., 2001).
Diagnosing errors and omissions in the
inferred scientific standard
The pure replication in the previous section helped me par-
tially infer the combination of technological inputs and pro-
cedures (or scientific standard) used in the original study.
Here, I diagnose potential errors and omissions. The objec-
tive is to learn from mistakes, assess their impact, and pro-
pose preventive measures, not to make a substantive
contribution about regime type and human welfare by
changing data sources, model specification, estimators, or
inferential procedures.
Relaxing the dynamic specification in the
observed dataset
The original study's preferred two-way fixed effect model
specification includes only one lag of polity, and no interac-
tions with time. Combined with the forward quinquennial
averages, this imposes severe dynamic restrictions.
Table 1. Summary statistics for Ross's quinquennial data set, 1970­2000.
Variable Obs. Missing % Mean Std. Dev. Min. Max.
Log under-five mortality 821 30.6 4.0 1.2 1.4 6.0
Small state dummy 1183 0.0 0.1 0.3 0.0 1.0
Lagged variables
Log under-five mortality 808 31.7 4.2 1.1 1.4 6.0
Log infant mortality (UNICEF) 770 34.9 3.9 1.0 1.4 5.4
Log infant mortality (WB) 656 44.5 3.8 1.0 1.4 5.4
Log GDP per capita 783 33.8 8.2 1.1 5.7 10.7
Log adult HIV prevalence 999 15.6 0.2 0.5 0.0 3.3
Log population density 906 23.4 3.7 1.5 -0.2 8.7
Real GDP growth 851 28.1 3.2 4.9 -42.5 35.6
Polity 1129 4.6 -0.6 7.3 -10.0 10.0
Log democratic years 1008 14.8 1.4 1.7 0.0 4.6
Data for 169 countries observed over the quinquennia 1970, 1975, ..., 2000. In general data are forward quinquennial averages of annual data (e.g.
the quinquennial datum for 1970 is the arithmetic average of the log annual data for the years 1970­1974 inclusive). These averages are computed
ignoring missing values. Over 30% of mortality data from various sources are observed as missing in the quinquennial data. The equivalent figure for
the annual data is 80%. Lagged variables are lagged one quinquennium.
WB: World Bank; GDP: gross domestic product
4 Research and Politics 
As formulated, the original study asks not whether democ-
racy has an effect ­ any effect ­ on infant and child mortal-
ity, but whether it has a constant additive effect in the first
three years after a transition. Few social scientists would
expect democracy to have a substantive impact in such a
short period, yet the original study provides no theoretical
justifications for this choice. This is all the more puzzling
considering that most econometric textbooks highlight the
flexibility of panel data in characterizing dynamic effects
(e.g. Baltagi, 2001: 6).
For example, in the preferred two-way fixed effects
model specification the outcome for 1975 is given by yi
,1975
=  i
+ polityi,1970
+ xi,1970
 + i
,1975
, where polity is lagged
one quinquennia, and the penultimate term is a vector of
lagged covariates and time dummies. First, the quinquennial
lag is computed as Polity Polity
i i t
t
, ,
{ , , }
.
1970
1
5 1970 19711974
=


This is centered in 1972 rather than 1970, which is closer to
a three-year than a five-year lag. Second, because the pre-
ferred model specification includes only one lag but no
interactions with time, it rules out ­ by assumption ­ any
dynamic adjustment, long-run effects, and changes to the
rate of mortality decline. That is, the model assumes democ-
racy only has a constant additive effect on mortality in the
first three years or so after a transition, and not thereafter.
This is an extremely restrictive assumption.
The dynamic restrictions are so severe that even a
minor relaxation, like computing centered quinquennial
averages (which allow for a slightly longer lagged effect),
is enough to reverse the null findings in the original study.
To show this separate from the multiple imputation I rep-
licated the listwise deleted estimation results in Table 3 of
the original study, replacing the forward quinquennial
data in the original estimation with centered quinquennia.
I also used Przeworski et al.'s (2000) unbalanced panel of
sovereign country years.9 Using the exact same two-way
fixed effect specification in the published table ­ the
study's preferred specification ­ I obtained a point esti-
mate of -0.005 (s.e. 0.002). This is statistically and practi-
cally significant, and about twice as large as the published
estimate (­0.0021 (s.e. 0.002)). For example, a movement
of 10 points in the polity variable implies a 5% average
decline in child mortality after five years (95% CI: ­9.4 to
-1.3%).
To check that this was not a result of using a different
population, I replaced Przeworski et al.'s (2000) unbal-
anced panel of sovereign country years with the original
study's artificially balanced panel. The result is an almost
identical estimate (­0.0054; s.e. 0.002). Relaxing the
dynamic specification further, by adding an extra lag of
polity or an interaction with a linear time trend, also yielded
practically and statistically significant results. These results
underscore the importance of omitted dynamics in generat-
ing the original study's null result.
Relaxing the dynamic specification in the
multiply imputed dataset
The original study claims previous significant findings may
have been biased by missing data. Specifically, listwise
deletion drops rich autocracies with enviable records in
reducing mortality from the sample, thus biasing the esti-
mated effect in favor of democracies. Assuming this bias is
removed by multiply imputing the missing data and con-
trolling for two-way fixed effects, the original article
showed democracy has a negligible effect on mortality. In
what follows I show the claim about selection bias has
weak theoretical support. The null result in the original
study is an artifact of the extremely restrictive dynamic
Table 2. Summary statistics for Ross's quinquennial data set, 1970.
Variable Obs. Missing % Mean Std. Dev. Min. Max.
Log under-five mortality 154 8.9 4.5 0.9 2.6 6.1
Small state dummy 169 0.0 0.1 0.3 0.0 1.0
Lagged variables 
Log under-five mortality 154 8.9 4.5 0.9 2.6 6.0
Log infant mortality (UNICEF) 0 100.0 ­ ­ ­ ­
Log infant mortality (WB) 0 100.0 ­ ­ ­ ­
Log GDP per capita 0 100.0 ­ ­ ­ ­
Log adult HIV prevalence 0 100.0 ­ ­ ­ ­
Log population density 0 100.0 ­ ­ ­ ­
Real GDP growth 0 100.0 ­ ­ ­ ­
Polity 131 22.5 ­1.0 7.3 ­10.0 10.0
Log democratic years 0 100.0 ­ ­ ­ ­
Data for the first quinquennia (1970­1974) are missing for most regressors. The annual data set was truncated in 1970 before computing the lagged
quinquennial averages, with two exceptions. First, the quinquennial lag of polity was calculated before truncation. Second, the dependent variable
in 1970 and its lagged value are exactly identical because the former was used to manually impute the latter. For the other variables, truncating the
annual data before calculating the lags discards one-eighth of the cells, including UNICEF data on child and infant mortality for 1965.
WB: World Bank; GDP: gross domestic product
Martel García 5
specification, not the result of correcting selection bias in
previous studies.
First, the selection bias argument does not withstand
theoretical scrutiny. The fact that rich autocracies with
enviable declines in infant and child mortality are listwise
deleted from the estimation sample tells us nothing about
the effect of democracy on mortality. For all we know, their
declines could have been faster (or slower) had they been
democracies. Therefore the bias, if it exists, could go either
way. Besides, if selection is on the basis of income and
regime type, as the original study claims, then controlling
for these variables, like most previous studies do, should
help alleviate the bias. For example, suppose autocratic
regimes above a certain income threshold all drop out from
the sample. If the effect of democracy increases with
income, then the sample estimate will underestimate the
population effect. But the estimate will remain unbiased for
the countries in the sample, which in this case includes
most of the world. Figure 1 illustrates this logic using a
causal diagram.10
Second, the selection bias argument does not withstand
empirical scrutiny. For example, using centered quinquen-
nia, and a multiple imputation software better suited for
time dependence, I found democracy has a practical and
statistically significant effect on infant and child mortality,
as reported in Table 3.11 These results are very different
Table 3. Procedural replication of Ross's Table 4 (Ross, 2006: 869).
Log under-five mortality LDV LDV LDV FE LDV LDV FE
Log under-five mortality 0.981 0.97 0.955 0.974 0.959 
 (0.01) (0.009) (0.013) (0.009) (0.013) 
Log GDP per capita -0.062 -0.062 -0.069 -0.404 -0.061 -0.067 -0.399
 (0.013) (0.012) (0.012) (0.056) (0.013) (0.013) (0.057)
Log adult HIV prevalence 0.069 0.072 0.088 0.297 0.068 0.084 0.303
 (0.011) (0.011) (0.013) (0.036) (0.011) (0.014) (0.036)
Log population density -0.013 -0.013 -0.013 -0.122 -0.014 -0.014 -0.125
 (0.002) (0.002) (0.002) (0.104) (0.002) (0.002) (0.105)
GDP growth -0.005 -0.005 -0.005 0.001 -0.005 -0.005 0.002
 (0.002) (0.002) (0.002) (0.004) (0.002) (0.002) (0.004)
Polity -0.002** -0.003*** -0.008** 
 (0.001) (0.001) (0.003) 
Period 3 -0.043 -0.128 -0.042 -0.125
 (0.021) (0.026) (0.022) (0.026)
Period 4 -0.085 -0.29 -0.084 -0.285
 (0.02) (0.027) (0.021) (0.028)
Period 5 -0.059 -0.431 -0.058 -0.427
 (0.03) (0.047) (0.03) (0.048)
Period 6 -0.068 -0.65 -0.067 -0.648
 (0.025) (0.046) (0.026) (0.047)
Period 7 -0.069 -0.81 -0.068 -0.812
 (0.026) (0.056) (0.028) (0.059)
Period 8 -0.081 -0.975 -0.083 -0.989
 (0.026) (0.067) (0.027) (0.07)
Log democratic years -0.008*** -0.010*** -0.036
 (0.002) (0.002) (0.028)
Constant 0.475 0.521 0.693 8.221 0.509 0.685 8.253
 (0.149) (0.13) (0.154) (0.573) (0.132) (0.156) (0.574)
Observations (NT) 957 957 957 957 957 957 957
***Significantly different from zero at 99% confidence. Only noted for key independent variables.
**Significantly different from zero at 95% confidence. Only noted for key independent variables.
*Significantly different from zero at 90% confidence. Only noted for key independent variables.
These estimates were computed using a stricter definition of sovereign country years (Przeworski et al., 2000), centered quinquennial averages, and
the software package Amelia II for multiple imputation (see main text for further details). Both polity and democratic years are now highly statisti-
cally significant in all specifications except the last. By contrast, in the original study they are insignificant across all specifications. All regressors,
except period dummies, are lagged one quinquennia. The LDV specification uses panel corrected standard errors, assuming a panel-specific AR(1)
autocorrelation structure. The static fixed effects (FE) specification uses robust standard errors (although, in theory, these are not needed (Greene,
2008: 200)). Standard errors are in parentheses.
LDV: Lagged dependent variable; NT: Number of countries (N), Number of time periods (T), where NT= N x T; AR: Auto-regressive.
Source: Reproduced from Ross M (2006) Is democracy good for the poor? American Journal of Political Science 50(4): 860­874.
6 Research and Politics 
from the corresponding estimates in Table 4 of the original
study (Ross, 2006: 869). There none of the coefficients on
polity or democratic years is significant. By contrast, the
corresponding estimates reported in Table 3 are all practi-
cally and statistically significant, with the exception of
democratic years in the last column.
To further check the robustness of this results I repli-
cated Table 5 in the original study (Ross, 2006: 870). That
table reports the coefficients on polity when different mul-
tiply imputed measures of infant and child mortality are
used. I repeated the replication twice. Once using
Przeworski et al.'s (2000) unbalanced panel of sovereign
country years and centered quinquennia (top panel, Table
4), and again using the artificially balanced panel of sover-
eign country years and forward quinquennia from the origi-
nal study (bottom panel, Table 4).
First, using the original study's preferred two-way fixed
effect model I found polity is significant at the 10% level or
less whenever I used the centered quinquennia data (top
panel, last column of Table 4). However, using the forward
quinquennia I found all estimated coefficients are insignifi-
cant, and about half the size (bottom panel, last column).
Table 4. Procedural replication of Ross's Table 5 showing
the coefficients on polity across alternate multiply imputed
measures of infant and child mortality.
LDV LDV and period
dummies
FE and period
dummies
ACLP population of sovereign country years, centered quinquennial
averages
CMR WB -0.003** -0.003** -0.008**
 (0.001) (0.001) (0.003)
CMR UNICEF -0.002** -0.003*** -0.08**
 (0.001) (0.001) (-0.003)
CMR WHO -0.001 -0.001 -0.005*
 (-0.001) (0.001) (0.003)
IMR WB -0.002* -0.003** -0.006*
 (0.001) (0.001) (0.003)
IMR UNICEF -0.002 -0.002*** -0.006**
 (0.001) (0.001) (0.003)
NT 957 
Ross population of sovereign country years, forward quinquennial
averages
CMR WB -0.003*** -0.003*** -0.004
 (0.001) (0.001) (0.003)
CMR UNICEF -0.003** -0.003*** -0.003
 (0.001) (0.001) (0.003)
CMR WHO -0.003*** -0.004*** -0.002
 (0.001) (0.001) (0.003)
IMR WB -0.003*** -0.003*** -0.002
 (0.001) (0.001) (0.003)
IMR UNICEF -0.002*** -0.003*** -0.003
 (0.001) (0.001) (0.003)
NT 1183 
***Significantly different from zero at 99% confidence.
**Significantly different from zero at 95% confidence.
*Significantly different from zero at 90% confidence.
The top panel reports estimates using Przeworski et al.'s (2000) more
restrictive definition of sovereign country years, centered quinquen-
nial averages (so the quinquennial data for 1970 is the average of years
1968­1972), and corrections for other minor errors and omissions
(see main text). The bottom panel reports the same estimates using
the original study's population of sovereign country years, forward
quinquennial averages (so the quinquennial data for 1970 is the average
of years 1970­1975), and corrections for other minor errors and omis-
sions (see main text).
FE: fixed effects; CMR: child mortality rate; WB: World Bank; WHO:
World Health Organization; IMR: infant mortality rate
CLP: Przeworsky et al's (2000) dataset; LDV: Lagged dependent variable;
NT: Number of countries (N), Number of time periods (T), where
NT= N x T.
Source: Reproduced from Ross M (2006) Is democracy good for the
poor? American Journal of Political Science 50(4): 860­874.
U
t
t
t­1
t­1
R
GDP(t­1)
Figure 1. Simplified causal diagram illustrating the causes of the
outcome of interest, the missingness, and the selection through
listwise deletion. The graphical model assumes mortality is
caused by last period's regime type (polityt-1
), income (GPDt-1
),
and other unobserved causes (Ut
). For simplicity I assume GDPt-1
is the only variable with missing data. The missingness indicator
R
GDP
t-1
equals one whenever GDP is missing, and is zero
otherwise. Selection into the listwise deleted sample is on the
basis of missingness. Thus, Select equals one if an observation
is included in the listwise deleted sample (i.e. R
GDP
t-1
= 0), and
is zero otherwise (i.e. R
GDP
t-1
= 1). Conditioning the analysis on
Select = 1, a descendant of collider R
GDP
t-1
, opens a backdoor
path from polityt-1
to IMRt
via the missingness indicator and
income variables. However, conditioning on income blocks this
and other backdoor paths. If so the population experimental
distribution that would have been observed had polityt-1
been
randomized can be estimated ­ within income strata ­ using the
passively observed distribution (formally P (IMRt
|do (polityt-1
),
GDPt-1
, Select)  P(IMRt
|polityt-1
, GDPt-1
), where the operator
do (.) captures the notion of experimental manipulation).
From here, we can estimate the overall population effect if the
distribution of income in the selected sample overlaps with the
population distribution and if the population weights for the
strata are known. Otherwise we can only estimate the effect
within the selected sample.
GDP: gross domestic product; IMR: infant mortality rate
Martel García 7
Second, using the lagged dependent variable specifica-
tions I found most point estimates are similar and signifi-
cant, even when forward quinquennia are used (first two
columns of Table 4). This is because the lagged dependent
variable specification, though still very simple, allows for
short- and long-run effects. However, I found standard
errors are higher when using Przeworski et al.'s (2000)
stricter definition of sovereign country years (top panel)
compared to the original study's criteria (bottom panel).
The reason for this difference is that the stricter criteria
yield 957 observations, as opposed to the original study's
1183 observations. The latter treats observations for coun-
tries like Ukraine prior to 1989 as missing rather than unde-
fined. Multiply imputing these data may exaggerate the
amount of information in the dataset, thus underestimating
uncertainty.
I summarize the lessons from the pure replication in the
section "Pure replication" and the diagnosis and criticism
in "Diagnosing errors..." in a checklist (see Table 5). Such
a checklist can be used prospectively to help design more
effective studies on the impact of regime type on human
welfare. It can also be used retrospectively to assess the
quality of existing studies and as a quality control in the
peer review process.
Conclusion
Ross's (2006) controversial and widely cited finding that
democracy has no effect on child mortality is of momen-
tous significance. If true it has wide ranging theoretical,
policy, and practical implications. I replicated this study
using a procedural replication and found reasons to chal-
lenge it.
I found Ross's (2006) original null result is an artifact of
an extremely restrictive dynamic specification. The pre-
ferred static fixed effect model specification, combined
with forward quinquennial averages, assumes democracy
only has an additive effect on child or infant mortality
within the first three years or so after a transition ­ and not
thereafter. Few social scientists expect democracy to have a
substantive impact in such a short period. The restriction is
so severe that even a small change in the dynamic specifi-
cation, like using centered quinquennial averages that allow
for a five-year lag, is enough to detect practically and statis-
tically significant effects. The lesson here is that scholars
should think carefully about dynamics when estimating the
effect of democracy on mortality.
I also found the original study's concern over listwise
deletion and selection bias may have been overstated. Ross
(2006) claims previous significant findings are biased by
missing data. Specifically, listwise deletion drops rich autoc-
racies with excellent records in reducing mortality from the
sample, thereby biasing the estimated effect in favor of
democracies. However, the theoretical arguments and empir-
ical evidence presented here demonstrate that selection bias
may not have been such a problem after all. What is driving
the null result is the extremely restrictive dynamic specifica-
tion, not the presumed correction for selection bias in previ-
ous studies. I also found a more sound definition of the
population of interest yields better measures of uncertainty.
Finally, I showed how causal diagrams can be used to ana-
lyze selection bias and listwise deletion succinctly.
Here I have demonstrated the use of procedural replica-
tion. The objective of procedural replication is to diagnose
sources of errors and omissions, identify research artifacts,
and propose preventive measures including checklists to
Table 5. DEMOCHECK: A procedural checklist for studying the impact of democracy on human welfare.
Item Check
Procedures
Carefully consider the dynamic nature of the effect you are trying to estimate, and whether a static fixed effect
specification makes theoretical sense, is consistent with the data, and is robust.

Describe the population of interest, including the cross-sectional and time-wise criteria used for selection of
country-year units into the study, and be explicit about how you plan to deal with extinct countries, new countries,
mergers, and splits. Consider using Przeworski et al.'s (2000) unbalanced panel of sovereign country years.

Consider using a casual diagram to communicate easily and transparently the assumed causal structure generating the
outcome, the missing data, and the sample selection.

Exercise care in aggregating panel data to lower frequencies, and consider how that may affect the dynamic
interpretation of the estimates. Centered averages are often easier to interpret.

Form lags before truncating the data to a shorter period. 
Examine the time-wise and cross-sectional patterns of missingness. 
Use a random seed, like a verifiable public lottery number, for multiple imputations and include it in the replication file. 
Use the within estimator, rather than the least square dummy variable estimator, in fixed effect models to get a
more meaningful R2.

Software technologies
Report the software used and its release version in the main article or replication file. 
Consider using a multiple imputation software, like Amelia II, for data sets with time dependence. 
8 Research and Politics 
inform future research, streamline editorial reviews, and
improve cumulative research about the impact of regime
type on human welfare. In pursuing this objective I deliber-
ately avoided questioning the basic research design, choice
of measures, model specifications, estimators, inferential
techniques and other assumptions.12 Advocating alternative
choices and assumptions, and testing them, is the remit of
standard scientific studies, not procedural replications.
Indeed, it is a mistake to think all replication studies must
make a substantive contribution. The point of any conse-
quential scientific endeavor is not just to present novel
findings, but to actually answer existing questions reliably.
Procedural replication focuses squarely on improving our
answers to existing questions and so the method ought to be
as relevant as the questions are consequential.
Acknowledgement
I would like to thank Michael Ross for his kindness and generos-
ity in sharing his data, answering my questions, and providing
excellent constructive comments on earlier drafts of this manu-
script; Patrick Royston for kind help with the Stata package mim;
Neal Beck; anonymous reviewers; and the editors of Research &
Politics. All errors are my own.
Declaration of conflicting interest
The author declares that there is no conflict of interest.
Funding
This research received no specific grant from any funding agency
in the public, commercial, or not-for-profit sectors. The views
expressed are my own and not necessarily those of Cambridge
Social Science Decision Lab Inc.
Supplementary material
The replication files are available at: http://rap.sagepub.com/con-
tent/by/supplemental-data
Notes
 1. See Nelson (2007) andWigley andAkkoyunlu-Wigley (2011)
for reviews of the empirical literature. The child mortality
rate is the probability of a one year old dying before reaching
the age of five if subject to current age-specific mortality;
the infant mortality rate is the probability of an infant dying
before reaching one year of age; and the under-five mortality
rate is the probability of an infant dying before the age of
five (World Bank, 2008). The latter encompasses both infant
and child mortality. These probabilities are reported as the
number of deaths per 1000 live births.
 2. Google Scholar, accessed 18 August 2014.
3. In the health sciences, for instance, these have been used
to improve the reporting of scientific studies (Simera et al.,
2010), assess a study's susceptibility to bias (Higgins
et al., 2011; Moher et al., 1995; Olivo et al., 2008; Sanderson
et al., 2007), and review statistical methods (Gardner and
Bond, 1990). Turner et al. (2012: 1) find that journals endors-
ing the CONSORT statement for reporting randomized clini-
cal trials provide more complete reports of the randomized
controlled trials they publish, which is critical for assessing
the evidence. Political scientists have recently begun advo-
cating the use of checklists, as well (Boutron et al., 2010;
Gerber et al., 2009; Sovey and Green, 2011).
4. Of 1176 observations, 27% were different. Average differ-
ences were small but some observations were more than a
standard deviation away. The results presented herein are
robust to using either the quinquennial frequency version
of polity I generate from the annual frequency data, or the
original quinquennial frequency polity data provided in the
replication file.
 5. Other problems with artificially balanced panels may include
survivorship bias, double counting of the same political
entity, and nested counterfactuals (Pearl, 2009: 131) (e.g.
what would have happened had Ukraine been (a) a sovereign
country in 1970, and (b) made a transition to democracy?).
The original study tries to mitigate these issues by including
a dummy for countries in the former Soviet Union, but this
only allows for intercept shifts while ignoring extrapolation.
 6. Exceptionally, the quinquennial lag of polity was calculated
before truncation (though the data for 1965 to 1969 is miss-
ing from the annual dataset, so it cannot be replicated), and
the lagged child mortality rate in 1970 (referring to 1965)
was manually imputed after the fact using the observation
in 1970. As a result, both the actual and lagged values for
child and infant mortality in the 1970 quinquennia are iden-
tical. Furthermore, the lag of the HIV variable for 1970 is
missing even when the study assumes HIV to be zero prior
to 1980 (Ross, 2006: 867). This value should be zero, not
missing.
7. The original study uses a least squares dummy variable
(LSDV) estimator for the fixed effect model, so the reported
R2 of .99 is misleading. The preferred (within) R2 for the two-
way fixed effects model in column 4, Table 3, of the original
study (Ross, 2006: 869) is 0.62, as computed by the within
estimator (Greene, 2003). The R2 for the lagged dependent
variable specifications is also close to 1 because the pattern
of time-wise missing data is such that all time periods, except
the last two, are dropped from the estimation.
8. Had polity been imputed, the number of observations in
the first two columns in Table 4 of the original study (Ross,
2006: 869) would both have been the same. After all, column
1 reports a lagged dependent variable (LDV) model without
the polity variable, and column 2 the same exact model but
with polity added. Yet the number of observations differs by
the exact same number of missing polity observations in the
unimputed data set.
9. I also address the following minor issues: (1) I include
Cyprus, which in the original article was dropped from the
quinquennial data despite having annual data; (2) I take
the logs of the quinquennial averages and not the average
of the logs; (3) I replace all missing lagged observations of
the HIV variable in the first period with zeroes (the original
study assumes adult HIV prevalence prior to 1985 is 0, and
yet data for the 1970 quinquennia are missing because of the
way lags were created); (4) I create the quinquennial data
using all the years in the annual dataset, from 1965 to 2002;
(5) I replace the lagged values of the under-five mortality
rate in the first period with missing placeholders (the origi-
nal study manually imputed these using the actual value for
that quinquennia); (6) because I could not replicate the polity
Martel García 9
variable in the quinquennial dataset using the annual data,
I check results using the original study's quinquennial pol-
ity version, and my version computed with the annual data;
(7) the World Development Indicators (WDI) child mortal-
ity rate for Eritrea in 1970 is reported as 0, which is obvi-
ously a typo. I set it to missing; (8) democracy years and
adult HIV prevalence are not available in the annual dataset.
Consequently I append the (non-centered) averages from the
study's quinquennial dataset to my quinquennial data.
10. For a demonstration of the use of causal diagrams for missing
data see Martel García (2013a). Mohan et al. (2013) extend
these findings to more general patterns of missingness. For a
demonstration of how causal diagrams can be used to over-
come selection problems in the context of generalization see
Martel García (2013b). For a more general treatment see
Bareinboim et al. (2014).
11. In this section I multiply impute the quinquennial data
described above using the statistical software R ver-
sion 3.0.1 (built: 16 May 2013) together with the pack-
age Amelia II version 1.7-2 (built: 5 September 2013). I
use all the annual data from 1965 onwards in creating the
quinquennial data for imputation. I also include polity in
the imputation model. I do not include country dummies
in the model for two reasons. First, one can include fixed
effects in Amelia II by adding a polynomial of degree 0 and
interacting it with the cross section (Honaker et al., 2011).
Second, in a LDV specification fixed effects are implicit,
although adding country dummies allows for individual
trends. I tried the LDV fixed effects specification and
results are quite similar. I also include a lead and a lag of
all variables except the period dummies, add a 1% empiri-
cal prior to speed up convergence, and address problems of
multicollinearity with highly correlated variables (Honaker
et al., 2011). Convergence and stability of the imputation
model were checked by plotting densities and repeating the
multiple imputation using over dispersed values. Satisfied
by the diagnostic checks, I then replicated Tables 4 and 5
in the original study using the user written package mim
(Carlin et al., 2008; Royston et al., 2009, version st0139_1)
for Stata 10.1. The utility stacks the five imputed datasets
into a single file, and then computes estimates and appro-
priate standard errors.
12. I address these issues in Martel García (2012).
References
Alesina A and Dollar D (2000) Who gives foreign aid to whom
and why? Journal of Economic Growth 5: 33­63.
Anderson RG, Greene WH, McCullough BD, et al. (2008) The
role of data/code archives in the future of economic research.
Journal of Economic Methodology 15: 99­119.
Baltagi BH (2001) Econometric Analysis of Panel Data. New
York: John Wiley & Sons.
Bareinboim E, Tian J and Pearl J Recovering from Selection Bias
in Causal and Statistical Inference. AAAI Conference on
Artificial Intelligence, North America, jun. 2014. Available at:
<http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/
view/8628> (accessed 28 November 2014).
Berthon P, Pitt L, Ewing M, et al. (2002) Potential research space
in mis: A framework for envisioning and evaluating research
replication, extension, and generation. Information Systems
Research 13(4): 416­427.
Boix C (2003) Democracy and Redistribution. Cambridge stud-
ies in comparative politics. Cambridge, UK; New York:
Cambridge University Press.
Boutron I, John P and Torgerson DJ (2010) Reporting methodo-
logical items in randomized experiments in political science.
The Annals of the American Academy of Political and Social
Science 628(1): 112­131.
Bueno de Mesquita B, Gleditsch NP, James P, et al. (2003a)
Symposium on replication in international studies research.
International Studies Perspectives 4(1): 72­107.
Bueno de Mesquita B, Smith A, Siverson RM, et al. (2003b) The
Logic of Political Survival. Cambridge, MA: MIT Press.
Burman LE, Reed WR and Alm J (2010) A call for replication
studies. Public Finance Review 38(6): 787­793.
Carlin JB, Galati JC and Royston P (2008) A new framework
for managing and analyzing multiply imputed data in Stata.
Stata Journal 8(1): 49­67.
Cobb MD and Kuklinski JH (1997) Changing minds: Political
arguments and political persuasion. American Journal of
Political Science 41(1): 88­121.
Crawford G (1997) Foreign aid and political conditionality: Issues
of effectiveness and consistency. Democratization 4(3): 69­
108.
Druckman JN and Lupia A (2000) Preference formation. Annual
Review of Political Science 3(1): 1­24.
Gardner MJ and Bond J (1990) An exploratory study of statis-
tical assessment of papers published in the British Medical
Journal. JAMA 263(10): 1355­1357.
Gelman A (2013) It's too hard to publish criticisms and obtain
data for replication. Chance 26(3): 49­52.
Gerber AS, Doherty D and Dowling C (2009) Developing a
checklist for reporting the design and results of social sci-
ence experiments. Prepared for the 1st Experiments in
Governance and Politics (EGAP) meeting, Yale University.
Available at: http://orion.luc.edu/~ddoherty/ September 4th
2012.
Greene WH (2003) Econometric Analysis (5th Edition). Pearson
Education, Prentice Hall. New Jersey, USA: Upper Saddle
River.
Greene WH (2008) Econometric Analysis (6th Edition). Pearson
International Edition. New Jersey, USA: Upper Saddle River.
Herrnson PS (1995) Replication, verification, secondary analysis,
and data collection in political science. PS: Political Science
& Politics 28(03): 452­455.
Higgins JPT, Altman DG, Gøtzsche PC, et al. (2011) The cochrane
collaboration's tool for assessing risk of bias in randomised
trials. BMJ 343. Available at: http://www.bmj.com/con-
tent/343/bmj.d5928.long (accessed June 2013).
Honaker J, King G and Blackwell M (2011) Amelia II: A program
for missing data. Journal of Statistical Software 45(7): 1­47.
Available at: http://www.jstatsoft.org/v45/i07/ (accessed
September 2012).
Ishiyama J (2014) Replication, research transparency, and jour-
nal publications: Individualism, community models, and the
future of replication studies. PS: Political Science & Politics
47(01): 78­83.
King G (1995) A revised proposal, proposal. PS: Political Science
and Politics 28(3): 494­499.
10 Research and Politics 
King G (2006) Publication, publication. PS: Political Science and
Politics 39(01): 119­125.
King G, Honaker J, Joseph A, et al. (2001) Analyzing incomplete
political science data: An alternative algorithm for multiple
imputation. American Political Science Review 95: 49­69.
Lake DA and Baum MA (2001) The invisible hand of democ-
racy: Political control and the provision of public services.
Comparative Political Studies 34(6): 587­621.
McCullough BD, McGeary KA and Harrison TD (2008) Do
economics journal archives promote replicable research?
Canadian Journal of Economics/Revue canadienne
d'conomique, 41(4): 1406­1420.
Martel García F (2012) Small, slow, and diminishing: The effect
of democracy on the under-five mortality rate. Working Paper
2188599, Social Science Research Network. Available at:
http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2188599
(accessed May 2013).
Martel García F (2013a) Definition and diagnosis of problematic
attrition in randomized controlled experiments. Working
Paper 2302735, Social Science Research Network. Available
at: http://ssrn.com/abstract=2302735 (accessed August 2013).
Martel García F (2013b) A unified approach to generalized causal
inference. Working Paper 2304970, Social Science Research
Network. Available at: http://ssrn.com/abstract=2304970
(accessed September 2013).
Meltzer AH and Richard SF (1983) Tests of a rational theory of
the size of government. Public Choice 41(3): 403­418.
Mohan K, Pearl J and Tian J (2013) Missing data as a causal
inference problem. Technical Report R-410, Computer
Science Department, University of California.
Moher D, Jadad AR, Nichol G, et al. (1995) Assessing the quality
of randomized controlled trials: An annotated bibliography
of scales and checklists. Controlled Clinical Trials 16(1):
62­73. Available at: http://www.sciencedirect.com/science/
article/pii/019724569400031W.
Nelson JM (2007) Elections, democracy, and social services.
Studies in Comparative International Development 41: 79­97.
Olivo SA, Macedo LG, Gadotti IC, et al. (2008) Scales to assess
the quality of randomized controlled trials: A systematic
review. Physical Therapy 88(2): 156­175. Available at:
http://ptjournal.apta.org/content/88/2/156.abstract.
Pearl J (2009) Causality: Models, Reasoning, and Inference. New
York, USA: Cambridge University Press.
Przeworski A, Alvarez ME, Cheibub JA, et al. (2000) Democracy
and Development: Political Institutions and Well-Being
in the World, 1950­1990. New York, USA: Cambridge
University Press.
R Core Team (2013) R: A Language and Environment for
Statistical Computing. Vienna, Austria: R Foundation for
Statistical Computing. Available at: www.R-project.org/.
Rochefort DA and Cobb RW (1993) Problem definition, agenda
access, and policy choice. Policy Studies Journal 21(1):
56­71.
Ross ML (2006) Is democracy good for the poor? American
Journal of Political Science 50(15): 860­874.
Royston P, Carlin JB and White IR (2009) Multiple imputation of
missing values: New features for mim. Stata Journal 9(2):
252­264.
Sanderson S, Tatt ID and Higgins JPT (2007) Tools for assess-
ing quality and susceptibility to bias in observational stud-
ies in epidemiology: A systematic review and annotated
bibliography. International Journal of Epidemiology 36(3):
666­676.
Schmidt S (2009) Shall we really do it again? The powerful con-
cept of replication is neglected in the social sciences. Review
of General Psychology 13(2): 90­100.
Sen AK (2000) Development as Freedom (1st Edition). New
York, NY: Anchor Books.
Simera I, Moher D, Hoey J, et al. (2010) A catalogue of reporting
guidelines for health research. European Journal of Clinical
Investigation 40(1): 35­53. Available at: http://dx.doi.
org/10.1111/j.1365­2362.2009.02234.x.
Sovey AJ and Green DP (2011) Instrumental variables estimation
in political science: A readers' guide. American Journal of
Political Science 55(1): 188­200.
Turner L, Shamseer L, Altman D, et al. (2012) Does use of
the consort statement impact the completeness of report-
ing of randomized controlled trials published in medical
journals? A Cochrane review. Systematic Reviews 1(1): 60.
Available at: http://www.systematicreviewsjournal.com/
content/1/1/60.
Wigley S and Akkoyunlu-Wigley A (2011) The impact of regime
type on health: Does redistribution explain everything?
World Politics 63: 647­677.
World Bank (2008) World Development Indicators. Washington,
DC: World Bank Publications.
