European Educational Research Journal
2016, Vol. 15(1) 117
­131
© The Author(s) 2016
Reprints and permissions:
sagepub.co.uk/journalsPermissions.nav
DOI: 10.1177/1474904115608387
eerj.sagepub.com
Exploring the impact of digital
technologies on professional
responsibilities and education
Tara Fenwick
School of Education, University of Stirling, UK
Richard Edwards
School of Education, University of Stirling, UK
Abstract
Digital technologies in combination with `big' data and predictive analytics are having a significant
impact upon professional practices at individual, organisational, national and international levels.
The interplay of code, algorithms and big data are increasingly pervasive in the governing,
leadership and practices of different professional groups. They are reshaping the relationships
between professional grouping and between professionals and their clients/users/students.
New forms of accountability and responsibility are emerging as a result of these trends, raising
important questions about culpability and decision-making in professional practice. However,
to date, despite the introduction of many professional codes on the use of digital data and
social media, these issues have received limited examination in research addressing professional
education. This article aims to explore some of these trends, how they are manifested in different
professions and what might be the educational implications. Our argument is that new digital
technologies are reconfiguring professional practice and responsibility, but that the education of
professionals has yet to adequately reflect these changes.
Keywords
Professional responsibility, accountability, professional education, digital technologies, analytics,
algorithms, big data
Introduction
Digital technologies in combination with `big' data and predictive analytics are having a signifi-
cant impact upon professional practices at individual, organisational, national and international
levels. These technologies and their associated analytics are proliferating across professional
Corresponding author:
Tara Fenwick, School of Education, University of Stirling, Stirling FK15 0HD, UK.
Email: tara.fenwick@stir.ac.uk
Article
608387
EER0010.1177/1474904115608387European Educational Research JournalFenwick and Edwards
research-article2015
118 European Educational Research Journal 15(1)
practices from medicine, law and education to urban planning and policing. They collect data
through continuous sensing. They access massive data sets, such as administrative and health
records, and link these with all sorts of unstructured data combed in real time from human digital
activity. They work through algorithms to analyse this data on a huge scale for patterns, then cal-
culate these patterns to identify problems and suggest solutions. Increasingly these technologies
are being used to predict and plan, to recommend and, at times, to even make automated decisions.
This interplay of code, algorithms and big data is increasingly pervasive in the governing, leader-
ship and practices of different professions. It is also reshaping the relationships between profes-
sional grouping and between professionals and their clients/users/students.
These trends raise important questions about responsibility: the contribution of the skilled pro-
fessional in these reconfigured practices, the role and position of professional judgement, and how
responsibility and accountability are to be delineated with so many technological actors integrated
into professional services. Digital technologies are part of the emerging knowledge infrastructures
of daily life, the `robust networks of people, artefacts, and institutions that generate, share and
maintain specific knowledge about the human and natural worlds' (Edwards, 2010: 17). They rep-
resent a significant part of professional futures. Yet, despite some research on the effects of digital
data and the coded governing of contemporary life in educational systems (e.g. Fenwick et al.,
2014; Lawn, 2013; Williamson, 2015), there has been little detailed examination of the implica-
tions of digital technologies for professional practice, responsibility and education.
This article seeks to explore the issues arising with the emergence of digital technologies, pre-
dictive analytics and big data in professional work, with particular interest in questions of respon-
sibility. What are the implications of digital analytics for practitioners' responsibility and
accountability in their everyday work, as well as for the disciplinary knowledge underpinning their
practice? What new capacities might be needed, and what dilemmas might be anticipated? How
could we be educating professionals for forms of practice and decision-making that are increas-
ingly `code-threaded'? At the very least, what critical dialogues might we engage student profes-
sionals in regarding digital analytics in their practice? These are significant questions for
professional educators as well as for the broader social science communities in a period of rapidly
changing circumstances. This article will touch upon these questions rather than address each fully,
as our intention here is to suggest an agenda for research and professional education that requires
far more attention than can be achieved within the context of a single article (cf. Fenwick, 2016).
The article is, therefore, not intended to be a comprehensive literature review or a report of
empirical data, but an exploratory essay drawing selectively on literature in professionalism and
professional work, ethics, education and software studies. The argument is presented in four parts.
First, we will outline some contested conceptions of professional responsibility and their ethical
assumptions and practical implications. We will explore also some forms of calculation and distri-
butions of accountability and professional responsibility associated with these trends and tensions
within them. Second, we outline some of the work emerging that explores the work of algorithms,
big data and analytics and their significance for social practices. Third, we explore selected ways
in which digital technologies interplay with professional practice, in domains as diverse as polic-
ing, health and architecture. Finally, we will outline what we take to be some of the key educational
implications arising from the discussion. While it may be rather easy to identify dystopian trends in
critical evaluations of digital technologies, the position we take is one of creating useful future
directions. These are likely to require a reconfiguration of professional practices, perhaps involv-
ing a reframing and refocusing of the specific dimension brought to sociotechnical, sociomaterial
assemblages of practice by expert human practitioners. We are mindful of the lurking dystopias,
while seeking ways to interlink the benefits of digital analytics with the significant issues that pro-
fessional groups and services seek to address. Our intention is to raise questions about the framing
Fenwick and Edwards 119
of future practice and research in relation to professional responsibility and education, deliberately
adopting a broad approach to reflect the multi-professional and multi-disciplinary spaces within
which these issues are being researched and discussed.
Professional responsibilities and accountabilities
While the notion of the professional is heavily contested, for the purposes of this article we may
understand professions as `the knowledge-based category of service occupations which usually
follow a period of tertiary education and vocational training and experience ... [and are] exten-
sively engaged in dealing with risk' (Evetts, 2013: 781). Within the professions, responsibility is
often treated as a defining set of obligations for the nature of professionalism itself: obligations to
the client's interests as well as the needs of society broadly (Freidson, 2001). Much of the literature
on the topic is characterised by normative moral declarations of what professionals ought to do,
and what comprises professionals' responsible practice in particular fields. Prescriptions abound
for codes of behavior as well as for methods to educate professionals to perform these codes. These
prescriptions may be stoked by complaints and public concern about professionals' perceived irre-
sponsible practice and the failure to regulate practices appropriately.
Conceptual discussions of professional responsibility are wide ranging, from causal (who
caused the problem) to consequential responsibility (who takes the blame); and from attributed
(who is held accountable) to distributed responsibility (how accountability is apportioned among
agents). Moral responsibility invokes notions of both obligation and moral decision-making.
Obligation calls forth a sense of duty to care for self and others extending beyond one's own self-
interest, and an accountability to others for one's actions. In this sense, questions of professional
responsibility have tended to focus on the actions and decisions of individuals, although questions
about collective and organisational responsibility have become more common. The others to whom
professionals are responsible can be interpreted broadly: other human beings, other collectives,
such as community or national interests, authorities, tradition, animals or non-sentient beings of
the natural universe, concepts or ideals. Moral decision-making to acknowledge and act upon one's
professional responsibilities incites questions about the conception of the `good', the attendant
criteria or principles that should guide action, and the extent of one's freedom to decide. Within all
of this, as Gibbs (2000) points out, some view a distinction between responsibility as felt and
responsibility as acted.
In the field of ethics, critical debates have long swirled around the questions: who is responsible
to whom, for what, and to what extent? Responsibility has been developed within a tradition of
rational philosophy as a question primarily of ethical decision-making, invoking issues of univer-
sal laws and the problem of the contingent particular situation, as well as bonds and obligations that
inhere in an individual, conceived as autonomous, intentional and capable of acting independently
of others. However, Levinas (1981) and educational philosophers who have taken up his concep-
tion of the ethical subject (e.g. Biesta, 2006) have begun from a basic critique of the assumptions
embedded in this rational tradition. Levinas counters the view that individuals act and reason as
autonomous agents, and stresses the intersubjective relationships that enmesh human beings with
one another beyond their conscious intention or rational application of moral principles. He also
argues that ethical responsibility is moved not by rational decision-making but is enacted within
moments of connection, participation with others that calls forth response.
These considerations shift the issue of responsibility from notions of individual felt duty to the
active responding to others, broadly conceived, within complex webs of connection. A focus on
response turns attention away from defining what is the good, and what ethical laws should guide
action, towards questions about how response is excited, by whom or what, what forms it takes and
120 European Educational Research Journal 15(1)
what are its consequences. Thus, responsibility is not necessarily a simply rational construct, but can
be a phenomenal and relational dynamic. The meanings of professional responsibility are tangled
with issues of ethics, where some seek a clear moral delineation of `good'practice through codes of
ethics and conduct to be followed, while others focus more on the responsiveness to circumstances.
The latter entails a more (philosophically) pragmatic approach to issues of professional responsibil-
ity than a simple principled approach, that is, the rational application of ethical `laws' and `rules'.
There is growing research pointing to the pragmatic pluralism of professionals'obligations, and
the tensions and conflicts in responsibility that they must negotiate. This web of commitments
often necessitates what May (1996) has called `legitimate compromises'. Professionals balance
obligations to their employing organisations and their rules of practice, to broad social needs served
by their profession, to the profession itself and the standards and regulatory codes governing its
practices, to individuals for whom the professional adopts a responsibility, and to personal alle-
giances influencing a sense of the `right thing to do'. Robinson (2009: 18) argues that these func-
tion as three different kinds of engagement in professional responsibility. One is a plural
engagement, working through critical dialogue to navigate the responsibility of different roles.
Another is a relational engagement, `maintaining close awareness of the other'. A third is creative
engagement, `looking for a collaborative and negotiated response'. These may occur singularly,
sequentially or even simultaneously.
According to empirical research, professionals' negotiations of these differing, and sometimes
conflicting, responsibilities are becoming exacerbated by particular tensions between the claims
of increased efficiency and accountability, and the best interests of clients, students and patients
(e.g. Colley et al., 2007; Solbrekke, 2008; Stronach et al., 2002). Stronach et al. (2002) report that
nurses and teachers appear to manage these tensions by juggling simultaneously the discourses of
economy and ecology in practice. Colley et al. (2007) suggest that professionals must often
choose to act in ways `unbecoming' according to formal regulations, which are themselves risky.
These tensions signal the uneasy relations between professional responsibility and accountabil-
ity. Responsibility may be described as the needs to which professionals are expected to respond,
and in what ways, while accountability is more about how professionals are expected to justify the
ways they perform those responsibilities. Many commentators such as Solbrekke and Sugrue
(2010, 2014) are concerned about the increasing attention given by employers and government to
professionals' accountability in ways that can distort core commitments of responsibility.
Accountability in professional practice takes various forms: fiscal accountability, legal accounta-
bility (compliance with explicit regulations), bureaucratic outcomes-oriented accountability (duty
to the organisation's mission), community accountability (duty to care) and professional account-
ability (duty to a profession's discipline and ethics).
These forms and effects of accountability are all made visible through systems of measurement.
These measurements require a conversion of living events and their often unpredictable ambiguity
into representations of particular scales, into data. In the process, qualitative judgements can be trans-
lated into measured technical data. These data are rendered in forms such that they can be scrutinised
and assessed according to often conflicting accountability demands by various stakeholder interests
ranging among professionals, government departments, employers and the general public.As Robson
(1992: 700) explains, accounts essentially make living events visible; they provide a basis for calcula-
tion. These calculations afford a means for acting upon individuals and institutions to produce new
processes. Over time, accountabilities have become increasingly calculated through the interlacing of
algorithms and data and the analytics and visualisations of the practice they generate.
In relation to accountabilities, Callon and Law (2005) describe the linking and manipulation of
data as an act of counting and judgement that typically follows a three-stage process. First, relevant
entities are categorised, detached and displayed in a single frame. Second, these entities are manip-
ulated and transformed to show (or create) relations between them. Finally, a result is extracted
Fenwick and Edwards 121
such as a new entity, a ranking, or a decision. Calculation does not reside in human subjects and
become projected through their efforts as acts of agency, but rather is enacted in `material arrange-
ments, systems of measurement and methods of displacement ­ or their absence' (Callon and Law
2005: 715). Increasingly this work is done through digital technologies.
Callon and Law (2005) reconfigure the concept of calculation in two ways that are helpful for
understanding accountability. First, they offer the term `qualculation'to capture the ways that arith-
metic and qualitative accounts are melded in acts of calculation. Things have to be valued in par-
ticular ways, they must qualify for calculation, which involves qualitative processes. Acts of
qualculation involve all sorts of ways to manipulate entities within a single frame, only some of
which are arithmetic. Thus, rather than big data being technicist and reductionist, that is, ignoring
issues of quality, in conceptualising them as practices of qualculation, we can trace the meshing
and translation of values into the socio-technical practices of data collection and analysis. Second,
calculation and non-calculation are mutually constitutive: they are interrelated, rather than existing
in separate spaces. All calculation comes about with and against non-calculation, and vice versa. In
other words, in making certain things visible, certain things are made invisible. The most important
boundary is not between the acts of counting and the acts of judgement, but between arrangements
that allow qualculation, and other arrangements that make it impossible. In the context of digital
technologies and big data, this entails the capacity for the values in professional codes to be trans-
lated into the binary logic of lines of code.
In our discussion, this points to the ways in which digital technologies are not simply technical
solutions to enhancing the quality, efficiency and effectiveness of practices, but can also be power-
ful value-embedded socio-technical interventions in the attempted shapings of practices, account-
abilities and responsibilities. What is made visible and invisible is the result of work and does not
exist a priori to its enactment. They are neither determining nor determined, as qualculations are
not simply internalised but become part of the web of relations through which professional practice
is enacted, in the process contributing to different enactments of responsibility.
Solbrekke and Sugrue (2014) suggest that responsibility and accountability are two logics used
in assessing professional work, both of which are concerned with the quality of practice. However,
while the first is framed around professionals' own judgement, the second focuses on profession-
als' compliance with externally determined indicators of performance. Thus, `best practice'
becomes performed and defined differently within each of these logics. On the one hand, the logic
of accountability frames practice through economic concerns for standardised, measurable priori-
ties and rationales, and economic processes of external audit and counting. On the other hand, the
logic of responsibility frames practice within a language of values and integrity, contextual nuance
and relationship, and processes of situated judgement and negotiated standards. For Solbrekke and
Sugrue, this logic of responsibility elicits more proactive activity, while that of accountability
prompts more reactive behaviour. There is a dynamic interplay between these logics with their
approaches and priorities affecting one another.
We witness well-developed research on professional responsibility and accountabilities. What
happens to these then when digital technologies are introduced into both the practice of profession-
als and their accountabilities, when qualculation takes hold? What professional decision-making is
informed by digital technologies or supplanted by them? How are responsibilities and accountabil-
ities being delegated and distributed by and to digital technologies? What possibilities and risks
emerge through these developments? We explore such questions in the next section.
Digital technologies, big data and analytics
So ubiquitously and insidiously are digital technologies permeating all aspects of life that some
claim we now live and work in `code/space' (Kitchin and Dodge, 2011). It is difficult to separate
122 European Educational Research Journal 15(1)
how we think from the logic of the software through which we form and represent our thoughts.
Nor can we disentangle our actions from the materials with which we work, generated through
automated analysis of massive information sets to which we contribute continuously. Digital tech-
nologies and people are becoming interdependent, constituting one another, with emergent effects;
they do not just mediate existing social forms, but are integral to practice.
Critics such as Kitchin (2014), Naughton (2012) and Pariser (2011) have been calling attention
to the wide-reaching and accelerating consequences of these forces, claiming that professionals,
professional educators, researchers, policy-makers and the public are just beginning to realise the
enormous challenges being posed by digital technologies, software code and standardised data. Yet
professional education curricula and pedagogy seems to be standing aside from these transforma-
tions, often continuing to develop practitioners' knowledge and skills without much attention even
to the new educational materials appearing on learning analytics (Buckingham Shum 2015). Where
digital technologies are part of professional education, they tend to be treated as tools: useful to
master, but clearly subordinate to the knowledgeable professional. Yet the industries that are mar-
keting these digital technologies, and the practitioners, policy-makers and consumers eyeing their
potential, are already moving towards a future that could quickly marginalise or even exclude
professional intervention in many arenas. For some, this is part of the democratising of knowledge
and expertise and a challenge to professional deference. For others, it represents the denial of
human expertise and expert judgement.
The development of digital technologies is linked to the use of big data. Big data is a widely
used, if problematic, term that refers to various types of data sets collected in massive volume at
high velocity that tend to be exhaustive in scope, use very fine-grained resolution, and combine
wide-ranging types and contexts of data (Kitchin, 2013). What marks their increased role in profes-
sional practice are their digital forms and the capacity for them to be searched, sorted and analysed
digitally by the algorithms of software code (Halford et al., 2012). The results are ever-expanding
masses of data and database formats that can be manipulated to produce measures of performance,
analytics to predict behaviours and actions, and capacity for automated decision-making. In a
recent report for the UK's Economic and Social Research Council, Ruppert and her team (2015)
argue that it is these new social practices that need investigation. Rather than focusing on the oft-
cited big data characteristics of volume, velocity and variety, these authors direct our attention to
the specific novel socio-technical practices through which data is born, given meaning, then exer-
cised in all sorts of ways (searched, cleaned, mashed, curated, staged, traced, shared, re-purposed,
etc.). These exercises enact data in ways that order, change, reproduce and govern social life.
This is an argument also made by Mackenzie (2015) in his examination of some of the practices
of prediction through machine learning. He suggests that `the production of prediction is not auto-
matic, although it is being automated. But as machine learning is generalized, the forms of value
that circulate in the form of commodities alter. Prediction changes the social reality of value forms'
(Mackenzie, 2015: 444). Thus, while these digital analytics are producing possibilities for `evi-
dence-informed' policy and practice in ways unimagined in previous eras, Ruppert et al. (2015)
suggest that we think about big data itself as having social lives. We tend to overlook these social-
technical lives, which raises new vulnerabilities, risks and problems in how they become enacted.
It is here that research on the development of knowledge infrastructures and ontology building
begins to give insights into such lives (e.g. Edwards et al., 2013). It is also the case that some of
these lives are imagined and marketed rather than practised and experienced.
Kitchen (2014) identifies that big data are collected through at least three ways. First,
through intentional surveillance operated by humans, such as assessment records of students or
patient record information accumulated through a range of measures, tests, electromagnetic
scans and biotechnical feedback. This produces what Kitchen calls `directed data'. A second
Fenwick and Edwards 123
means is through embedded sensors in objects, environmental measuring instruments, click-
streams measuring students' and staffs' digital activity, scanners that read objects, and machines
that record their own uses as well as the items passing through them, such as diagnostic
machines. These sensors and scanners produce `automated data'. A third way is through gather-
ing `volunteered data', which we ourselves post on the web or social media. This data often is
processed not by human actors, but by algorithms in software code. However, humans and
technologies are not so easily separated: they participate together in practices of generating,
manipulating and curating data. Through processes of tagging, classification, calculation and
generalisation, knowledge is being enacted, along with identities, categories and relationships.
These elements are being represented through what Manovich (2013) calls media hybridisation
and the `deep mix' of media platforms, logics and techniques. Ever new data formats, new
interfaces and new ways of creating media are emerging from this deep media hybridising. This
is why Manovich claims that software is `taking command'.
In effect, digital technologies, data manipulated by algorithms, alongside the explosion of soft-
ware code mediating much of our analytics, knowledge, communication and decision-making, are
organising new standards of decision-making and governing. In the process, Berry (2011) argues
that different forms of delegation, aggregation and quantification are being enacted. While his
analyses focus on social life more broadly, it is their implications for professional practices that are
of interest here.
Digital technologies, professional practices and responsibilities
Increasing amounts of research in the professions is exploring the issues raised by the introduction
of digital technologies and the use of big data and analytics. In medicine, for example, electronic
patient records (EPRs) are being implemented in hospitals across most developed countries. Critics
such as Greenhalgh et al. (2014) have shown empirically how the software of these EPRs not only
limit the categories for diagnosis and description of patients to pre-given databases, even reducing
diagnostics to pull-down menus, but also turn expert practitioners into data entry workers. In other
words, argue these researchers, such data systems are fundamentally changing clinical work in
ways that were not fully considered before implementation. Meanwhile in the rapidly growing area
of mhealth (mobile technologies for health care), new technologies such as the RemotoscopeTM
app, designed to work with anyone's mobile phone to diagnose ear infection at home, are moving
rapidly from prototype to market. Such products are likely to increase convenience and responsive-
ness of service. But are algorithmically calculated, data-driven diagnostics as reliable and consist-
ent as services performed by human professionals?Available studies are careful in their conclusions.
For example, in researching a new algorithm running on mobile technology for managing chil-
dren's illness in sub-Saharan Africa, Shao et al. (2015) found that it resulted in better identification
of children with viral infections and an 80% drop in unnecessary prescription of antibiotics ­
overall, better clinical outcomes than standard practice. However, success depended on the deploy-
ment of the technology by professional clinicians specifically trained to follow its protocols strictly.
Higher education is another sector that is employing algorithmic analytics to address a host of
issues. For instance, analytics can be used to determine which students may pose a retention prob-
lem as the basis for targeted assistance. Students can be assigned a dropout prediction score, which
is shared with staff who can then monitor student activity and provide resources to keep them
enrolled (Harris 2014). Educators are becoming interested also in the possibility of improving
student attainment through predictive analytics that match teachers and students, reshuffle student
work groups and `recommend', like Amazon, resources and classes to individual students. To help
predict students' employment paths and suggest suitable curricula, these analytics also are being
124 European Educational Research Journal 15(1)
linked with projected labour skills demands, demographics, aptitude tests and markers of students'
online engagement (time spent viewing pages, content highlighted, etc.).
This all appears valuable as part of educational interventions, but relies on the validity and reli-
ability of the analytics embedded in the qualculations. Questions are raised when the analysis and
educational prescription are delegated solely to the decisions made by digital technologies. Any
student data will contain complex mixes of culture, class, sexuality, etc. that, however good the
digital technology and analytics, often cannot be registered or can be manipulated or gamed.
Laurillard (2012) shows that much student data is collected as by-products from other interactions.
While useful, it needs additional interpretation from professional educators. Here is an opportunity,
Laurillard argues, for educators to collaborate with technology specialists to capture data that will
address issues of most educational concern, and to use it to improve specific educational practices.
In other words, the production of prediction and the qualculations themselves need re-translation
through professional decision-making in the enactment of practice.
In education more broadly, Williamson (2015) draws attention to new phases in the calculation
and classification of complex matters of learning, pedagogy and context. Educational governance
in the UK increasingly is being actively displaced to technical centres such as Education DataLab,
which deploys analytics to manipulate masses of data from the National Pupil Database in order to
generate `actionable policy insights'. In particular, Williamson focuses concern on the incorpora-
tion of citizens and the persuasive, almost seductive, authoritative power of data visualisation
being employed by these technologies. His example is Learning Curve produced by Pearson
Publishing:
The user of the Learning Curve is solicited to perform independent analyses by tweaking variables,
adjusting statistical weightings, and generating new visualisations. As a result, the user is solicited not
quite as the consumer figure of school comparison websites cited earlier, but more as a `prosumer' who
does not only consume content but also produces it. ... These logics of `prosumption' elide distinctions
between popular and expert knowledge practices. (Williamson, 2015: 15)
In this way, what becomes enacted through digital technologies as governing knowledge in educa-
tion is presented benignly as co-created fun, scripting its users' involvement and obscuring its
actual functions in ways that they are not encouraged to examine.
A comparable range of digital technologies and visualisations are being implemented also to
support `predictive policing'. For example, Motorola's Real-Time Crime Centre Starter Kit links
wide-ranging data from sources such as sensors, alarms, multiple video systems and computer-
aided dispatch with software analytics. Motorola's representative explains that the technology
`allows agencies to implement predictive policing tactics and leverage existing technology to pro-
vide relevant and timely intelligence to improve closure rates, help stop a crime in action and
proactively identify potential incidents before they occur' (Cipriano, 2014). These sorts of tech-
nologies increasingly build in public involvement so that citizens can monitor activity in their
neighbourhoods and feed it into the software for analysis to generate predictions and recommended
actions. The power of such predictions is one of the questions raised by Mackenzie (2015), as the
generalisations might be said more accurately to produce anticipations over which human judge-
ment still needs to be maintained rather than precise predictions. It is in the collapsing of anticipa-
tions into predictions that professional responsibility is delegated to digital technologies.
In the context of architects and other professionals working with built environments, Jaradat
et al. (2013) document how dramatically professional roles are changing as large integrated data
systems are used increasingly to design, construct and maintain buildings. The client is becom-
ing increasingly `professionalised', new conflicts are appearing across professional groups, and
Fenwick and Edwards 125
new kinds of professional accountabilities are emerging. For example, workflow approvals are
often delegated to digital mechanisms, while professionals running the projects may bypass the
fuss and unwieldy structures of uploading the required documents and continue to rely on phone
calls and emails to negotiate fast-changing details between engineers, contractors and architects.
New specialists dealing with document control and integration are becoming part of the building
design and delivery processes, who may exercise different standards of judgement in assessing
work quality than the design professionals. The proliferation of different design professionals ­
architects, servicing engineers and so forth ­ all mediated by digital technologies, create new
issues of standardisation and transfer of the digital data and potential for conflict and work
arounds in the practices of qualculation. The handover of digital data can create frustration at a
system's inflexibility, or the errors and misinterpretations that can occur with multiple users
interacting with the same data at once.
Digital technologies are not necessarily digital in the ways that professionals need to be. They
tend to work from simplistic premises: that problems are technical, comprise knowable, measura-
ble parameters, and can be solved through technical calculation. They rely on practices that enable
qualculations through a binary logic of generalisation and either/or. Barocas et al. (2013) also show
that algorithms reflect what they term `a profound deference to precedent', acting on the past to
make decisions regarding the future. Digital technologies work through identifying past patterns
and cycles of anticipation, which can be self-reinforcing and reproductive, augmenting path
dependency and entrenching existing practices. They can act as filter bubbles, simply reinforcing
past patterns of behaviour (Pariser, 2011). Complexities of responsibilities and values, ambiguities
and tensions, culture and politics and even the context in which data are collected are not necessar-
ily taken into account.
Many warn that the growth and unexamined nature of these sorts of analytics, as they permeate
professional practice, are creating particular forms of rationality, and potentially new epistemo-
logical orders (Kallinikos, 2010; Kitchin, 2014). There are new ethical as well as legal issues when
professional responsibility becomes delegated to algorithms (Barocas et al., 2013; Ruppert et al.,
2015). `Smart' machines such as diagnostic technologies and robotics are powerful augmenters of
practice but, as Marcus and Davis (2014) argue in the case of health care, they should supplement,
not replace, professional judgements: only human professionals can listen to patients with nuanced
understanding of complexities. Digital technologies do not attune or intuit, and, to date, they are
not considered conscious agents that can bear responsibility for decisions.
Bearing this in mind, it is sobering to read about technological developments that are allowing
increased delegation of professional decision-making to digital analytics. In human resource man-
agement for instance, Sullivan (2013) reports that Google is using big data and algorithm-based
decisions in its practices: `people analytics' for the twenty-first century. A hiring algorithm is used
to predict which employees are most likely to succeed after recruitment, both to shorten the total
interview time and to ensure that the selection panels do not `miss' top talent: this is `scientific'
recruitment. One algorithm targets `diversity problems', analysing root causes of `weak diversity'
and suggesting solutions. Another algorithm predicts which employees are likely to become a
`retention problem', alerting management so that pre-emptive action can be taken. These `forward-
looking' predictive models use technology-driven processes to identify and address `people man-
agement' problems and opportunities.
In the law profession, Susskind (2013) has tracked the ways technology-driven processes have
proliferated in legal services, with a corresponding rise of technology-driven entrepreneurs: legal
knowledge engineers, legal data technologists, risk managers and project managers. Online personal
legal services are increasingly common, just as e-services have become more prevalent in many
professions, using software that analyses problems and presents solutions. These `democratising'
126 European Educational Research Journal 15(1)
developments have been debated for some time in law journals, where the benefits of affordability
and convenience are weighed against the concerns about risk, quality, trust and accountability (Cho,
2006; Figueras, 2013). Susskind predicts a radical reconfiguration of the profession of law, deliv-
ered through diverse internet-based global legal businesses, online document production, virtual
courts and online dispute resolution. Segrist (2015) goes further, to argue that big data and predictive
analytics are actually changing the responsibility of an attorney.
As these sorts of examples show, across professional work in health care, education and many
other areas, new digital technologies are reframing practices in different ways. Predictive analytics
are used to assess conditions and prescribe remedies for students or patients or clients, to produce
client and professional service records that can be integrated with other data to make decisions, and
to plan and even automate service provision in areas such as health, social care, education and
policing. Some of this is for great benefit, as better and more quickly generated data can assist
improved decision-making to enhance practices. However, what we and others are suggesting is
that aspects of these trends have implications for professional accountability and responsibility that
require further exploration. The coded objects, infrastructures, processes and assemblages of digi-
tal technologies participating in reconfiguring professional practices are not simply tools to enhance
practice, but pose questions as to the nature of future professional work and the values embedded
in and evidenced by such work.
How then should we think about professional responsibility when algorithms are embedded in
the production of predictions? How do we understand the professional as a responsible actor when
capability is delegated and distributed? What does it mean for professionals to work responsibly
with big data sets of varying quality and with reductionist algorithms? What responsibilities do and
should professionals have within different regimes of coded accountability and governing? What
practices of qualculation enhance the value of professional work? Professionalism and profes-
sional discretion and responsibility are important aspects of professional education. Perhaps we
need to rethink how it is enacted in particular digital assemblages, working through particular
digitised problems. Then we might reimagine ways for professionals to learn strategies of respon-
sibility in these different contexts even as their own position is reconfigured in the production of
these assemblages.
Educational implications
This article has drawn attention to a number of issues for professional responsibility posed by new
digital technologies and analytics that we argue deserve more attention by educators and educa-
tional researchers. While our purpose is not to provide detailed pedagogical recommendations for
these particular issues, even if such recommendations were available in current literature, we do
wish to suggest educational approaches that might be implied by the foregoing discussion. These
may not be new or original suggestions, but we offer them in the spirit of inspiring further thinking,
practice developments and research around educating professionals for responsibility in work con-
texts increasingly reconfigured by new digital technologies, analytics and big data.
Critically examine new digital analytics being introduced in particular fields and
how they influence knowledge and practice
As we have indicated in this article, empirical studies are appearing showing the impact of new
digital technologies and analytics in different fields of professional work, and what benefits as well
as problems are occasioned. Students in the professional arenas should be introduced to these.
They also might interview experienced practitioners about how these resources are actually being
Fenwick and Edwards 127
used, or examine promotional material for these products. Students can examine and discuss all
these critically from the perspective of implications for professional responsibility. What happens
in practice? To what extent are particular digital analytics foreclosing nuances and complexity that
are important to professional analysis and problem-solving? What issues of trust, risk and quality
are raised? What do the practices of qualculation and the production of prediction entail and with
what implications for knowledge, practice and responsibility?
The object is to educate new professionals to develop a critical attunement that can see past the
persuasive apparent `precision' of solutions produced by digital technologies, qualculation and
predictive analytics, and to question their limitations as well as identify their possibilities. More
broadly perhaps, the aim is to prompt students' sense of responsibility to engage with these tech-
nologies as part of the assemblages of practice, and not just to accept them as black boxes that only
computer specialists can understand.
Learn more about the effects of computational processes
Students in all professions could be encouraged to learn more about computational processes that
produce certain forms of knowledge and the logic that structures thinking. `Learning to code' has
become an arena of debate in education more broadly, with some claiming that the challenge for
curriculum is to teach students either `to program or be programmed' (Naughton, 2012). The argu-
ment is that it is possible ­ even urgent ­ to make visible the hidden work of software code by
developing enhanced computer skills in all students.
In much professional education, however, learning to code is not practical: expertise relies on
specialism and each professional domain has its own arena of discrete capability. It is also the case
that learning to code is considered by some as an inadequate response to the work of digital tech-
nologies. The developing field of software studies and the work from which we have drawn for this
article indicates a far more intricate interplay in coding processes of technical and professional
issues with sociological, ethical, political and computational questions (e.g. Berry, 2011; Edwards
et al., 2013; Kitchin and Dodge, 2011; Manovich, 2013) than lessons in learning to code are likely
to appreciate.
For professional practice, it is the capability of the team harnessing different expertise that is
central. However, students within professional education could discuss the effects of digital tech-
nologies. Who generates the technologies and their outputs? Who should be able to understand the
code and big data, and at what level? How are issues of values and ethics translated into lines of
code and with what implications? Students also could look more closely at how algorithms built
into common software such as Facebook shape the way that they express and represent themselves,
interact with others, form preferences, make decisions and become drawn into particular social
groups and patterns. As students move into professional work, they could become more attuned to
making the computational work decipherable and more visible in relation to their practices.
Learn to collaborate with designers
In general, as writers cited here such as Laurillard (2012) have argued, it makes more sense for
professionals and student professionals to learn to collaborate with computer scientists than to
try to become computer scientists. This is something that our own colleagues have begun to do,
in our case through a series of workshops involving social scientists, professional educators,
practising and student professionals, and computer scientists (Code Acts, n.d.). Halford (2015)
convenes projects linking social and computer scientists, and argues this is the most important
area for educational attention. She claims that most disciplines still remain aloof from engaging
128 European Educational Research Journal 15(1)
with computational experts, for all sorts of understandable reasons, including the vast differ-
ences in language, logics, purposes and approaches. This is despite the proliferation of expertise
and resources among people, the internet and social media (MacKenzie 2015). However, Halford
argues that until public service professionals learn to collaborate with computer scientists, digi-
tal technologies may well continue to be designed within the vacuums of technological innova-
tion for its own sake rather than for the complex contexts of social worlds and responsibilities,
contributing to the reductionism that then becomes a focus of critique. Furthermore, collabora-
tion with coders helps professionals understand the possibilities as well as limitations of qualcu-
lations, semantic webs and big data, and address explicitly issues of responsibility and
accountability within these changing knowledge infrastructures. For the computer scientists,
although co-production has been a frequent aspiration in the development of digital technolo-
gies, the capacity for professionals to have a clear understanding of what is required and how it
can be produced and developed is also critical. This requires very different forms of cross-disci-
plinary curriculum and cross-professional working to those that mostly exist now.
Learn the issues and capacities needed to integrate new data analytics and
technologies effectively into responsible practice
Examples cited in this article, such as the inevitable proliferation of online (professional) services
and machine diagnostics, suggest that professionals need to be pragmatic as well as critical about
these new technologies. In other words, practitioners need to decide when and how to embrace
them. Embracing means neither accepting and using new technologies without question, nor stand-
ing aside and allowing `smart' machines to get on with it. As with the example of new mobile-
based algorithms for health care, the responsible use of these technologies relies upon trained
professionals.
Furthermore, as the example provided by Jaradat et al. (2013) showed, the new forms of big data
being introduced into professional work demand new systems for transferring data between clients,
operators and various groups of practitioners. The recommendation from Jaradat et al. (2013) is that
professionals need to understand the potential points for error or misinterpretation at various inter-
faces in this data integration, as different forms of data and different purposes for interpreting it must
be reconciled. Professionals also need to assume accountability themselves for examining these
points in order to better manage data flows and critically examine the issues in meanings, metrics
and ethics that arise. In order to do this, professionals who may not ordinarily work directly with
data systems need to understand more about data itself and how these systems work, the translations
of qualculation and production of predictions, and how to link with other professionals and institu-
tions to integrate practices responsibly using this data across professional roles.
Explicitly debate the implications of new digital technologies for professional
responsibilities and accountabilities
These questions about the potential expansion of professional responsibility to critically interfere
with and more actively engage with digital technologies and analytics raises the broader issue of
professionalism and accountability in this realm. How should we think about professional respon-
sibility when algorithms produce predictions and make decisions? How do we understand the
professional as a responsible agent when capability is distributed? What does it mean for profes-
sionals to work responsibly with `dirty' big data sets and generalising algorithms? What forms of
responsiveness are appropriate to the messiness of practices enmeshed within the binary code of
software? Professionalism is an important aspect of professional education: we need to rethink
Fenwick and Edwards 129
how it is enacted through its entanglement with digital technologies. Then we might encourage
new professionals to reimagine principles and pragmatics of responsibility, to develop purposes
and learn strategies for using digital technologies thoughtfully and responsibly in these brave new
worlds. Their promise might be of more accurate, consistent and clear analytics to reduce complex-
ity and improve decision-making. However, while the complexity, responsibilities and accounta-
bilities may be reconfigured, we would question if they are simply reduced. Digital analytics and
technologies are increasingly powerful and sophisticated actors in professional practices that are,
as in the industrial revolution of the nineteenth century, transforming work knowledge, divisions
of labour and work identities. However, they also bring opportunities for different forms of profes-
sionalism. They do not negate professional responsibilities and accountabilities, providing simple
technical solutions to complex social issues. They do highlight the need for a more informed debate
in professional education surrounding digital technologies and professional responsibility, one to
which we hope this article is a small contribution.
Declaration of conflicting interests
The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication
of this article.
Funding
The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publica-
tion of this article: This article is developed from work within the ESRC-funded seminar series Code Acts in
Education http://codeactsineducation.wordpress.com/about/ (grant reference: ES/L001160/1).
References
Barocas S, Hood S and Ziewitz M (2013) Governing algorithms: A provocation piece. Paper prepared for the
Governing Algorithms conference, New York University, May 16­17.
Berry D (2011) The Philosophy of Software: Code and Mediation in the Digital Age. Basingstoke: Palgrave
Macmillan.
Biesta G (2006) Beyond Learning: Democratic Education for a Human Future. Boulder: Paradigm Publishers.
Buckingham Shum S (2015) Learning analytics: On silver bullets and white rabbits. Medium (9 Feb.).
Available at: https://medium.com/@sbskmi/learning-analytics-on-silver-bullets-and-white-rabbits-
a92d202dc7e3.
Callon M and Law J (2005) On qualculation, agency, and otherness. Environment and Planning D: Society
and Space 25(5): 717­733.
Cho V (2006) A study of the roles of trust and risk in information oriented online legal services using an
integrated model. Information and Management 43(4): 503­520.
Cipriano M (2014) Crime centre kit boosts predictive policing capabilities. GCN: Technology, Tools and
Tactics for Public Sector IT, 28 March. Available at: http://gcn.com/articles/2014/03/28/predictive-
policing-starter-kit.aspx?admgarea=TC_BigData&m=2.
Code Acts (n.d.) Code acts in education: Learning through code/learning to code. Economic and Social
Research Council-funded seminar series and blog, University of Stirling 2014­15. Available at: https://
codeactsineducation.wordpress.com/about/.
Colley H, James D and Diment H (2007) Unbecoming teachers: Towards a more dynamic notion of profes-
sional participation. Journal of Education Policy 22(2): 173­193.
Edwards P (2010) A Vast Machine: Computer Models, Climate Data, and the Politics Of Global Warming.
Cambridge, MA: MIT Press.
Edwards P, Jackson S, Chalmers M, et al. (2013) Knowledge Infrastructures: Intellectual Frameworks and
Research Challenges. Ann Arbor, MI: Deep Blue.
Evetts J (2013) Professionalism: Value and ideology. Current Sociology 61(5/6): 778­796.
130 European Educational Research Journal 15(1)
Fenwick T (2016) Professionalism and Professional Responsibility: A Sociomaterial Examination. London:
Routledge.
Fenwick T, Manguez E and Ozga J (eds) (2014) Governing Knowledge: Comparison, Knowledge-based
Technologies and Expertise in the Regulation of Education. London: Routledge.
Figueras I (2013) The LegalZoom identity crisis: Legal form provider or lawyer in sheep's clothing? Case
Western Reserve Law Review 63(4): 1419­1443.
Freidson F (2001) Professionalism: The Third Logic. Cambridge: Polity Press.
Gibbs R (2000) Why Ethics? Signs of Responsibility. Princeton, NJ: Princeton University Press.
Greenhalgh T, Stones R and Swinglehurst T (2014) Choose and book: A sociological analysis of `resistance'
to an expert system. Social Sciences and Medicine 104: 210­219.
Halford S (2015) Decoding code: A critical politics of the semantic web as an opportunity for inter-profes-
sional learning. Presentation to Code Acts in Education ESRC seminar series, University of Stirling,
February.
Halford S, Pope C and Weal M (2012) Digital futures? Sociological challenges and opportunities in the emer-
gent semantic web. Sociology 47(1): 173­189.
Harris C (2014) Big data means big results in higher education. Tech Page One, 13 May. Available at: http://
techpageone.co.uk/en/technology/big-data-means-big-results-in-higher-education/.
Jaradat S, Whyte J and Luck R (2013) Professionalism in digitally mediated project work. Building Research
and Information 41(1): 51­59.
Kallinikos J (2010) Governing Through Technology: Information Artefacts and Social Practice. London:
Palgrave.
Kitchin R (2013) Big data and human geography. Dialogues in Human Geography 3(3): 262­267.
Kitchin R (2014) The Data Revolution: Big Data, Open Data, Data Infrastructures and Their Consequences.
London: Sage.
Kitchin R and Dodge M (2011) Code/Space: Software and Everyday Life. Cambridge, MA: MIT Press.
Laurillard D (2012) Teaching as a Design Science: Building Pedagogical Patterns for Learning and
Technology. London: Routledge.
Lawn M (ed.) (2013) The Rise of Data in Education Systems: Collection, Visualisation and Use. Oxford:
Symposium.
Levinas E (1981) Otherwise Than Being Or Beyond Essence. The Hague: Martinus Nijhoff.
MacKenzie A (2015) The production of prediction: What does machine learning want? European Journal of
Cultural Studies 18(4­5): 429­445.
Manovich L (2013) Software Takes Command: Extending the Language of New Media. London: Bloomsbury
Academic.
Marcus G and Davis, E (2014) Eight (no, nine!) problems with big data. New York Times, 7 April, A23.
Available at: http://www.nytimes.com/2014/04/07/opinion/eight-no-nine-problems-with-big-data.
html?_r=2.
May L (1996) The Socially Responsive Self. Social Theory and Professional Ethics. Chicago: University of
Chicago Press.
Naughton J (2012) From Gutenberg to Zuckerberg: What You Really Need to Know About the Internet.
London: Quercus.
Pariser E (2011) The Filter Bubble: What the Internet is Hiding From You. London: Viking.
Robinson S (2009) The nature of responsibility in a professional setting. Journal of Business Ethics 88: 11­19.
Robson K (1992) Accounting numbers as `inscription': Action at a distance and the development of account-
ing. Accounting, Organisations and Society 17(6): 685­708.
Ruppert E, Harvey P, Lury C, et al. (2015) Socialising Big Data: From Concept to Practice. CRESC Working
Paper Series, Working Paper No. 138, the University of Manchester and Open University. Available at:
http://www2.warwick.ac.uk/fac/cross_fac/cim/research/socialising-big-data/sbd_wp_2015.pdf.
Segrist P (2015) How the rise of big data and predictive analytics are changing the attorney's duty of compe-
tence. North Carolina Journal of Law & Technology 16(3): 527­622.
Shao AF, Rambaud-Althaus C, Samaka J, et al. (2015) New algorithm for managing childhood illness using
mobile technology (ALMANACH): A controlled non-inferiority study on clinical outcome and antibi-
otic use in Tanzania. PLoS One 10(7): e0132316. DOI: 10.1371/journal.pone.0132316.
Fenwick and Edwards 131
Solbrekke T (2008) Professional responsibility as legitimate compromises: From communities of education
to communities of work. Studies in Higher Education 33(4): 485­500.
Solbrekke T and Sugrue C (2010) Professional responsibility: Retrospect and prospect. In: T Solbrekke and
C Sugrue (eds) Professional Responsibility: New Horizons of Practice? London: Routledge, 11­28.
Solbrekke T D and Sugrue C (2014) Professional accreditation of initial teacher education programmes:
Teacher educators' strategies ­ between `accountability' and `responsibility'. Teaching and Teacher
Education 37: 11­20.
Stronach I, Corbin B, McNamara O, et al. (2002) Towards an uncertain politics of professionalism: Teacher
and nurse identities in flux. Journal of Education Policy 17(1): 109­138.
Sullivan J (2013) How Google is using people analytics to completely reinvent HR. TLNT: The Business of
HR, 26 February. Available at: http://www.tlnt.com/2013/02/26/how-google-is-using-people-analytics-
to-completely-reinvent-hr/.
Susskind R (2013) Tomorrow's Lawyers: An Introduction to Your Future. Oxford: Oxford University Press.
Williamson B (2015) Digital education governance: Data visualisation, predictive analytics and `real-time'
policy instruments. Journal of Education Policy. DOI: 10.1080/02680939.2015.1035758.
Author biographies
Tara Fenwick is Professor of Professional Education and Director of ProPEL (research in professional prac-
tice, education and learning) at the School of Education, University of Stirling. Her most recent books include
Professional Responsibility and Professionalism: A Sociomaterial Examination (Routledge forthcoming) and
Reconceptualising Professional Learning (with M. Nerland, Routledge 2014).
Richard Edwards is Professor of Education at the School of Education, University of Stirling, who has pub-
lished extensively in educational theory, globalization and lifelong learning. His current research focuses on
changing knowledge infrastructures, informal learning, citizen science, and the effects of digitization.
