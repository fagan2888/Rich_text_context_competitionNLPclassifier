Creative Commons Non Commercial CC-BY-NC: This article is distributed under the terms of the Creative Commons
Attribution-NonCommercial 3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use,
reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open
Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).
Methodological Innovations
Volume 9: 1­11
© The Author(s) 2016
Reprints and permissions:
sagepub.co.uk/journalsPermissions.nav
DOI: 10.1177/2059799116638001
mio.sagepub.com
Introduction
Measures of education are routinely incorporated into analy-
ses of a wide variety of social outcomes and in analyses of
social and population change. Education is a powerful explan-
atory factor influencing a number of economic phenomena,
most notably both participation and success in the labour mar-
ket (e.g. Card, 1999; Hartog, 2000; Jenkins and Siedler, 2007).
Education is also important in far less obvious fields such as
health (e.g. Desai and Alva, 1998; Kunst and Mackenbach,
1994; Lindeboom et al., 2009; Ross and Wu, 1995). Measuring
education appropriately is more difficult than researchers
might initially assume, because there is no simple, universal or
agreed upon measure of education. Most societies have com-
plex educational systems that have often changed over time.
Therefore, the seemingly prosaic activity of measuring an
individual's education within a social survey is far from
straightforward, and analysts of social survey data should be
mindful of the challenges and potential pitfalls associated with
using education variables in statistical analyses.
There are a number of high-quality social surveys which
are specifically designed to collect detailed and comprehen-
sive educational information.1 Most of the more general and
multipurpose social surveys (e.g. large-scale cross-sectional
surveys and household panel surveys) also collect informa-
tion on a respondent's educational background but usually in
less detail. Because there is no simple measure of education
that is universally agreed upon, the information collected in
social surveys can take numerous forms. For example, details
on the respondent's experiences in compulsory education,
their school grades, how much formal education they have
completed, the title or nature of their qualifications and the
types of institution that they attended post-school, are all
often collected in multipurpose social surveys, but there are
variations from survey to survey in the range of measures
collected. Social survey data collectors also usually construct
one or more `derived' education variables. These summary
A review of educational attainment
measures for social survey research
Roxanne Connelly1, Vernon Gayle2 and Paul S. Lambert3
Abstract
This article is a review of issues associated with measuring education and using educational measures in social science research.
The review is orientated towards researchers who undertake secondary analyses of large-scale micro-level social science
datasets. The article begins with an outline of important context, which impinges upon the measurement of education. The
United Kingdom is the focus of this review, but similar issues apply to other nation states. We provide a critical introduction
to the main approaches to measuring education in social survey research, which include measuring years of education, using
categorical qualification based measures and scaling approaches. We advocate the use of established education measures to
better facilitate comparability and replication. We conclude by making the recommendation that researchers place careful
thought into which educational measure they select, and that researchers should routinely engage in appropriate sensitivity
analyses.
Keywords
Measuring education, social surveys, quantitative data analysis, UK
1The University of Warwick, Coventry, UK
2The University of Edinburgh, Edinburgh, UK
3University of Stirling, Stirling, UK
Corresponding author:
Dr Roxanne Connelly, Department of Sociology, University of Warwick,
Coventry, CV4 7AL, UK
Email: R.Connelly@warwick.ac.uk
638001
MIO0010.1177/2059799116638001Methodological InnovationsConnelly et al.
research-article2016
Original Article
2 Methodological Innovations
measures tend to be the most popularly used in sociological
analyses but often vary from survey to survey.
In specialist fields such as educational sociology and
social stratification research, educational measures are fre-
quently analysed by researchers who have specific expertise
in the field of education (for an illustration see Breen and
Jonsson, 2005; Lucas, 2001; Paterson and Iannelli, 2007).
Outside of these specialist areas, secondary analysts may
wish to use an education measure as either an outcome or
explanatory variable, but they may have less in-depth knowl-
edge of the scope and limitations of the possible ways they
can summarise this information. An aim of this article is to
increase awareness of the issues associated with measuring
education in context and to provide guidance for researchers
who are not experts in this field.
We commence with an outline of important context which
impinges upon the measurement of education. The United
Kingdom is the focus of this article, but similar issues apply
to many other nation states. We outline the main approaches
to handling educational information in social survey data.
This article is not orientated towards a theoretical evaluation
of education measures nor does the article document the his-
tory or development of education measures. It is our inten-
tion that this article will serve as a useful reference for
researchers seeking guidance on summarising educational
attainment information effectively when analysing social
surveys. We conclude by making a series of practical recom-
mendations for researchers engaged in secondary social sur-
vey data analysis.
Education in context
General social surveys usually collect data on a large sample
of respondents which reflect the wider structure of a popula-
tion (e.g. the nation). Therefore, samples will routinely
include respondents of different ages and at different stages of
the life course. There have been radical changes in the educa-
tion systems in most nations within living memories, and
older cohorts of respondents in surveys will tend to have been
educated in different circumstances to younger cohorts. For
ease, we will refer to different groups as `educational cohorts'.
Below, we elaborate upon a number of changes to educational
systems and opportunities that have influenced `educational
cohorts'in the United Kingdom and stress that there are com-
parable stories of substantial educational change, albeit with
different specific details, in other countries.
The difference between `educational cohorts' is easily
illustrated using a British example. The British Household
Panel Survey (BHPS) is a multipurpose household panel sur-
vey of approximately 5000 households and 10,000 individu-
als (Berthoud and Gershuny, 2000; Institute for Social and
Economic Research, 2010). In the first wave of the survey
(1991), the oldest adult respondent was born in 1894 and the
youngest in 1975, a span of 81years. A small number of very
old BHPS respondents attended school before the First World
War, about a quarter attended school in the inter-war years,
and the bulk of respondents attended school after the Second
World War. The respondents also had varying access to edu-
cational opportunities beyond compulsory schooling. Those
born before 1945 had very limited opportunities to gain post-
school qualifications. Those born from 1945 benefitted from
higher education expansion, and those born after 1965 ben-
efitted from greater expansion in both further and higher
education. Each of these educational cohorts were educated
under different conditions, the structure and organisation of
educational institutions differed, and the educational oppor-
tunities available to pupils were markedly different.
Minimum school leaving age2
The `raising of the school leaving age' (ROSLA) is a term
used in the United Kingdom to describe an act brought into
force when the legal age that a young person is allowed to
leave compulsory education increases (Ainley, 1988;
Blackburn and Jarman, 1992; Bolton, 2012; Paterson, 2003;
Trowler, 2003). In the United Kingdom, the compulsory
school leaving age was increased from 14 to 15
years in
1947, as a result of the 1944 Education Act. It was raised
again in 1973 to 16years, and more recently in England the
school leaving age has been further extended.3 Many
researchers include a measure of years of full-time education
completed within their analyses (Eikemo et al., 2008;
Kunovich and Slomczynski, 2007). In some research appli-
cations using a duration measure is a straightforward and
functional strategy. The organisational changes to the length
of compulsory education in Britain might be consequential
but would be hidden in an analysis that included adults of
very different ages (and therefore from different educational
cohorts). A naïve analysis of all adults in the BHPS might
overlook this important contextual detail. In such circum-
stances, it might prove beneficial to include an explicit indi-
cator for educational cohort within the analysis.
Changing school structures
Over the course of the 20th century different educational
cohorts in the United Kingdom have passed through very dif-
ferent school and post-school systems. The 1944 Education
Act sought to provide compulsory secondary education for all,
free of charge through a school system that was highly selec-
tive (Blackburn and Jarman, 1992). On the basis of an ability
test taken at the age of 11years (the 11-plus exam), most chil-
dren were allocated to one constituent of a tripartite system of
schooling (Ainley, 1988). Children who passed the 11-plus
examination were generally allocated places at grammar
schools, whereas pupils who failed the 11-plus were generally
allocated places at secondary modern schools. In some regions,
education was also provided at technical schools. Grammar
schools provided traditional academic education leading to
formal qualifications and the possibility of entering higher
Connelly et al. 3
education, while a more vocationally orientated curriculum
was delivered in secondary modern and technical schools.
The United Kingdom has since moved away from the tri-
partite school system. The `11-plus' was abolished in most
regions by the early 1970s, and comprehensive schools (i.e.
schools which do not select their intake on the basis of aca-
demic achievement or perceived ability) became the most
common types of school, although a small number of areas
of England still maintain selective grammar schools (Bolton,
2012; Paterson, 2003). Given the context of changes in
school structures over time, an analysis that uses an educa-
tional measure such as the type of secondary school attended
has the potential to be misleading when respondents from
different educational cohorts are included within the same
analytical sample.
Changing school-age qualifications
Nations like the United Kingdom have education systems
with a wide range of qualifications. In addition to the school
leaving age increasing and school systems being reorgan-
ised, there have also been dramatic changes in school-level
qualifications (Bolton, 2012). Noah and Eckstein (1992)
highlight that in the period since the end of the Second World
War new qualifications have emerged and later disappeared.
In England, Wales and Northern Ireland the General
Certificate of Education Ordinary Level (O' Level) was
introduced in the 1950s and was the normal examination, at
the end of compulsory education, for pupils attending gram-
mar Schools. The Certificate of Secondary Education (CSE)
was introduced in the 1960s and was designed for pupils per-
forming at a lower level, but its highest grade was considered
to be equivalent to a low grade O' Level. These qualifica-
tions were replaced by the General Certificate of Secondary
Education (GCSE) in the late 1980s (Department of
Education, 1985; Mobley et al., 1986; North, 1987).
The Scottish education system has always had a different
set of school-age qualifications. The Ordinary Grade of the
Scottish Certificate of Education (commonly known as
O-Grades) was usually taken at the ages of 15 or 16
years
until the late 1980s when they were replaced by Standard
Grades. A new system of National grades was introduced in
Scotland in 2014 (see Kidner, 2013).
The UK school education system has generally been organ-
ised into a two tier qualification structure which comprises a
lower tier of examinations that are undertaken at the end of
compulsory school and a higher tier of more advanced qualifi-
cations which are undertaken usually in the years that immedi-
ately follow post-compulsory school. The more advanced
school-level qualifications (which are usually targeted towards
entry into higher education) have remained relatively more sta-
ble. The General Certificate of Education Advanced Level (A'
Level), usually requiring 2
years of study, has been under-
taken by pupils in England, Wales and Northern Ireland since
the early 1950s. Pupils usually undertake three subject-specific
A'Levels. These qualifications are the standard requirement for
university entry and a prerequisite for some jobs. Other qualifi-
cations such as the more advanced Scholarship Level and
Special Papers existed for pupils in the post-compulsory school
stage during various periods but were abolished sometime ago.
At other times a range of intermediate qualifications such as the
Advanced Supplementary Level (AS) and the more recent
Advanced Subsidiary (AS) Level have been available to pupils
(the similarity of the titles and abbreviations of these qualifica-
tions often causes confusion). Recently advanced qualifications
such as the International Baccalaureate and Pre U are beginning
to be offered by some schools as alternatives to A' Levels.
Scotland has also experienced substantial variations in advanced
school-level qualifications in recent decades (see Paterson,
2003). These changes are summarised succinctly in a timeline
produced by the Scottish Credit and Qualifications Framework.4
The chequered history of both lower and higher tier school
qualifications, means that care is required when undertaking
secondary analyses of school-level qualification measures. If
the survey dataset contains respondents who gained school-
level qualifications in different time periods, this issue is
especially acute. Even within the same educational cohort
pupils could have gained a mixture of qualifications. For
example, during the early 1980s comprehensive school
pupils in England and Wales frequently undertook a mixture
of O' Levels and CSEs at the age of 16years and might have
undertook a mixture of O' Levels and A' Levels in the fol-
lowing school years. Similarly, in Scotland during the last
decade it was not uncommon for pupils to study a mixture of
Advanced Highers, Highers and Intermediates in the last
stages of school.
In the United Kingdom pupils undertake a portfolio of
school qualifications across a range a subjects. In England,
Wales and Northern Ireland pupils study for many GCSEs
and the award is for the individual subject (e.g. Maths,
English, History, etc.).5 Pupils choose their subjects based on
the prescriptions of their teachers and schools and also to
some extent based on personal and parental choice. This
means that pupils will have studied a reasonably individual-
ised personal portfolio of GCSEs. Therefore, school GCSE
attainment cannot be easily summarised by an obvious single
measure.
In some specialist surveys (e.g. the Youth Cohort Study of
England and Wales) data on individual qualifications and
grades awarded in individual subjects are collected. Each
individual GCSE is awarded a separate grade from A* (the
highest) to G (the lowest grade of pass). The grade is alpha-
betical rather than numerical, therefore there is no single
clear indicator of an individuals' overall level of school
attainment. Gaining five or more GCSEs at grades A*­C is a
standard benchmark and it is used in official reporting (see
Leckie and Goldstein, 2009). This benchmark is routinely
employed in a wide variety of social science applications
(e.g. Connolly, 2006; Gayle et al., 2003; Sullivan et al.,
2011). A limitation of this measure is that it treats an A* in
4 Methodological Innovations
history, a C in maths and a B in geography equally in deter-
mining whether or not a pupil has five GCSEs at grades
A*­C (Gorard and Taylor, 2002). In more recent years, the
UK Government has produced league tables which have also
included a measure of the proportion of pupils in a school
gaining five or more GCSEs at grades A*­C including maths
and English (Taylor, 2011). The addition of achieving grades
A*­C in maths and English does not, however, overcome the
more general obstacle of how best to suitably combine alpha-
betical grades from a portfolio of different GCSE results.
A plausible alternative strategy for measuring GCSE attain-
ment is to construct measures based on scores. There are many
possible scores that could be assigned to the alphabetical grades
ascribed to the levels of GCSE attainment. In line with a
Qualifications and Curriculum Authority (QCA) scoring
method, Croxford et al. (2007: 52) calculated a measure of
GCSE attainment by allocating 7 points for an A*/A, 6 points
for a B, 5 points for a C, 4 points for a D, 3 points for an E, 2
points for an F and 1 point for a G, and therefore producing an
overall score for each pupil's attainment. More recently, a new
set of scores has been proposed,6 although we note that the
scores for each alphabetical GCSE grade are similarly spaced
in both schemes and are therefore unlikely to dramatically alter
observed patterns of attainment. Haque and Bell (2001) con-
verted GCSE attainment into numerical scores and then used
these scores to calculate a mean score for each pupil. Their
method has the potential advantage of taking into account vari-
ations in the number of GCSEs which pupils have undertaken,
which is often a result of school policies. An innovative
approach has recently been developed by Playford and Gayle
(2016) who have studied subject-specific GCSE attainment
using latent class analysis and have identified distinct groups of
pupils based on their attainment across a number of subjects.
We hope that the information presented in the passages
above indicates that there are alternative approaches to using
detailed survey data on school-level qualifications. Some
approaches will be better suited to specific analyses. Our
empirical research leads us to conclude that representing
school-level attainment information in as much resolution as
possible and avoiding the simple categorisation of results is
a favourable analytical approach when the data have suffi-
cient detail (see Connelly et al., 2013; Gayle et al., 2014). We
advise that it is good practice to avoid constructing arbitrary
or ad hoc measures of school-level attainment from existing
social survey data. We suggest that it is preferable, wherever
possible, for data analysts to stick with established measures
(e.g. the QCA scoring methods) as these are transparent,
documented, used by other researchers and are replicable.
Post-school educational institutions and
educational expansion
In Britain the number of pupils staying on in education past
the compulsory school leaving age increased dramatically
through the second half of the 20th century, from around
10% in 1950 to around 70% in 2000 (Clark et al., 2005). This
expansion was associated with growth in both further educa-
tion and higher education (involving University courses).
The expansion in participation in higher education was une-
ven, with general patterns of increase punctuated by two
periods of accelerated expansion. The first period was
between 1963 and 1970 (Walford, 1991). The second period
was between 1988 and 1992 (Bathmaker, 2003). To illustrate
the scale of expansion, official statistics report that there
were 414,000 full-time undergraduate students in 1970/1971
and 1,052,000 in 1997/1998 (Office for National Statistics
(ONS), 2000 Table 3.12). There has been further expansion
in British higher education, for example by the mid-1990s
around 30% of 18- to 19-year-olds in the United Kingdom
were participating in higher education, but this increased to
36% by the end of the 2000s (Higher Education Funding
Council for England (HEFCE), 2010). The expansion of par-
ticipation in British higher education can be illustrated using
social survey data. Using data from the General Household
Survey,7 Figure 1 depicts the variation by age in the probabil-
ity of a respondent having a degree which is the result of the
expansion in higher education.
Post-school educational expansion has led to dramatic
increases in the average levels of educational attainment of
different educational cohorts (Glennerster, 2001; Greenaway
and Haynes, 2003). It is argued that educational expansion
has also led to changes in the relative social value which can
be attributed to educational qualifications, a process some-
times known as `credential inflation' (see Blackburn and
Jarman, 1992; Brown, 1995; Burris, 1983; Clogg and
Shockey, 1984; Groot and Van den Brink, 2000). The creden-
tial inflation thesis predicts that as the supply of highly edu-
cated labour increases, the value of specific educational
qualifications decrease within the labour market (Van de
Werfhorst and Andersen, 2005). Similarly, the social mean-
ing of an educational qualification such as a university
Figure 1. Higher education expansion ­ attainment of a
University Degree by age.
Connelly et al. 5
degree will change over time; this is particularly evident in
the United Kingdom, which has moved from an elite to a
mass system of higher education. These dramatic transfor-
mations in post-school education have substantial implica-
tions for survey data collected from respondents from
different educational cohorts, and secondary data analysts
should, therefore, exercise suitable caution.
Approaches to measuring education in
social surveys
Despite the key importance of education in sociological
research, the practical process of constructing measures from
social survey data is often handled rather cursorily. At least
three broad categories of approach are commonly used to
measure education in survey research. First, measures of the
time spent in education (i.e. years of education). Second, tax-
onomies of the highest educational qualifications held
(Schneider, 2010). Third, scaling techniques which attribute
scores to the highest educational qualifications held (Buis,
2010). We critically evaluate each of these three approaches
in this section.
Years of education
Many social surveys include a measure of years of full-
time education completed (Schneider, 2011). This meas-
ure is routinely included in analyses (see Eikemo et al.,
2008; Kunovich and Slomczynski, 2007). As metric
measures of education these are particularly attractive
within statistical modelling approaches as they can be
added to regression models as continuous covariates (see
Treiman, 2009: 382). Measures of years of education are
particularly popular in economics where an attempt to
represent educational assets gradationally often fits
neatly with theories or analyses of incremental returns to
human capital (see Harmon et al., 2003). It is common-
place for economists to convert categorical data on a
respondent's highest qualification into a measure of time
spent in education, on the basis of external information
about the average time in education for each qualification
(see Dearden et al., 2002).
A potential limitation of using measures of years in full-
time education is that it may not necessarily work well as a
proxy for educational attainment. In Britain, for example,
qualifications with very different levels often require a simi-
lar amount of time in education due to the structure and
organisation of the educational year. This can be a significant
shortcoming for using years of education as a measure, as it
risks conflating different qualifications that may provide dif-
ferent competencies and have a different value in the labour
market (see Dearden et al., 2002). Hoffmeyer-Zlotnik and
Warner (2013) warn that in practice, measures of years of
education are only weakly associated with measures of edu-
cational qualifications (p. 106).
Qualification-based categorizations
Qualification-based measures provide more detailed infor-
mation about formal educational experiences, the courses
and subjects studied, and the vocational or academic nature
of the education undertaken. It is often assumed that as a
result qualification based measures provide additional infor-
mation on the education which an individual has attained.
For example, the signals which the qualifications held might
send to potential employers. Frequently, social surveys ask
individuals to describe the highest qualification that they
hold (either by providing a textual description of the qualifi-
cation or by choosing one option from a selection of catego-
ries). In addition, some surveys include extensive questioning
in order to enumerate all of the respondent's formal qualifi-
cations and the grades attained for their qualification(s)
(Jenkins and Siedler, 2007; Schneider, 2011). Given the large
number of qualifications available in countries like the
United Kingdom, it is generally necessary for researchers to
reduce this information into an education measure with a
much smaller number of categories (see Schneider, 2011).
Survey data analysts generally focus upon the highest quali-
fication which a respondent holds when analysing adult
samples.
A common approach to educational measurement is to
make use of the `derived' measures deposited with social
survey datasets. These summary measures of qualification
categories are prepared by the data depositors (Schneider,
2011). Unfortunately, there are substantial variations from
survey to survey in the content, format and quality of the
derived educational measures. For example, the BHPS gen-
erated a 12 category typology of highest educational qualifi-
cation.8 This measure is not the same as the highest
educational qualification measure deposited with either the
Labour Force Survey9 or the General Household Survey.10
Therefore, consideration is still required when using a
derived educational measure that has been deposited with a
large-scale dataset because the measure might not be readily
comparable across surveys.
In order to promote a standardised measurement instru-
ment for education, the ONS has suggested a taxonomy of
qualifications with three categories (degree level and above,
other and none; ONS, 2005). Schneider (2011) highlights the
obvious point that such a simple classification does not rep-
resent the full variety of educational qualifications and levels
of attainment in education within the United Kingdom. We
are convinced that the diverse range of qualifications placed
within the same category of this crude measure will lead to a
large degree of unhelpful within-category variation.
Therefore, the ONS educational measure is likely to be sub-
optimal for almost all empirical social science analyses.
The National Vocational Qualification (NVQ) levels pro-
vide another approach to categorising UK qualifications.
Due to concerns over the complexity of vocational qualifica-
tions in the late 1980s, the National Council for Vocational
6 Methodological Innovations
Qualifications developed a new framework of vocational
qualifications called NVQs (Jenkins and Sabates, 2007).
Although the original NVQ qualifications have been
replaced, researchers such as Dearden et al. (2002) have
found the NVQ levels useful for classifying both vocational
and academic qualifications into a convenient scheme for
empirical research. Examples of qualifications and their
NVQ levels are shown in Table 1.
There are other well-known recommendations for catego-
rising educational qualifications, which are available. Two
prominent examples are the `Comparative Analysis of Social
Mobility in Industrial Nations' (CASMIN) classification of
education (Brauns et al., 2003) and the `International
Standard Classification of Education' (ISCED; UNESCO,
1997, 2012). CASMIN (see Table 2) contains nine categori-
cal levels and differentiates between academic and voca-
tional qualifications. By contrast, ISCED contains seven
levels, with further sub-categories within each level, but also
incorporates academic and vocational skills (see Table 3).
CASMIN and ISCED are specifically designed to permit
cross-national comparisons and have been successfully used
in large-scale comparative projects (e.g. Blossfeld and
Hofmeister, 2005; Breen, 2004; Heath et al., 2007). In the
United Kingdom the BHPS has deposited CASMIN and
ISCED along with other educational measures, an example
of good practice that other large-scale social surveys could
also usefully adopt.
CASMIN and ISCED measures could also be deployed in
national level analyses, although at the current time this
approach is not widely used. Using these measures might
help to overcome the general problem of different measures
being deposited with different large-scale surveys. For
within-country analyses there may also be benefits to devel-
oping similar theoretically informed but nationally specific,
standardised educational categorizations. Although the
methodologies behind such new measures must be
theoretically informed and well thought through, they must
be appropriately documented and must not be developed on
an ad hoc basis.
Despite their ubiquity in large-scale surveys there are
limitations to undertaking analyses using categorical educa-
tional qualification measures. Many qualification measures
have large numbers of categories which can be cumbersome
to work with. Educational measures with many levels rou-
tinely have some sparse categories, even when sample sizes
are relatively large. In practice, researchers will often want to
make comparisons between respondents with different edu-
cation levels, which are more difficult with measures with a
large number of categories. In our experience interpreting
the influence of an interaction between a categorical educa-
tional measure and another explanatory variable can be tax-
ing especially when both measures have a large number of
categories. The use of scales is an obvious strategy for
addressing this problem,11 this is the focus of the next
section.
Scaling education measures
Another approach to the analysis of educational qualifica-
tions involves developing scales based upon some relevant
criteria. For example a qualification might be ranked by the
average income of workers with that certain level of educa-
tion.Treiman (1977, 2007, 2009) has advocated this approach
which is sometimes called `effect proportional scaling'. Buis
(2010) has demonstrated a variety of methods for producing
scales of education, based upon the association between edu-
cational qualifications and other outcomes, for example
income and occupational positions. Buis (2010) and Lambert
(2012) advocate scoring educational qualifications because a
large number can be attributed to a single scale. In a statisti-
cal modelling framework scoring offers a parsimonious way
of summarising detailed educational data. In our experience
Table 1. Examples of UK educational qualifications and their NVQ level.
NVQ level Example qualifications
Academic
qualifications
1 CSE below grade 1
2 O' Level, GCSE grades A*­C, CSE grade 1
3 A' Level, Scottish Certificate of 6th Year Studies, SCE Higher, AS Level
4 Diploma in Higher Education
5 First Degree, Higher Degree
Vocational
qualifications
1 SCOTVEC National Certificate Modules, NVQ Level 1, GNVQ Foundation,
City and Guilds Part 1, BTEC First Certificate
2 NVQ Level 2, GNVQ Intermediate, City and Guilds Part 2, BTEC First Diploma
3 NVQ Level 2, GNVQ Advanced, City and Guilds Part 3, ONC, OND
4 NVQ Level 4, HNC, HND
5 NVQ Level 5
NVQ: National Vocational Qualification; CSE: Certificate of Secondary Education; GCSE: General Certificate of Secondary Education; SCE: Scottish
Certificate of Education; SCOTVEC: Scottish Vocational Education Council; GNVQ: General National Vocational Qualification; BTEC: Business and
Technician Education Council; ONC: Ordinary National Certificate; OND: Ordinary National Diploma; HNC: Higher National Certificate; HND: Higher
National Diploma.
Connelly et al. 7
interpreting the influence of an interaction between a metric
educational measure and another explanatory variable can be
more straightforward than interpreting an interaction between
two categorical variables (especially when one or both meas-
ures have a large number of categories). Despite these attrac-
tive properties a cursory review of existing studies leads us
to conclude that approaches which scale education are not
popular in secondary social survey data analyses within con-
temporary sociology, but as Treiman (1977, 2007, 2009)
demonstrates in some empirical inquiries scales may be
beneficial.
Scaling approaches are not without limitations, Chauvel
(2002) for instance argues that the nature of educational
attainment is too complex, heterogeneous and multi-dimen-
sional to be represented on a unidimensional scale. He con-
cludes that scaling educational attainment may therefore
hide complex qualitative differences between individuals.
We recognise that this is a justifiable methodological point.
Buis (2010) and Lambert (2012) however provide extended
exploratory analyses that persuade us that in practice, for
many research purposes, this is not a serious limitation to
using a scaling approach.
Table 2. The Comparative Analysis of Social Mobility in Industrial Nations (CASMIN) with UK qualification examples (Schneider, 2011).
Description UK qualification examples
1a Inadequately completed general elementary education No qualification
1b Inadequately completed general elementary education GCSE grades D­G, SCE standard grades 4­7
1c Basic vocational qualification or general elementary
education and basic vocational qualification
Basic Skills qualification, Key Skills qualification,
 City and Guilds other, RSA other,
 SCOTVEC modules or equivalent, BTEC first or general
certificate, GNVQ/GSVQ foundation level, NVQ/SVQ
Level 1 or equivalent
2a Intermediate vocational qualification or intermediate
general education plus basic vocational qualification
BTEC/SCOTVEC first or general diploma, City and
Guilds craft, RSA diploma, GNVQ intermediate, NVQ/
SVQ Level 2 or equivalent
2b Intermediate general qualification GCSE grade A­C or equivalent, SCE standard grades 1­3
2c
(Vocational)
Intermediate general qualification OND/ONC, BTEC/SCOTVEC national, GNVQ
advanced, NVQ/SVQ Level 3
2c
(General)
Full general maturity certificate AS level or equivalent, A' Level or equivalent, SCE higher
or equivalent, Scottish 6th Year Certificate (CSYS)
3a Lower tertiary certificate HNC/HND, BTEC higher etc., NVQ/SVQ Level 4
3b Higher tertiary certificate University/CNAA Bachelor Degree, Higher Degree,
Doctorate, NVQ/SVQ Level 5
GCSE: General Certificate of Secondary Education; SCE: Scottish Certificate of Education; RSA: The Royal Society of Arts; SCOTVEC: Scottish Vocational
Education Council; BTEC: Business and Technician Education Council; GNVQ: General National Vocational Qualification; GSVQ: General Scottish Voca-
tional Qualifications; NVQ: National Vocational Qualification; SVQ: Scottish Vocational Qualification; OND: Ordinary National Diploma; ONC: Ordinary
National Certificate; CSYS: Certificate of Sixth Year Studies; HNC: Higher National Certificate; HND: Higher National Diploma; CNAA: Council for
National Academic Awards.
Table 3. The 2011 International Standard Classification of Education 1997 (ISCED) (UNESCO, 1997).
Description
0 Pre-primary
education
The initial stage of organised instruction, school or centre based, designed for children aged at
least 3years
1 Primary education Begins between 5 and 7years of age, start of compulsory education
2 Lower secondary
education
Continues the basic programmes of the primary level, although teaching is typically more subject-
focused. Usually, the end of this level coincides with the end of compulsory education
3 Upper secondary
education
Generally begins at the end of compulsory education. The entrance age is typically 15 or 16years.
It requires entrance qualifications. Instruction is often more subject-oriented than at ISCED Level 2
4 Post-secondary
non-tertiary
education
Between upper secondary and tertiary education. This level serves to broaden the knowledge of
ISCED Level 3 graduates. Typical examples are programmes designed to prepare pupils for studies
at Level 5 or programmes designed to prepare pupils for direct labour market entry
5 Tertiary education
(first stage)
Entry to these programmes normally requires the successful completion of ISCED Level 3 or 4
6 Tertiary education
(second stage)
Reserved for tertiary studies that lead to an advanced research qualification (i.e. PhD or doctorate)
8 Methodological Innovations
Credential inflation is a particularly difficult issue to deal
with when categorical schemes of educational qualifications
are used. Scaling approaches have the attraction of allowing
the adjustment of scores to reflect changes between educa-
tional cohorts. For example, the score attributed to a degree
level qualification could be set lower for more recent educa-
tional cohorts, in order to recognise the relative growth in
graduate level education. We note that a useful alternative
method to combating credential inflation has been demon-
strated by Tam (2007). This approach is called a Positional
Status Index (PSI), and scores represent the percentage of
other survey respondents that an individual has to overtake in
order to reach their educational level. The PSI approach pro-
vides a within educational cohort measure and therefore
lends itself towards providing increased control for creden-
tial inflation. Bukodi and Goldthorpe (2013) have success-
fully employed this approach when analysing data from three
British birth cohorts covering different educational
periods.12
Conclusion
Measures of education are essential components of many
sociological analyses and are powerful predictors of a diverse
range of social outcomes. We began this article with the
claim that education is more difficult to measure than is often
assumed. We have tried to draw attention to some hidden
challenges associated with undertaking analyses, which
include educational measures. We conclude by making the
recommendation that researchers place careful thought into
which educational measure (or measures) they select when
analysing survey data.
In nations such as the United Kingdom, the education sys-
tem and qualifications appear to almost be in a constant state
of flux. We have highlighted that these changes have genuine
influences on education data. It is important for survey data
analysts to consider the educational context in which survey
respondents undertook their education. We advise against
researchers developing ad hoc educational measures which
do not facilitate comparability across studies and which do
not support reliable and valid replications. When social sur-
veys contain a number of competing measures, or when
researchers can produce different measures, we argue that
they should undertake sensitivity analyses which evaluate
the merits of different educational measures. As a routine
part of their analytical programme researchers should make
their sensitivity analyses public, for example in data supple-
ments, on web pages or in institutional repositories.
In circumstances where survey data analysts construct
new educational measures, it is desirable that they place
effort into clearly documenting the theoretical basis of the
measures and how they were practically constructed. It is
also important that these details are preserved and made
available to the wider research community. These practices
chime squarely with efforts to introduce more replicability
and with an atmosphere of `open data' in the social sciences
(see Freese, 2007). There have already been a few efforts in
the social sciences to bring together documentation and
metadata about the construction of educational measures
(Ganzeboom and Treiman, 1992; Lambert et al., 2011). We
suggest that these good practices should be encouraged.
These activities should support researchers in being better
positioned to operationalise and compare the properties of
multiple relevant measures. These are good habits which
have the potential to bring long-term improvements in the
way in which data on education is used in social science
research.
Declaration of conflicting interests
The author(s) declared no potential conflicts of interest with respect
to the research, authorship, and/or publication of this article.
Funding
The author(s) received no financial support for the research, author-
ship, and/or publication of this article.
Notes
1. Influential examples include the Youth Cohort Study of
England and Wales, the Longitudinal Study of Young People in
England and the Scottish School Leavers Survey (see Murray
and Gayle, 2012). There are also specialist cross-national
education studies (e.g. Program for International Student
Assessment (PISA), The Trends in International Mathematics
and Science Study (TIMSS) and Progress in International
Reading Literacy Study (PIRLS; Brown et al., 2007).
2. In the United Kingdom school refers to the education com-
pleted within primary and secondary school institutions. These
schools are attended by pupils between the ages of 5years and
18
years (pupils move from primary to secondary schools at
around the age of 11
years). Secondary schools can include
pupils who have completed their compulsory education, who
remain in secondary school to complete higher school-level
school qualifications (which are required to gain entry into
higher education). The term further education refers to edu-
cation completed in addition to compulsory school educa-
tion. Further education qualifications often have a vocational
orientation. Higher education refers to education completed
in addition to compulsory school education, which is more
demanding than secondary school education and further edu-
cation. Higher education is most usually completed within a
university setting (and will lead to a degree).
3. For contemporary educational cohorts, the Education and
Skills Act 2008 increased the minimum age at which young
people in England can leave school or formal training. From
2013 young people had to remain in education until they
reached the age of 17years, and from 2015 young people must
remain in education or training until the age of 18years. The
school leaving age currently remains at 16years in the rest of
the United Kingdom.
4. http://www.scqf.org.uk/content/files/Old%20Vs%20New%20
%28low%20res%29%20-%20Updated%20July%202013.pdf.
5. In Scotland pupils also study for a range of subjects, and
grades are awarded for each individual subject however, the
Connelly et al. 9
examinations undertaken are different. The same problems
described in this section emerge from the analysis of school
examinations in Scotland.
6. See http://www.education.gov.uk/schools/performance/2011/
secondary_11/PointsScoreAllocation2011.pdf.
7. Office for National Statistics. Social and Vital Statistics
Division, General Household Survey, 2006 [computer file].
3rd Edition. Colchester, Essex: UK Data Archive [distribu-
tor], February 2009. SN: 5804, http://dx.doi.org/10.5255/
UKDA-SN-5804-1.

8. See: https://www.iser.essex.ac.uk/bhps. Variable name:
wQFEDHI.
9. See: http://www.ons.gov.uk/ons/guide-method/method-qual-
ity/specific/labour-market/labour-market-statistics/index.
html. Variable name: EDLEV00.
10. See: http://discover.ukdataservice.ac.uk/series/?sn=200019.
Variable name: HIQUAP.
11. See for example Strand (2014).
12. We would also like to draw attention to recent analysis in which
Connelly and Gayle (2014) have successfully used a Positional
Status Index (PSI) approach to operationalise parental social
class in an analysis of three birth cohorts.
References
Ainley P (1988) From School to the YTS: Education and Training
in England and Wales, 1944­1987. Milton Keynes: Open
University Press.
Bathmaker AM (2003) The expansion of higher education: A con-
sideration of control, funding and quality. In: Bartlett S and
Burton D (eds) Education Studies: Essential Issues. London:
SAGE, pp. 169­189.
Berthoud R and Gershuny J (2000) Seven Years in the Lives of
British Families: Evidence on the Dynamics of Social Change
from the British Household Panel Survey. Bristol: The Policy
Press.
Blackburn RM and Jarman J (1992) Changing inequalities in access to
highereducation.Workingpaperno.12.Cambridge:Sociological
Research Group, University of Cambridge.
Blossfeld H and Hofmeister H (2005) GLOBALIFE ­ Life Courses
in the Globalization Process: Final Report. Bamberg: Faculty
of Social and Economic Science, Otto-Friedrich-University of
Bamberg.
Bolton P (2012) Education: Historical Statistics. House of
Commons Library, London.
Brauns H, Scherer S and Steinmann S (2003) The CASMIN edu-
cational classification in international comparative research.
In: Hoffmeyer-Zlotnik JHP and Wolf C (eds) Advances in
Cross-National Comparison: A European Working Book
for Demographic and Socio-Economic Variables. London:
Kluwer, pp. 221­244.
Breen R (ed.) (2004) Social Mobility in Europe. Oxford: Oxford
University Press.
Breen R and Jonsson JO (2005) Inequality of opportunity in com-
parative perspective: Recent research on educational attain-
ment and social mobility. Annual Review of Sociology 31:
223­243.
Brown DK (1995) Degrees of Control: A Sociology of Educational
Expansion and Occupational Credentialism. New York:
Teachers College Press.
Brown G, Micklewright J, Schnepf SV, et al. (2007) International
surveys of educational achievement: How robust are the
findings? Journal of the Royal Statistical Society: Series A,
Statistics in Society 170(3): 623­646.
Buis ML (2010) Inequality of educational outcome and inequality
of educational opportunity in the Netherlands during the 20th
century. PhD Dissertation, VU University, Amsterdam.
Bukodi E and Goldthorpe JH (2013) Decomposing `social origins':
The effects of parents' class, status, and education on the edu-
cational attainment of their children. European Sociological
Review 29(5): 1024­1039.
Burris V (1983) The social and political consequences of overedu-
cation. American Sociological Review 48(4): 454­467.
Card D (1999) The causal effect of education on earnings. Handbook
of Labor Economics 3: 1801­1863.
Chauvel L (2002). `Educational Inequalities: Distribution of
Knowledge, Social Origins and Social Outcomes'. In Lemel
Y and Noll HH (Eds), Changing Structures of Inequality: A
Comparative Perspective (pp. 219­249). Montreal: McGill-
Queens UP.
Clark D, Conlon G and Galindo-Rueda F (2005) Post-Compulsory
education and qualification attainment. In: Hansen K and
Vignoles A (eds) What's the Good of Education? The
Economics of Education in the UK. Princeton, NJ: Princeton
University Press, pp. 71­98.
Clogg CC and Shockey JW (1984) Mismatch between occupation
and schooling: A prevalence measure, recent trends and demo-
graphic analysis. Demography 21(2): 235­257.
Connelly R and Gayle V (2014) Are there changing socio-eco-
nomic inequalities in childhood cognitive test performance?
Analysis of three British Birth Cohort Studies. In: Centre for
population change seminar series, University of Edinburgh.
Available at: http://www.cpc.ac.uk/seminars/?link=home.
php&id=157
Connelly R, Murray SJ and Gayle V (2013) Young people and
school GCSE attainment: Exploring the `middle'. Sociological
Research Online 18(1): 6.
Connolly P (2006) The effects of social class and ethnicity on gen-
der differences in GCSE attainment: A secondary analysis of
the Youth Cohort Study of England and Wales 1997­2001.
British Educational Research Journal 32(1): 3­21.
Croxford L, Ianelli C and Shapira M (2007) Documentation of the
youth cohort time-series datasets (ed Centre For Educational
Sociology). Available at: http://www.esds.ac.uk/doc/5765/
mrdoc/pdf/5765userguide.pdf
Dearden L, McIntosh S, Myck M, et al. (2002) The returns to aca-
demic and vocational qualifications in Britain. Bulletin of
Economic Research 54(3): 249­274.
Department of Education (1985) General Certificate of Secondary
Education: A General Introduction. London: Her Majesty's
Stationery Office.
Desai S and Alva S (1998) Maternal education and child health:
Is there a strong causal relationship? Demography 35(1):
71­81.
Eikemo TA, Huisman M, Bambra C, et al. (2008) Health ine-
qualities according to educational levels in different welfare
regimes: A comparison of 23 European countries. Sociology
of Health & Illness 30(4): 565­582.
Freese J (2007) Replication standards for quantitative social sci-
ence: Why not sociology? Sociological Methods & Research
36(2): 153­172.
10 Methodological Innovations
Ganzeboom HBG and Treiman DJ (1992) International
Stratification and Mobility File: Conversion Tools (Version
92-08-25). Utrecht: Department of Sociologie.
Gayle V, Berridge D and Davies RB (2003) Econometric Analysis
of the Demand for Higher Education. Nottingham: Department
for Education and Skills.
Gayle V, Murray S and Connelly R (2014) Young people and
school General Certificate of Secondary Education attain-
ment: Looking for the `missing middle'. British Journal of
Sociology of Education. Epub ahead of print 15 August. DOI:
10.1080/01425692.2014.935292.
Glennerster H (2001) United Kingdom education 1997­2001.
CASE paper 50, November. London: Centre for Analysis of
Social Exclusion.
Gorard S and Taylor C (2002) What is segregation? A compari-
son of measures in terms of `strong' and `weak' compositional
invariance. Sociology 36(4): 875­895.
Greenaway D and Haynes M (2003) Funding higher education in
the UK: The role of fees and loans. The Economic Journal
113: F150­F167.
Groot W and Van den Brink HM (2000) Overeducation in the labor
market: A meta-analysis. Economics of Education Review
19(2): 149­158.
Haque Z and Bell JF (2001) Evaluating the performances of minor-
ity ethnic pupils in secondary schools. Oxford Review of
Education 27(3): 357­368.
Harmon C, Oosterbeek H and Walker I (2003) The returns to edu-
cation: Microeconomics. Journal of Economic Surveys 17(2):
115­156.
Hartog J (2000) Over-education and earnings: Where are we, where
should we go? Economics of Education Review 19(2): 131­
147.
Heath AF, Cheung SY and Smith SW (2007) Unequal Chances:
Ethnic Minorities in Western Labour Markets. Oxford: Oxford
University Press.
Higher Education Funding Council for England (HEFCE) (2010)
Trends in young participation in higher education: Core
results for England. Issues paper 2010/03, January. London:
HEFCE.
Hoffmeyer-Zlotnik JHP and Warner U (2013) Harmonising
Demographic and Socio-Economic Variables for Cross-
National Comparative Survey Research. Berlin: Springer.
Institute for Social and Economic Research (2010) British
Household Panel Survey, Waves 1-18, 1991­2009 (Computer
file, SN5151). Colchester: UK Data Archive.
Jenkins A and Sabates R (2007) The Classification of Qualifications
in Social Surveys. London: Centre for Longitudinal Studies,
Institute of Education, University of London.
Jenkins S and Siedler T (2007) Using Household Panel Data to
Understand the Intergenerational Transmission of Poverty.
Colchester: Institute for Social and Economic Research.
KidnerC(2013)Curriculumforexcellence.Availableat:http://www.
scottish.parliament.uk/ResearchBriefingsAndFactsheets/S4/
SB_13-13.pdf
Kunovich S and Slomczynski KM (2007) Systems of distribution
and a sense of equity: A multilevel analysis of meritocratic
attitudes in post-industrial societies. European Sociological
Review 23(5): 649­663.
Kunst AE and Mackenbach JP (1994) The size of mortality differ-
ences associated with educational level in nine industrialized
countries. American Journal of Public Health 84(6): 932­937.
Lambert PS (2012) Comparative scaling of educational categories
by homogamy ­ Analysis of UK data from the BHPS. Technical
paper 2012-1 of the DAMES node, Data Management through
e-Social Science, January. Stirling: University of Stirling.
Lambert PS, Warner G, Doherty T, et al. (2011) Collaborative
Systems for Enhancing the Analysis of Social Surveys: The
Grid Enabled Specialist Data Environments. Brussels: New
Techniques and Technologies for Statistics.
Leckie G and Goldstein H (2009) The limitations of using school
league tables to inform school choice. Journal of the Royal
Statistical Society: Series A, Statistics in Society 172(4):
835­851.
Lindeboom M, Llena-Nozal A and van Der Klaauw B (2009)
Parental education and child health: Evidence from a school-
ing reform. Journal of Health Economics 28(1): 109­131.
Lucas SR (2001) Effectively maintained inequality: Education
transitions, track mobility, and social background effects.
American Journal of Sociology 106(6): 1642­1690.
Mobley M, Emerson C, Goddard I, et al. (1986) All about GCSE
­ A Clear and Concise Summary of All the Basic Information
about GCSE. London: Heinemann.
Murray S and Gayle V (2012) Youth transitions. Survey ques-
tion bank: Topic overview 8. Survey Resources Network.
Available at: http://www.surveynet.ac.uk/sqb/topics/youth/
sqb_youthtransitions_murray_gayle.pdf
Noah HJ and Eckstein MA (1992) The two faces of examinations:
A comparative and international perspective. In: Eckstein
MA and Noah HJ (eds) Examinations: Comparative and
International Studies. Oxford: Pergamon Press, pp. 147­170.
North J (1987) The GCSE: An Examination. London: Claridge
Press.
Office for National Statistics (2000) Social Trends 30. London:
Office for National Statistics.
Office for National Statistics (2005) Harmonised Concepts and
Questions for Social Data Sources: Primary Standards.
London: Office for National Statistics.
Paterson L (2003) Scottish Education in the Twentieth Century.
Oxford: Oxford University Press.
Paterson L and Iannelli C (2007) Social class and educational attain-
ment: A comparative study of England, Wales, and Scotland.
Sociology of Education 80(4): 330­358.
Playford CJ and Gayle V (2016) The concealed middle? An explo-
ration of ordinary young people and school GCSE subject area
attainment. Journal of Youth Studies. 19(2): 149­168.
Ross CE and Wu C-L (1995) The links between education and health.
American Sociological Review 60(5): 719­745.
Schneider SL (2010) Nominal comparability is not enough: (In-)
Equivalence of construct validity of cross-national measures
of educational attainment in the European Social Survey.
Research in Social Stratification and Mobility 28(3): 343­357.
Schneider SL (2011) Measuring educational attainment. Survey
question bank: Topic overview 6. Available at: http://sur-
veynet.ac.uk/sqb/topics/education/sqb_education_schneider.
pdf
Strand S (2014) Ethnicity, gender, social class and achievement
gaps at age 16: Intersectionality and `Getting it' for the
white working class. Research Papers in Education 29(2):
131­171.
Sullivan A, Heath A and Rothon C (2011) Equalisation or inflation?
Social class and gender differentials in England and Wales.
Oxford Review of Education 37(2): 215­240.
Connelly et al. 11
Tam T (2007) A paradoxical latent structure of educational ine-
quality: Cognitive ability and family background across
diverse societies. Paper presented at the conference on social
inequality and mobility in the process of social transforma-
tion, international sociological association RC28, Brno,
24­27 May.
Taylor J (2011) The English Baccalaureate: How not to meas-
ure school performance. Available at: http://eprints.lancs.
ac.uk/49044/4/EnglishBaccalaureate.pdf
Treiman DJ (1977) Occupational Prestige in Comparative
Perspective. New York: Academic Press.
Treiman DJ (2007) The legacy of apartheid: Racial inequalities
in the New South Africa. In: Heath AF, Cheung SY and
Smith SW (eds) Unequal Chances: Ethnic Minorities in
Western Labour Markets. Oxford: Oxford University Press,
pp .403­450.
Treiman DJ (2009) Quantitative Data Analysis: Doing Social
Research to Test Ideas. San Francisco, CA: John Wiley & Sons.
Trowler P (2003) Education Policy. London: Routledge.
UNESCO (1997) International Standard Classification of Education:
ISCED 1997. Montreal, QC, Canada: UNESCO-UIS.
UNESCO (2012) International Standard Classification of
Education: ISCED 2011. Montreal, QC, Canada: UNESCO
Institute for Statistics.
Van de Werfhorst HG and Andersen R (2005) Social back-
ground, credential inflation and educational strategies. Acta
Sociologica 48(4): 321­340.
Walford G (1991) Changing relationship between government and
higher education in Britain. In: Neave G and Van Vught FA
(eds) The Changing Relationship between Government and
Higher Education in Western Europe. Oxford: Pergamon
Press, pp. 165­183.
