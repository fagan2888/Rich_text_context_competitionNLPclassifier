https://doi.org/10.1177/2053168017702990
Research and Politics
April-June 2017: 1
­7
© The Author(s) 2017
Reprints and permissions:
sagepub.co.uk/journalsPermissions.nav
DOI: 10.1177/2053168017702990
journals.sagepub.com/home/rap
Creative Commons Non Commercial CC BY-NC: This article is distributed under the terms of the Creative Commons
Attribution-NonCommercial 4.0 License (http://www.creativecommons.org/licenses/by-nc/4.0/) which permits non-commercial
use, reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and
Open Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).
Introduction
With the rise of social media, concerns have been raised
as to the extent to which people can use the customizabil-
ity of networks to insulate themselves from undesirable
content (Pariser, 2012). This concern is built on two
assumptions: first, that people do not want to see certain
types of content (political content, partisan content from
the other side, etc.); and second, that people are able to
effectively sort out less desired content from content they
are more interested in or amenable to. While a great deal
of evidence exists confirming the first assumption
(Arceneaux et al., 2013; Garrett, 2009; Graf and Aday,
2008; Stroud, 2008), the second assumption is less clear.
In order to opt out of unwanted content, people have to
effectively eliminate it from their attention in some way.
This can happen in terms of exposure--people can unfriend
or unfollow types of information flows they dislike on
social media (Bode, 2016a)--but it can also happen in less
extreme ways. Rather than opting out of whole streams of
information within social media, people can simply skip
over content in their feed that they are not interested in
(Thorson et al., 2014). This gets at the heart of selective
attention--picking and choosing among the information to
which you are exposed, choosing to pay attention to only
some types of content while ignoring others.
Within social media, political content is particularly
likely to be subject to these selective attention pressures.
Despite scholars' interest in the democratic value of politi-
cal content on social media, it tends to be a salient, disliked,
and oft-avoided form of content (Bode, 2016a; Vraga et al.,
2015b; Vraga et al., 2016b). Yet little is known about how
selective attention on social media occurs.
As part of the process of selective attention, people
should respond to cues signaling the goal of the content
being read. When those cues are prominent and easily
understood--for example, featuring a political picture or a
partisan word--users should be able to easily identify and
avoid content they do not like.
Of course, selective attention is more difficult to study
than selective exposure. Exposure is often asked via self-
reports (Bode, 2012; Kim et al., 2013), whereas attention is
harder to capture in this way. Attention is also more
nuanced--people might start reading a particular post and
stop only once they realize they are not interested. This
would still count as exposure, but the question of how much
Skipping politics: Measuring avoidance
of political content in social media
Leticia Bode1, Emily K. Vraga2 and Sonya Troller-Renfree3
Abstract
Selective exposure is a growing concern as people become more reliant on social media for political information. While
self-reports often ask about exposure to political content on social media, existing research does not account for the
fact that even those exposed to political content may still choose to ignore it. To effectively account for this, we employ
corneal eye tracking software, such that we can observe users' gaze and the amount of time they actually spend with
political content. Consistent with expectations, the earlier a cue that a post is political, the faster a user skips over it.
This trend is concentrated among those least interested in politics. Implications for how we think about social media and
political information flows in the modern media environment are discussed.
Keywords
Selective exposure, social media, eye tracking, selective avoidance, political information
1Georgetown University, Washington, District of Columbia, USA
2George Mason University, Fairfax, Virginia, USA
3University of Maryland, College Park, Maryland, USA
Corresponding author:
Leticia Bode, Georgetown University, 3520 Prospect St NW Suite 311,
Washington DC 20007, USA.
Email: lb871@georgetown.edu
702990
RAP0010.1177/2053168017702990Research & PoliticsBode et al.
research-article2017
Research Article
2 Research and Politics 
attention has been paid is more complicated to answer. This
study seeks to fill in this gap, to better understand how peo-
ple avoid political information on social media.
To do so, we expose individuals to a simulated Facebook
feed, comprising posts on a range of social, news, and polit-
ical topics. We then use eye tracking technology to observe
how much time they spend with different types of political
posts and what encourages them to skip over political con-
tent more or less quickly. This allows us to determine not
just exposure to politics on social media, which is constant
for all of our subjects, but instead measure attention to such
content, which varies by individual.
Literature review
In general, people just do not like politics (Eliasoph, 1998).
As a result, most people do not produce political content on
social media (Duggan and Smith, 2016), and many report
disliking the presence of politics on social media (Vraga
et al., 2015b). However, they do see political content on
social media from their friends even when they are not nec-
essarily looking for it (Bode, 2016b; Duggan and Smith,
2016; Kim, et al., 2013), although previous research sug-
gests such incidental exposure may not garner much atten-
tion to political posts (Vraga et al., 2016b). This may result
from individuals' motivation to avoid disliked content
(Stroud, 2008; Taber and Lodge, 2006), which suggests
they will be able to effectively ignore unpalatable political
content on social media.
But what helps people realize that content is political? In
general, people use cues to stand in for more complicated
information. Known as heuristics or information shortcuts,
when considering politics or political candidates, these
cues include economic conditions, partisan identification,
ideology, race, and gender (Atkeson, 2003; Grofman, 1995;
Kuklinski and Hurley, 1994; Popkin, 1994). In the cacoph-
ony that is social media, cues should be even more impor-
tant to direct individuals towards or away from certain
types of content, depending on their interests.
We think there are three main cues that could alert read-
ers to the political-ness of content. First, there are political
words in each political post. Identifiers like political par-
ties, recognizable politicians, or political institutions should
offer a red flag that the post is political. The earlier those
words occur, the more effectively users can skip over
them--therefore earlier political words should mean less
time spent with a post (H1A). Second, the more such words
occur in a post, the more cues are available to a reader that
the content is political. This, too, then, should lead to the
ability to skip and therefore less time spent with the content
(H1B). Finally, posts that include outside links also include
pictures. Some, but not all, of these pictures are identifiably
political--most often showing a known political figure like
John Boehner or Hillary Clinton. These pictures should
also serve as a cue that the post is political, and political
pictures should therefore lead to more skipping, or less time
spent on the post (H1C).
Additionally, this desire to skip content should depend
on the extent to which people dislike the content. While
many people prefer to ignore politics, some are quite
interested in it (Zaller, 1992), and people are known to
tailor their media choices to consume more politics if they
are interested, and less politics if they are uninterested
(Prior, 2007). For this reason, we expect that those lowest
in political interest should be more sensitive to political
cues and thus spend less time with political content when
these political cues (including first political word (A),
number of political words (B), and presence of political
pictures (C)) are present (H2).
Finally, we test whether the presence of political cues
intersects with the tone taken in the political post. A long
line of research has debated the benefits and drawbacks of
negative politics (see Lau and Rovner, 2009 for a sum-
mary). While we cannot weigh in on every aspect of this
debate--we cannot say anything about its effects on turn-
out, trust, etc.--we can test what draws attention. Because
the literature is mixed, we phrase this as a research ques-
tion, asking whether people will spend more time on posi-
tive or negative posts (RQ1), and whether this relationship
will be moderated by the placement and salience of politi-
cal cues, such as the placement of the first political word
in text, the number of political words in a post, or the
inclusion of a political picture (RQ2).
Methods
To answer these questions, we pair two methods: corneal
eye tracking and surveys.
Eye tracking
Eye tracking is a well-validated measure of attention to
content (Duchowski, 2002; Pan et al., 2004), offering
insight into precisely when people turn their attention from
one post to another. This allows us to `watch' respondents'
attentional patterns, without relying on unreliable self-
reports of attention, which are often flawed through inac-
curate recall, unconscious processing, social desirability,
and a tendency to rely on inferences of attention based on
interest (Nisbett and Wilson, 1977; Prior, 2009; Schwarz
and Oysermann, 2001; Vraga et al., 2015a).
Participants were allowed to scroll through 35 pages of
a simulated Facebook feed, consisting of 120 posts about
news, social or personal posts, and politics at their own
pace, and were encouraged to view the posts as if they were
scrolling through their own Facebook News Feed (analysis
is restricted to only those who had Facebook to ensure this
experience was as natural as possible)1. Two versions of the
task were used to guarantee that the same posts did not
always occur together, which could have influenced
Bode et al. 3
attentional patterns (Pollatsek and Well, 1995), and the
order of the 35 pages of posts was fully randomized.
The study began with a standard nine-point calibration,
presented using Tobii Studio (Tobii Technology, Sweden).
Eye movement data were recorded at 60-Hz (that is, 60
times per second) using a Tobii X60 (Tobii Technology,
Sweden) corneal reflection eye tracker, and stimuli were
presented using Eprime 2.0 (Psychology Software Tools,
Inc., Sharpsburg, PA), standard for the method. Visual
attention to the stimuli was measured with tens of millisec-
onds precision. To determine attention to each post, areas of
interest (AOIs) were established around each post using a
rectangular drawing tool (essentially a rectangle is drawn
around the outside of each post, allowing us to measure
whether any given gaze was directed at that area or at some
other place). AOIs were 520 × 100 pixels for text posts and
520 × 355 pixels for picture and link posts.
Sample
The sample of participants was recruited from fliers
posted on campus and course instructor emails at a Mid-
Atlantic university in the summer of 2014. Participants
took an online survey about social media habits and demo-
graphics, and then reported to the Psychology laboratory
for the eye tracking task (the average time between the
survey and the eye-tracking task was 3.8 days, standard
deviation (SD) = 2.7). They then engaged in a liking task
(viewing each post and indicating whether they liked or
disliked it) and completed a post-test survey.
A total of 65 people participated, with mean age 23.31
(SD = 5.22), 54% female, and more Democratic in their
party affiliation (48% Democrat, 30% Independent, 22%
Republican, which mirrors national samples of this age
cohort).2 The 53 participants who had a Facebook account
are similar (age mean (M) = 22.78, SD = 4.62; gender 53%
female; party affiliation 46% Democrat, 31% Independent,
23% Republican) to the overall sample.
Post creation
Posts were created by researchers to resemble frequent top-
ics of posts on Facebook, including social posts, news posts,
and political posts (Vraga, et al., 2016a). Posts were consist-
ently formatted to standard sizes, with two lines of text and
blurred picture, user name, and time and date information to
prevent these things from influencing respondents. Links
consisted of one line of text for the link title, with website
information removed to ensure consistency.
For the analyses presented in this paper, only political
posts are included--a total of 60 posts. To be political, a
post had to mention political personalities or campaigns,
usually mentioning prominent political figures (e.g. Barack
Obama, Hilary Clinton, John Boehner, and Chris Christie)
or political parties (e.g. Republican, and Democrat) by
name. Political posts were further subdivided into those
favoring Democrats, those favoring Republicans, and those
favoring neither side (e.g. neutral). Those favoring each
party were then subdivided into those that attacked the
opposing party, and those that praised the favored party.
Across all of these categories, posts consisted of two stylis-
tic types: statuses or links.
All posts were pre-tested to confirm they were catego-
rized correctly by researchers, both in terms of their topic
and political preference (that is, we pre-tested to ensure
that what we thought of as favoring Republicans was
perceived that way by respondents as well). For more
information on the creation and pre-testing of posts, see
Vraga et al. (2016a).
Measures
Visual attention.Throughout the eye tracking task, time
spent looking at each individual post was recorded in mil-
liseconds. This time per post was then divided by the total
time spent on the task to control for individual differences
like reading speed to compute a percentage score (this
could theoretically vary between 0 if a user spent no time
on the post and 100 if a user spent all their time during the
task on that single post; M = 0.84, SD = 0.21).
Political cues. The presence of political cues is what should
allow subjects to effectively identify political posts and
skip over them if they are uninterested. Political words
include references to political parties (Republican, Demo-
crat, Grand Old Party, etc.), references to well-known
political figures (Hillary Clinton, John Boehner, Joe
Biden, etc.), and references to political ideas (candidate,
Congress, bipartisan, etc.). We measure political cues in
two ways. First, we identify the location of the first politi-
cal word that occurs in the post (word location, ranges
from 0 to 24, M = 4.15, SD = 4.86). Second, we count the
number of political words that occur in the post (political
words, ranges from 0 to 4, M = 1.65, SD = 0.88), on the
assumption that more cues should serve as a greater heu-
ristic to the political-ness of the post. Finally, we analyze
whether a picture present in a link is political in nature
(political picture, 17 of the 30 pictures included with
links). Political pictures were identified by containing
known political symbols (donkey, elephant, and Capitol
Building) or known political figures (Clinton, Boehner,
and Biden). These are our key independent variables.
Links.Because previous work has shown that posts with
links receive more compared to other types of posts, we
include a dummy variable to control for whether a post was
a link or not (Vraga, et al., 2016b).
Total words in post. Looking time is partly a function of
the length of a post, so we also control for the total
4 Research and Politics 
number of words in a post (ranges from 13 to 37, M =
22.55, SD = 5.14).
Political interest. Because some of our analyses are split
by high and low political interest, we created an item
from a measure in the survey respondents completed
several days before engaging in the eye tracking task,
which asked how interested they were in politics on a
seven-point scale, from "not at all interested" to "very
interested" (M =2.85; SD =1.51). A median split was
used to divide participants into low (1­2; 47.2%) versus
high (3­7; 52.8%) political interest.
Praise/attack.Two categories of partisan posts were cre-
ated: posts that praised one party or posts that criticized an
oppositional party. Therefore, posts that praised the Repub-
lican Party or attacked the Democratic Party were coded as
"pro-Republican," while those that attacked Republicans or
praised Democrats were coded as "pro-Democrat." This
created four categories of partisan posts, each of which
included 10 posts.
Analysis and results
Our analyses begin by considering how long people spend
on posts, which we anticipated would depend on how
quickly they can identify them as political. First, we esti-
mate an ordinary least squares regression, with time spent
on the post as the dependent variable. The key variables
are the location of the first political word--which is the
first way in which subjects could determine a post was
political--and the number of political words. We control
for whether the post was a link, as that includes more
information (headline and picture), and how many total
words the post contained, since longer posts should gener-
ate more attention in general.
As can be seen in Table 1, our first hypothesis, which
predicted that politically identifying words would result in
shorter looking time, is partially supported. The further into
a post a political word arrives, the longer people spend
looking at it, supporting H1a. In contrast to H1b, however,
the number of political words do not seem to matter for
attention, suggesting that people are relatively effective at
identifying a political post by its first political cue.
The third part of that hypothesis is that political pictures
should also serve as a cue to the political-ness of a post.
Because political pictures only occur within links, we
restrict our analysis to link posts only, and then estimate a
similar model to that just described, but also including a
dichotomous variable for whether or not the picture
included is political (17 of the 30 pictures are identifiably
political). Results of this model, shown in Table 2, must be
interpreted with caution due to the low sample size (n =
30). Still, it does not seem that pictures are offering a mean-
ingful cue above and beyond the political words included in
the post, in contrast to H1c.
Our second expectation was that this relationship should
vary by political interest. To test this, we split our sample
into higher and lower political interest individuals, and then
estimated the same model described above. As can be seen
in Table 3, it does seem that the only people affected by
word location are those lower in political interest.
Specifically, the earlier a political word appears in a post,
the less time low interest individuals spend on that post--
but this relationship is not significant for individuals who
report higher levels of political interest.
Finally, we were interested in determining whether peo-
ple were better able to skip over posts that praised a politi-
cal party or entity, or attacked it. To examine this, we
estimate a separate model predicting time spent on a post,
with a variable indicating whether the post was attacking or
praising a political entity, and an interaction between that
variable and the first political word location (and again
controlling for whether the post was a link and how many
words it contained).As can be seen in Table 4, people spend
more time on posts that attack a political figure or idea, as
compared to those that praise, but that does not interact
with the first political word location. This suggests that
attack posts garner more attention overall, but the location
of the first political word does not influence this relation-
ship. This attention to political attack may partially explain
the success of fake partisan news on social media, which
frequently attack a political candidate (Silverman, 2016).
Discussion and conclusions
The findings of this study reinforce concerns about the
extent to which people consume political content via
Table 1. Ordinary least squares regression predicting time
spent on posts.
 Standard error Significance
Word location 0.005 0.002 0.05
Political words ­0.008 0.013 0.55
Link 0.203 0.028 0.01
Total words in post 0.010 0.003 0.01
Note: n = 59.
Table 2. Ordinary least squares regression predicting time
spent on posts (links only).
 Standard error Significance
Word location 0.005 0.003 0.09
Political words ­0.006 0.018 0.72
Political Picture ­0.016 0.033 0.64
Total words in post 0.010 0.004 0.02
Note: n = 30.
Bode et al. 5
social media. While people may have relatively centrist
media diets in general (Guess, 2016), and regularly be
exposed to political content posted by others on social
media (Duggan and Smith, 2016), our findings suggest
that they are relatively efficient in identifying political
content based on the first salient cue, and skipping over it
if they are uninterested.
If people are adept at skipping over political content,
even incidental exposure to political content (Bode, 2016b;
Kim, et al., 2013) is brought into question, since we cannot
be sure how much of the content is actually consumed by
social media users. It further suggests that measuring the
extent to which people are engaging in selective exposure on
social media is more complicated than simply asking what
types of content they see there. This reveals an area of confu-
sion in the literature, when people often talk about selective
exposure but really mean selective attention. As we have
shown in previous research (Vraga et al., 2015a), attention is
often the preferred concept and operationalization for some
of these key questions in mass communication research.
We also show some evidence that people spend more
time with attack posts than praise posts ­ though this does
not interact with how quickly they are cued to the political-
ness of the post. Recent evidence shows that citizens and
researchers do not always agree on what constitutes nega-
tivity (Mattes and Redlawsk, 2014), so future research
should examine different manifestations of negative con-
tent to see if this effect depends on different types of nega-
tivity. Both expertise (McClurg, 2006) and incivility (Mutz,
2015), for example, may function differently than simple
disagreement with the other side. Due to our sample size,
we also cannot consider other factors that might affect
attention to content and skipping speed. We encourage
future research to examine the role of factors like partisan-
ship and gender in this area.
This also suggests practical implications for those look-
ing to share political information with others. Our results
do not discourage the use of political pictures associated
with links, which previous research has shown to be par-
ticularly engaging (Vraga et al., 2016b), but do suggest that
the longer one withholds the first clearly political word in a
post, the more of that post will be consumed by otherwise
uninterested readers.
Declaration of conflicting interest
The authors declare that there is no conflict of interest.
Funding
This research was supported by the George Mason University
Office of Research and Economic Development.
Notes
1. It is worth noting that because we limit our analysis to those
that had a Facebook account, we are only able to general-
ize to that population. These processes are likely differ-
ent for non-users of Facebook, partly by virtue of lack of
familiarity with the platform, and partly in terms of a selec-
tion bias--for example, those that opt out of the commonly
used social media platform are more likely to be male, older,
and wealthier (Greenwood et al., 2016). We believe study-
ing those familiar with the platform is an important first step
in understanding attention patterns on Facebook, but future
research should test the ability to "skip" politics across a
range of online and offline spaces.
2. For comparison, the median age of the United States is
37.9, the US is 51.5% female (Central Intelligence Agency,
2016), and the partisan breakdown for 24-year-olds is
46% Democrat, 18% Independent, and 32% Republican
(Newport, 2014).
Carnegie Corporation of New York Grant
This publication was made possible (in part) by a grant from
Carnegie Corporation of New York. The statements made and
views expressed are solely the responsibility of the author.
Table 3. Ordinary least squares regression predicting time spent on posts by political interest.
Low political interest High political interest
  Standard
error (SE)
Significance  SE Significance
Word location 0.006 0.003 0.07 0.003 0.003 0.34
Political words ­0.023 0.019 0.22 ­0.028 0.018 0.13
Link 0.197 0.042 0.01 0.236 0.040 0.01
Total words in post 0.005 0.004 0.21 0.005 0.004 0.20
Note: n = 59.
Table 4. Ordinary least squares regression predicting time
spent on posts that praise versus posts that attack.
 Standard error Significance
Word location 0.001 0.005 0.76
Link 0.186 0.035 0.01
Total words 0.010 0.004 0.03
Praise ­0.102 0.041 0.02
Praise*Political word 0.006 0.008 0.46
Note: n = 39.
6 Research and Politics 
Supplementary material
The replication files are available at http://dx.doi.org/10.7910/
DVN/TXY7OY.
References
ArceneauxK,JohnsonMandCrydermanJ(2013)Communication,
persuasion, and the conditioning value of selective exposure:
Like minds may unite and divide but they mostly tune out.
Political Communication 30(2): 213­231.
Atkeson LR (2003) Not all cues are created equal: The condi-
tional impact of female candidates on political engagement.
Journal of Politics 65(4): 1040­1061.
Bode L (2012) Facebooking it to the polls: A study in social net-
working, social capital, and political behavior. Journal of
Information Technology & Politics 9(4): 352­369.
Bode L (2016a) Pruning the news feed: Unfriending and unfol-
lowing political content on social media. Research & Politics
3(3): 1­8.
Bode L (2016b) Political news in the news feed: Learning politics
from social media. Mass Communication & Society 19(1):
24­48.
Central Intelligence Agency (2016) The World Fact Book.
Available at: https://www.cia.gov/library/publications/the-
world-factbook/geos/us.html (accessed 16 November 2016).
Duchowski AT (2002) A breadth-first survey of eye tracking
applications. Behavior Research Methods, Instruments, &
Computers 34(4): 455­470.
Duggan M and Smith A (2016) Political content on social media.
Pew Research Center, 25 October 2016. Available at: http://
www.pewinternet.org/2016/10/25/political-content-on-
social-media/ (accessed 16 November 2016).
Eliasoph N (1998) Avoiding Politics: How Americans Produce
Apathy in Everyday Life. New York, NY: Cambridge
University Press.
Garrett RK (2009) Politically motivated reinforcement seek-
ing: Reframing the selective exposure debate. Journal of
Communication 59(4): 676­699.
Graf J and Aday S (2008) Selective attention to online political
information. Journal of Broadcasting & Electronic Media
52(1): 86­100.
Greenwood S, Perrin A and Duggan M (2016) Social Media
Update 2016. Pew Research Center. 11 November 2016.
Available at: http://www.pewinternet.org/2016/11/11/social-
media-update-2016/ (accessed 16 November 2016).
Grofman B (1995) Information, Participation, and Choice: An
Economic Theory of Democracy in Perspective. Ann Arbor,
MI: University of Michigan Press
Guess A (2016) Media choice and moderation: Evidence from
online tracking data. Unpublished manuscript. Available
at: https://www.scribd.com/document/323356298/Media-
Choice-and-Moderation-Evidence-from-Online-Tracking-
Data (accessed 16 November 2016).
Kim Y, Chen HT and gil de Zuniga H (2013) Stumbling upon
news on the Internet: Effects of incidental news exposure
and relative entertainment use on political engagement.
Computers in Human Behavior 29(6): 2607­2614.
Kuklinski JH and Hurley NL (1994) On hearing and interpreting
political Messages: A cautionary tale of citizen cue-taking.
Journal of Politics 56(3): 729­751.
Lau RR and Rovner IB (2009) Negative campaigning. Annual
Review of Political Science 12: 285­306.
McClurg S (2006) The electoral relevance of political talk:
Examining disagreement and expertise effects in social
networks on political participation. American Journal of
Political Science 50(3): 737­754.
Mattes K and Redlawsk DP (2014) The Positive Case for Negative
Campaigning. Chicago, IL: University of Chicago Press.
Mutz DC (2015) In-Your-Face Politics: The Consequences of
Uncivil Media. Princeton, NJ: Princeton University Press.
Newport F (2014) Party identification varies widely across the age
spectrum. Gallup. 10 July 2014. Available at: http://www.
gallup.com/poll/172439/party-identification-varies-widely-
across-age-spectrum.aspx (accessed 16 November 2016).
Nisbett RE and Wilson TD (1977) Telling more than we can
know: Verbal reports on mental processes. Psychological
Review 84(3): 231­260.
Pan B, Hembrooke HA, Gay GK, et al. (2004) The determi-
nants of web page viewing behavior: an eye tracking study.
In: Proceedings of the 2004 symposium on eye tracking
research & applications, pp.147­154. New York. NY: ACM.
Available at: http://panb.people.cofc.edu/pan/ETRA04.pdf
(accessed 16 November 2016).
Pariser E (2012) The Filter Bubble: How the New Personalized
Web is Changing What We Read and How We Think. New
York, NY: Penguin Books.
Pollatsek A and Well AD (1995) On the use of counterbalanced
designs in cognitive research: A suggestion for a better and
more powerful analysis. Journal of Experimental Psychology
Learning, Memory, and Cognition 21(3): 785­794.
Popkin SL (1994) The Reasoning Voter: Communication and
Persuasion in Presidential Campaigns. Chicago, IL:
University of Chicago Press.
Prior M (2007) Post-Broadcast Democracy: How Media Choice
Increases Inequality in Political Involvement and Polarizes
Elections. New York, NY: Cambridge University Press.
Prior M (2009) The immensely inflated news audience: Assessing
bias in self-reported news exposure. Public Opinion
Quarterly 73(1): 130­143.
Schwarz N and Oyserman D (2001) Asking questions about
behavior: Cognition, communication, and questionnaire con-
struction. American Journal of Evaluation 22(2): 127­160.
Silverman C (2016) This analysis shows how viral fake election
news stories outperformed real news on Facebook. Buzzfeed
News, 16 November 2016. Available at: https://www.buzz-
feed.com/craigsilverman/viral-fake-election-news-outper-
formed-real-news-on-facebook?utm_term=.jj13ePW3Eb#.
wnZeJaye47 (accessed 16 November 2016).
Stroud NJ (2008) Media use and political predispositions:
Revisiting the concept of selective exposure. Political
Behavior 30(3): 341­366.
Taber CS and Lodge M (2006) Motivated skepticism in the evalu-
ation of political beliefs. American Journal of Political
Science 50(3): 755­769.
Thorson K, Vraga EK and Klinger-Vilenchik N (2014) Don't push
your opinions on me: Young citizens and political etiquette on
Facebook. In: Hendricks JA and Schill D (eds) Presidential
Campaigning and Social Media: An Analysis of the 2012
Campaign. New York, NY: Oxford University Press, pp.74­93.
Vraga EK, Bode L and Troller-Renfree S (2015a) Eyes don't
lie: Validating self-reported measures of attention on social
Bode et al. 7
media. In: Association for education in journalism and mass
communication (Communication Theory & Methodology),
San Francisco, CA, August 2015.
Vraga EK, Thorson K, Kligler-Vilenchik N, et al. (2015b) How indi-
vidual sensitivities to disagreement shape youth political expres-
sion on Facebook. Computers in Human Behavior 45: 281­289.
Vraga EK, Bode L, Smithson A, et al. (2016a) Blurred lines:
Defining social, news, and political posts on Facebook.
Journal of Information Technology & Politics 13(3):
272­294.
Vraga EK, Bode L and Troller-Renfree S (2016b) Beyond self-
reports: Using eye tracking to measure topic and style differ-
ences in attention to social media content. Communication
Methods and Measures 10(2/3): 149­164.
Zaller J (1992) The Nature and Origins of Mass Opinion. New
York, NY: Cambridge University Press.
