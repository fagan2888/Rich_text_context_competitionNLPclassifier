Article
There Is No Solution!:
"Wicked Problems"
in Digital Games
Frank G. Bosman1
Abstract
Ethical gameplay can be defined as "the outcome of a game sequence in which
players take definitive choices based on moral thinking, rather than instrumental
thinking." Often moral problems presented by video games can be solved easily once
the ethical framework of the game is understood, or on the basis of help from the
visible moral feedback of the game, or simply by experimenting with the different
outcomes by using the game's saving/loading system. In this article, I focus on the
nature of the moral problems it presents to the player with the help of the notion of
"wicked problems." Using four case studies from two games that heavily rely on
ethical gameplay, I will differentiate between four kinds of moral problems arising
from ethical gameplay: tame moral problems, semiwicked problems, real wicked
problems, and super wicked problems, each of which present a greater (moral)
challenge to the player.
Keywords
ethical gameplay, moral dilemmas, morality system, wicked problem, Fallout 3, Mass
Effect (video game series)
In the game Fallout 3 (Bethesda Game Studios, 2008), the player is confronted with
a very particular side quest, called "Tenpenny Tower." The world setting of the
Fallout series is a postapocalyptic North American wasteland, where all remaining
1 Tilburg Cobbenhagen Center, Tilburg University, Tilburg, the Netherlands
Corresponding Author:
Frank G. Bosman.
Email: f.g.bosman@tilburguniversity.edu
Games and Culture
1-17
Âª The Author(s) 2017
Reprints and permission:
sagepub.com/journalsPermissions.nav
DOI: 10.1177/1555412017716603
journals.sagepub.com/home/gac
life--vegetable, animal, and human--is under constant threat from toxic radiation,
from the mutants resulting from this radiation, and from civil war between multiple
human factions.
In this pessimistic world, the game protagonist, called "the Lone Wanderer,"
ultimately discovers a large isolated apartment complex in the middle of the desert.
The complex is named after the owner, Alister Tenpenny, and is heavily fortified and
guarded against the dangers of the wasteland. The tower houses a number of rich
tenants who are strongly opposed to the ghouls who are trying to get in. The
ghouls--mutated humans who are unpleasant to look at, but still possess human
intelligence and morality--argue that they are as human as the tenants are and
demand housing in the tower. The tenants, however, fear and loathe the ghouls
whom they consider to be subhuman.
The player--as the Lone Wanderer--has to decide how to handle this situation:
He has to help either Tenpenny get rid of the ghouls once and for all (which means
killing them all) or the ghouls to take over the tower (which means that the ghouls
will kill all the tenants). When I played the game myself, this quest struck me as
being morally difficult. Both sides--the ghouls and the tenants--have their (morally
ambivalent) motivations to want what they want, and killing one of the two groups
seemed hardly a morally adequate solution or a pleasant experience for me as a
player.
I felt rather smart for finding a third option, which was to convince the tenants to
let the ghouls enter the tower. Initially, the results were good, as ghouls and tenants
seemed to be living together relatively happily in Tenpenny Tower. But when I
visited the Tower 2 days later (in terms of the game's internal chronology), I found
out that the ghouls had killed all the original tenants. I was shocked by this unin-
tended but horrible outcome of my "ideal solution."
This Tenpenny Tower quest from Fallout 3 is a prime example of ethical game-
play: The player is confronted with a difficult (moral) problem that he has to solve in
order to progress through the game. But because it is impossible for the player of
Fallout 3 to know all the possible solutions beforehand, he has to follow his con-
science and hope for the best.
Methodology
In more formal terms, this ethical gameplay (as it occurs in Fallout 3) can be defined
as "the outcome of a game sequence in which players take definitive choices based
on moral thinking, rather than instrumental thinking. Ethical gameplay is, in other
words, the outcome of moral play" (Sicart, 2010, p. 104). Ideally, the moral dilem-
mas that the game presents to the player break the fluidity of the gameplay, " . . . a
caesura that forces players to evaluate their behaviors in light of ethical thinking,
rather than ludic strategic thinking" (Sicart, 2013a, p. 31).
Not all video games offer ethical gameplay, and not all games that do, do so in the
same way. Game scholars such as Sicart (2010, 2013a) and Knoll (2015) have
2 Games and Culture XX(X)
argued that many of the ethical dilemmas presented to the player by the game are
lacking in ludological quality and narratological depth. Too often, moral problems
that the game presents to the player can be solved easily once the ethical framework
of the game is understood, or on the basis of help from the visible moral feedback of
the game, and/or simply by experimenting with the different outcomes by using
(exploiting) the game's saving/loading system. And last but not least, moral choices
often do not have much ludological and/or narratological repercussions on the rest of
the game.
In this article, I focus on ethical gameplay and more precisely on the nature of the
moral problems it presents to the player. How "real" are these moral dilemmas? Can
they be (easily) circumvented by exploiting in-game mechanics? Does the game
offer an "ideal solution"? Do the moral choices that the player makes in the game
have any consequences for gameplay and/or narrative?
For this analysis, I use the concept of "wicked problems," which originated in the
domain of social engineering (Rittel & Weber, 1973). It is a widely used concept to
denote problems which are (very) difficult or even (potentially) impossible to solve
because of incomplete, contradictory, and changing requirements. Moreover, the
concept has been used specifically in game studies to think about ethical gameplay
(Sicart, 2010). I will return to this concept later on.
Two approaches to ethical gameplay have been identified: game agency or player
agency (Knoll, 2015). The first is a game-immanent concept focusing on the agency
"provided by the game through game mechanics, rules, level architecture ( . . . )
narrative (and even aesthetic) structures directly dependent on these systems." The
second is an actor-centered approach that focuses on the agency of the player, that
can take "various forms and is heavily dependent on individual expectations of a
game, personal preferences and of course socialization and in some cases even
religious denomination." I will focus on game agency in this article (not player
agency per se).
As has been seen, this game agency focus is based on a game-immanent approach
to video games (Heidbrink, Knoll, & Wysocki, 2014, 2015). The playing of the
actual game is essential to this approach (internal reading) as is collecting all in-
game information (internal research), mapping the intermedial relationships
between the game and other media relating to the same complex of interwoven
narratives (external reading), and gathering all outgame information provided by
fellow players and scholars (external research; Bosman, 2016).
In this context, digital games are essentially regarded as "digital (interactive),
playable (narrative) texts" (Bosman, 2016, p. 30). As a text, a video game can be an
object of interpretation; as a narrative, it can be regarded as communicating mean-
ing; as a game, it is playable; and as a digital medium, it is interactive in nature
(Ryan, 2006). This definition makes it possible to theorize about video game narra-
tives from a philosophical (or sociological or psychological, etc.) point of view.
The structure of this article is as follows. First, I will introduce and reflect on two
important and constitutive notions concerning ethical gameplay in the context of this
Bosman 3
research: morality systems (second section) and wicked problems (third section).
Second, I will differentiate between four kinds of moral problems within ethical
gameplay: tame moral problems, semi-wicked problems, real wicked problems, and
super wicked problems, each of which present a greater (moral) challenge to the
player (fourth section). Finally, I will summarize and propose some suggestions for
further research (fifth section).
This article is aimed at exploring the different ludological and narratological
"settings" in which the moral dilemmas are presented to the game by the game
developers and how "intelligent"--in terms of feed-back and repercussions on the
rest of the game (ending)--they are deployed by the developers. This focus implies
that some other--even interesting and certainly related--topics cannot be addressed,
especially not in the context of one article. This article, therefore, dismisses the
differentiation one could make between the player (as a human agent) and the avatar
he is controlling in the game. Also, the insight, that the ethical decisions a player
makes in the game through his avatar, may (or may not) differ from the decisions a
player would make in real-life is not further reflected upon in this article. Experi-
menting with different ethical "stances" throughout one or more play throughs are
certainly interesting as a topic for scholarly research, but this article is not aimed at
this "tension" between in-game and real-life ethical choices, but at the different
ways developers present their moral problems to the player.
One could also argue that moral dilemmas in video games are in themselves less
complicated than real-life situations because of technical and other practical limita-
tions. This may be true, but this does not prevent to evaluate the different ways in
which the developers have succeeded in presenting an "interesting" ("wicked")
moral dilemma to the player (or not), by comparing them mutually based on certain
(technical and ethical) qualifications (as I will do in this article).
Morality Systems in Digital Games
Morality systems are one of the most prominent (and visible) ways in which ethical
gameplay is used in video games. Games such as Fallout 3, the Mass Effect series
(BioWare, 2007, 2010, & 2012), BioShock (2 K Boston & 2 K Australia, 2007), the
Infamous series (Sucker Punch Productions, 2009, 2011, & 2014), and the Fable
series (Lionhead Studios, 2004, 2008, & 2010) all use morality systems. In short,
video game morality systems can be defined as implicit or explicit digital systems
within a particular game that morally rate certain player actions and/or choices on
the basis of a presupposed ethical framework. In most games with a morality system,
the player is rewarded when he saves innocent people but penalized when he steals
or robs people. Intriguingly enough, however, there are some games in which killing
the bad guy is counted as "good" while stealing from him as "bad."
These morality systems can be either implicit or explicit. In the former case, the
player is unaware of the presence of the system in the game. The player does not
know that the game has a morality system and/or does not know the criteria used in
4 Games and Culture XX(X)
the morality system. The player is unaware of the (subtle) changes in gameplay and/
or narrative that are caused by his moral actions based on the way they are rated by
the morality system because he lacks means of comparison or because the changes
occur only explicitly at the end of the game. The game Metro Last Light (4A Games,
2013) is a good example. There are multiple instances in the game where player
actions are "measured," for example, when the game protagonist Artyom has the
choice to kill or save his worst enemy Pavl. The only consequence of this system is a
slightly different ending to the game, but the player is oblivious to this because he
does not know that another ending is possible.
A video game morality system can also be explicit: This means that the player is
aware of the presence of the system in a particular game. The player knows that the
game has a morality system and also knows the criteria it uses (or is able to find out
through simple experimentation) because this is evident from feedback that the
system gives and that visualizes the in-game moral judgment through some sort
of "morality chart."
A morality chart that the morality system uses to rate player actions and choices
can be in the form of a "scale" or a "meter" model. In a scale model, the morality of
the player's in-game choices is rated by the sum of all his or her ethically qualified
choices in the game, placing the player's moral behavior on a scale ranging from
good to evil (or neutral). A good example is Fallout 3, which calculates the moral
"status" on a line ranging from very evil (Ã750 to Ã1,000 "karma points") to very
good (Ã¾750 to Ã¾1,000 karma points). Moral "levels" often have colorful names such
as "scourge of humanity" and "harbinger of war" (for bad karma) and "last hope of
humanity" and "ambassador of peace" (for good karma).
In a meter model, the in-game actions of the player are rated by (at least) two
different meters--usually "good" and "evil"--which keep track of all his or her
ethically qualified choices in the game, allowing the player to be (more or less) good
and evil at the same time. The Mass Effect series is a good example. Certain sets of
actions result in the player being designated as "paragon" (morally just actions) or
"renegade" (morally unjust actions). This means that in this series, it is possible to be
a little bit of a renegade (evil) but overwhelmingly a paragon (good) at the same time
(or the other way around), a feature that enables more differentiated character
development.
While morality systems are a well-established game mechanic, they have come
under criticism from academic scholars (Knoll, 2014; Nguyen, 2016; Sicart,
2013a; Svelch, 2010; Zagal, 2009) and game critics alike (Birch, 2014; Rio,
2014; Takacs, 2013). The criticisms focus on the two-dimensional (dualistic)
nature of the systems, their selective morality, the inconsistency of the rule sys-
tems, and the notion of "ludonarrative dissonance" (Hocking, 2007). Especially
the last criticism is important with regard to ethical gameplay. If in any given
game, the game's narrative conflicts with its mechanics, the ethical gameplay is
disturbed because the player experiences a divide between what the game seems
to ask from the player (moral behavior) and what the game actually makes the
Bosman 5
player do (gunning down hordes of enemies). Of course, this could be intended
as such by the game developers as some sort of meta-ethical discussion, but it
hardly ever is.
As Sicart (2013a) has mentioned, the problem with many morality systems
(especially the explicit ones) is that the gameplay actually encourages ludos-
trategic behavior in gamers instead of the required narratologicalÂ­ethical beha-
vior (Knoll, 2014). This means that players are more inclined to look for the
biggest advantage in terms of gameplay and to disregard the morally charged
game narrative.
Sicart (2013a) has also argued that most moral dilemmas in video games can be
easily circumvented by experimenting (exploiting) the load/save system of the
game. It is quite possible, especially in cases that have only short-term conse-
quences, to literally try all possible options in any given dilemma until the best
result is achieved. This of course "kills" the most important aspect of ethical game-
play, that is, the decision is one-off and irreversible. This problem can be solved by
resorting exclusively to long-term consequences--such as Life is Strange (Dontnod
Entertainment, 2015), for example--but this is rarely done because of the strain such
an elaborate system of long-term consequences produces in terms of technological
and narratological elaborations.
Finally, I want to address one last problem concerning ethical gameplay in
general and morality systems in particular. Most games offering moral dilemmas
tend to incorporate at least one "ideal solution." Rather than mirroring the moral
ambiguity of everyday life, these games suggest that--at least theoretically--there
is always one solution that morally outweighs all the other solutions and is thus
preferable. This type of game also often requires an external "police" to govern
player agency.
The Concept of Wicked Problems
To bring our reflection on ethical gameplay and morality systems to the next level,
I introduce the concept of wicked problems. I argue that this concept makes it
possible to differentiate between different forms of ethical gameplay that the
game presents to the player, essentially to find a model that meets the criticisms
discussed earlier.
As has been seen, the concept of wicked problems originates in the context of
social engineering. The term was coined by Rittel and Webber in their 1973 article
"Dilemmas in a General Theory of Planning." The authors claimed there that "the
search for scientific bases for confronting problems of social policy is bound to fail,
because of the nature of these problems. They are `wicked' problems, whereas
science has been developed to deal with `tame' problems." Rittel and Webber
present 10 distinguishing characteristics of planning-type problems. Conklin
(2006) broadened the notion of wicked problems to make it applicable to other fields
of human endeavor while reducing the number of characteristics to six.
6 Games and Culture XX(X)
1. The problem is not understood until after a solution has been formulated. The
information needed to understand the problem depends upon one's idea for
solving it.
2. Wicked problems have no stopping rule. The problem solver quits his
problem-solving job not because he knows he has done his job to full perfec-
tion but because of external motivations, that is, he runs out of time, money,
or patience.
3. Solutions to wicked problems are not right or wrong. The quality of the
outcome of the solution to a wicked problem cannot be determined unam-
biguously, because there are no established criteria for this. The outcome is
"good" or "good enough" rather than "right" or "wrong."
4. Every wicked problem is essentially novel and unique and cannot be reduced
to a problem experienced or described before.
5. Every solution to a wicked problem is a "one-shot operation." It is not
possible to experiment because the consequences of one's choice cannot
be reversed to try a different one.
6. Wicked problems have no given alternative solutions. There may be no solution
at all, and/or there may be a solution that no one has ever thought of before.
Sicart (2013a) tried to apply the notion of wicked problems to the field of ethical
gameplay, and his attempt resulted in the formulation of 10 characteristics of the
"perfect moral dilemma" (my formulation) in a video game (and I quote):
1. The player's knowledge of possible outcomes will be limited by ethical
cognitive friction between the semiotic and the procedural domains. The
player does not have perfect information about the potential outcome of a
dilemma.
2. Ethical gameplay dilemmas have consequences that cannot be predicted by
understanding only the procedural level of the game. Knowing how the
system works should not be enough to make a decision because some
aspects of the system that affect the outcome are unknown to the player.
3. The evaluation of the outcome by the game system will not be commu-
nicated to the player in quantized terms.
4. After players make a choice, they cannot reload to a state that is prior to that
choice.
5. Every solution to an ethical gameplay dilemma locks players into a news
state of the game. They are not able to return to prior states. All decisions
matter.
6. Ethical gameplay dilemmas have some solutions that make the procedural
and semantic level collide, suggesting nonoptimal strategies that have emo-
tional, cultural, and contextual values.
7. Ethical gameplay dilemmas tend to be unique. A dilemma's structure
should not be repeated through the game.
Bosman 7
8. Ethical gameplay dilemmas reveal the moral nature of the semiotic and
procedural domains of the game. Dilemmas represent the values that
designers want to communicate with the game.
9. There is no correct solution to an ethical gameplay dilemma. Players have to
evaluate the morality of their choices.
10. Players have no right to replay. Decisions made by players bind them to
their chosen path, and the game, in the state determined by the choice taken,
is playable only once.
In this article, I want to carry Sicart's thinking on ethical gameplay a little further
by using the notion of wicked problems, not to sketch an ideal game scenario (as
Sicart did) but to differentiate how actual video games (and instances within these
games) use ethical gameplay and/or morality systems.
4. Tame, Semi-, Real, and Super Wicked Problems
Based on the concepts of wicked problems, I want to propose a four-level
differentiation in ethical gameplay: tame, semi-wicked, real wicked, and super
wicked (moral) problems. The constitutive parts (criteria) of this differentiation
are:
1. the extent to which the specific problem stimulates narratologicalÂ­ethical
gameplay,
2. the extent to which it is possible to solve the problem by exploiting the
loading/saving mechanism of the game,
3. the temporary nature of the consequences of a particular choice,
4. the presence of an "ideal solution", and
5. the present and nature of any feedback given to the player by the game.
The first criterion is necessary for the existence of a wicked problem in the
first place. The second criterion factor focuses on the ludological element of
ethical gameplay, while the third one focuses on the game's narratological
element. The fourth criterion concentrates on the extent to which the given
moral problem is presented as a moral dilemma, enhancing its "wicked nature."
The fifth criterion handles the feedback (if any) given to the player by the game
in regard to the in-game evaluation of the player's moral actions. The explicit
nature of this kind of feedback (usually in the form of a morality system)
influences the complexity of the moral decisions as I have discussed earlier in
the article.
I elaborate on these different kinds of wicked problems subsequently on the basis
of various examples of video games that use these kinds of problems.
8 Games and Culture XX(X)
Tame moral problems. The first sort of wicked problem is not actually wicked at all
but "tame." Tame moral problems in video games "involve a decision that looks
moral but is only a consequentialist calculation of outcomes" (Sicart, 2013b, p. 105).
Tame moral problems involve no "wickedness" and stimulate ludostrategic instead
of the required narratologicalÂ­ethical behavior.
A few examples of tame moral problems can be found in the game Fallout 3.
Fallout 3 is a first-/third-person, action role-playing, open-world video game
produced by Bethesda Softwork in 2008. The game features a post-apocalyptic
retrofuture, covering an area including Washington DC, northern Virginia, and
parts of Maryland. The vast majority of inhabitants have been killed by atomic
bombs during a Great War or by the radiation resulting from the detonation of
these bombs. Humans have to share the limited resources with all kinds of
mutants who are generally hostile to "normal" humans. During his adventures
and quests in this wasteland, the gamer--in the persona of the game's only
protagonist called `the Lone Wanderer'--comes across a number of minor
"moral" situations that add good or bad karma to his character (as I have
explained earlier).
Positive karma can be gained by a number of actions. Some are rather obvious,
like donating money to a church, helping to repair a water-processing plant,
giving clean water to beggars, deactivating a bomb, or freeing slaves. Other
"good" choices are a little more far-fetched, like selling the fingers taken from
the corpses of evil characters or providing a gun to particular persons for reasons
of self-defense. Bad karma results from other actions, some of which are the
exact opposite of the good karma actions: stealing (from good and bad characters
alike), breaking into someone's computer, killing a "good" character, giving
contaminated water to beggars, enslaving waste landers, allowing someone to
commit suicide, helping addicts get their drugs, and selling ears from the corpses
of good characters.
The "tameness" of the moral problems that the gamer encounters lies in their
shallowness. Gamers do not make these decisions based on moral thinking (narra-
tologically based) but on strategic thinking (ludologically based), based on the kind
of player they intend to be, good or evil. The explicit nature of the morality systems
makes it abundantly clear what actions the developers consider to be good or evil. As
soon as the gamer has decided to play as a good or evil character, the choices lose
their moral appeal altogether. Even the stranger moral values, such as selling the
fingers of bad persons (for good karma) or giving addicted persons the drugs they
need to survive (for bad karma), lose their wickedness as soon as the player has
performed them.
Semi-wicked problems. The second form of wicked problems are semi- (or pseudo-)
wicked problems. Semi-wicked problems do inspire narratologicalÂ­ethical behavior
in the gamer (rather than ludostrategic behavior), but the problem itself can be
solved relatively easily by exploiting the game's saving/loading system. The player
Bosman 9
is able to empirically explore all the (unforeseen) consequences of all possible
solutions within the game. This works especially well with explicit morality systems
with short-term consequences. The moral problem is real on the level of the narrative
but has no consequences on the ludological level.
This kind of wicked problem occurs, for example, numerous times in the Mass
Effects series, a series that has been the subject of scholarly research concerning
ethical gameplay before (Boyan, 2015; Knoll, 2015). The games in the Mass Effect
series, which consists of three interconnected games, can be characterized as second-
person (over-the-shoulder), action role-playing games. All three installments
(released in 2007, 2010, and 2012) were produced by BioWare. Moral choices made
in the first (and the second) game are transferred to the second (and third) install-
ment, creating an interlinked narratological and ludological unity. The series is set
within the near future (end of the 22nd century), where interstellar travel is possible
through a network of Mass Relays. The relays were built by a now extinct alien race
known as the Protheans.
With the help of Prothean technology discovered on Mars, humankind takes a
decisive step into the galactic arena, where there are many sentinel and space-
traveling races. The Milky Way is governed by a conglomerate body known as the
Citadel Council, which is dominated by the three most powerful races in our galaxy,
Asari, Salarians, and Turians, later also joined by humanity. The player's moral
behavior is explicitly recorded and evaluated by means of two morality meters,
"paragon" (good) and "renegade" (evil), as I described earlier in this article.
In the three game installments, the player gathers multiple teammates from dif-
ferent in-game races who can be chosen by the player to accompany him on mis-
sions. These teammates and their respective races have all kinds of psychological
and emotional problems arising from their individual deeds (before joining She-
pard's crew) and/or from the fact that their respective races are at war with each
other. In a number of instances, Shepard (the player) has to intervene between
teammates in order to prevent them from leaving or--even worse--getting killed.
These "rescues" have to be performed in dialog scenes, where the player can choose
from different options of what to say. I will give an example.
In the Mass Effect universe, the Korgan race (battle-hardened lizards) has been
infected by what is called the "genophage," which makes all females infertile. The
genophage was used by the Turians against the Krogan, but it was developed by the
Salarians. When Shepard lands on the planet Virmire, the player can choose a
Krogan by the name of Wrex (who was earlier recruited by Shepard) as his team-
mate. Then Shepard, Wrex, and the other teammate run into a Salarian squad, which
has its own mission on Virmire. The player learns from the Salarians that they have
come to stop Saren (a rogue Turian) from curing the genophage. Saren wants to cure
the genophage in order to breed his private army of Korgan warriors. Wrex, under-
standably, is not amused to hear that the only cure for his race is about to be
destroyed. And he turns for answers to Shepard who wants to stop Saren from
accomplishing his goals.
10 Games and Culture XX(X)
This standoff between Shepard and Wrex has two possible outcomes: (1) Shepard
"convinces" Wrex to fight against Saren together with the Salarians by destroying
the cure. (2) Wrex is killed. The "convincing" can have different forms: Shepard
may charm Wrex or intimidate him, or he can already have obtained Wrex's trust.
The killing of Wrex can be carried out by either Shepard himself or another team-
mate. Intimidating or killing Wrex will gain renegade points (designated by the
morality system as morally unjust), charming or "gaining his trust" earns paragon
points (designated as morally just). When one of the player's squad kills Wrex, the
awarding of points depends on his reaction to this event: An angry response by
Shepard earns renegade points, a grateful response paragon points.
While the dilemma between helping the Salerians to stop Saren from misusing the
Turians by lifting the genophage on the one hand, and the need to keep Wrex healthy
and wholeheartedly on one's side on the other seems like a real moral conundrum, in
fact it is not. Not only is there an ideal solution--convincing Wrex to help the player
to stop Saren--it is also easy to find it by going through the dialog options multiple
times, until all the possible solutions (and the corresponding paragon and renegade
points) have been tried. The player can decide how to act on this basis. The possi-
bility of exploiting the saving/loading mechanism of the game makes this problem a
semi-wicked problem rather than a real one.
Real wicked problems. The third form of wicked problems in video games is what I
would call "real" wicked problems. These problems cannot be solved easily by
multiple saves/loads because the morality system is implicit and/or the moral
choices have long-term consequences. A morally ideal solution may be available,
but it can be identified only in hindsight.
The first example is Metro Last Light, released in 2013. These games share the
same game mechanics and world. Metro Last Light is a single-player, first-person
shooter video game with stealth and survival horror elements set in a postapocalyptic
world. The game features a what-if history, a representation of our collective past
diverting from reality in certain key elements (Hellekson, 2001). In this case, a
massive nuclear war occurred in 2013 leaving Moscow--where the game is set--
with severe radiation damage. The survivors have gone to live in metro stations and
are fighting over limited resources. Many animals were mutated into aggressive
beasts, which makes traveling on the surface dangerous.
Metro Last Light features an implicit morality system that tracks certain decisions
the gamer makes during his play through and offers two distinct alternative endings
based on these decisions. Some points of decision are subtle, others more obvious.
But since the player is unaware of the tracking device, he does not know that he is
being morally judged by the game. The subtle instances where the game makes
moral judgments of the player's behavior include whether or not to play a guitar
(in the "Introduction" level), whether or not to stay near an ally (level "Ashes"), or
whether or not to listen to conversations between nonplayable characters (level
"Bolshoi"). More obvious instances (obvious only once the player has become aware
Bosman 11
of the morality system) include whether or not the player approaches unknown
entities in a violent manner (level Introduction), releases prisoners (level "Pavl"),
or kills enemies that are surrendering (level "Reich").
The "realness" of the wicked problems that Metro Last Light presents to the
player lies in the implicitness of the morality system, which prevents the player
from executing ludostrategic behavior. The decision to kill or to spare the lives of
enemies who are surrendering can only be taken on the level of narratologicalÂ­
ethical gameplay. Only when a player has finished one play through (and/or reads
about the game on the Internet) and becomes aware of the existence of the morality
system, can he or she play the game a second time with new knowledge that permits
him or her to decide to take other values into account (e.g., to play the good or the
bad guy in the game). Before that, it is impossible to exploit the game's saving/
loading mechanism because the player does not know that he is being "tracked."
And because the game does not give any visible or audible feedback, the player does
not know which decisions are being tracked and how they are evaluated (although it
is possible to guess of course).
Super wicked problems. The fourth, last, and--in my opinion--most important kind of
wicked problems in video games are "super" wicked problems. No player can offer
any satisfactory solution to this kind of moral problem, not even in hindsight, simply
because there is no morally correct solution. Every choice, even in hindsight, has
both good and evil consequences. I will give two examples.
For the first example, I return to the game Mass Effect discussed above in relation
to its semi-wicked moral problems. As has been seen, many of the fights between
teammates can be solved by the player simply by experimenting with the different
dialog options and exploiting the game's saving/loading system. But there is one
particular instance where the semi-wicked problem becomes a super wicked problem.
In the first Mass Effect game, Commander Shepard is sent to investigate the
human colony of Eden Prime to recover an unearthed Prothean beacon. During the
inspection, Shepard and his crew are attacked by Geth (a race of self-conscious
artificial intelligences) under the secret leadership of the Turian Saren Arterius, a
council high officer-turned-rogue. The rest of the first Mass Effect is dedicated to
unmasking this Saren as the mastermind behind the Geth attacks on the Milky Way's
other space-traveling races.
On the planet Virmire, Shepard and his crew eventually discover Saren's secret
base, which they plan to destroy using a massive nuclear device. However, the crew
is surprised by another legion of Geth soldiers, and this leads to a very difficult moral
dilemma for the player. Two of Shepard's teammates, Ashley Williams and Kaidan
Alenko, are pinned down by the Geth on two different locations on Virmire. There is
only time to save one of them, and the game stalls indefinitely until one of the two
options is selected. There is no third or "ideal" solution.
For almost all situations, there is a third option to save both teammates (as we
have seen), but the Kaidan/Ashley dilemma is unique because this ideal solution is
12 Games and Culture XX(X)
not provided. The player must choose who will die and who will live. That this
choice matters to players is evident from the existence of many online discussions,
where players mourn the fact that either Ashley or Kaidan must die and/or discuss
why they chose one or the other. To see an example, it is necessary only to visit the
BioWare forum (https://forum.bioware.com) and search for "Kaidan-Ashley."
These discussions on this kind of Internet forums could be considered as a viable
end-game place to participate and discuss the morality of different moral choices
within the game.
For a second example of a super wicked problem in a video game, I return to Fallout
3, and more specifically to the Tenpenny quest, which was already discussed above.
Fallout 3 is a first-/third-person, action role-playing, open-world video game
produced by Bethesda Softwork in 2008. The game features a postapocalyptic
retro-future, covering an area including Washington DC, northern Virginia, and
parts of Maryland. The vast majority of inhabitants have been killed by atomic
bombs during a Great War or by the radiation resulting from the detonation of these
bombs. Humans have to share the limited resources with all kinds of mutants who
are generally hostile to "normal" humans. This specific quest has previously
received scholarly attention, specifically for its ethical gameplay dimension
(Schulzke, 2009; Sicart, 2013a).
Tenpenny Tower is a prewar luxury hotel, which stands alone in the middle of the
desert. Upon inquiry, the player learns that the tower is the property of Alister Ten-
penny who has turned the hotel into a private, elite residential and commercial build-
ing that permits only wealthy (and truly "human") residents. As he approaches the
entrance of the tower, the player overhears an intercom conversation between a ghoul
by the name of Roy Phillips (who stands outside) and the head of security, Chief
Gustavo (who is inside). Roy demands that he and his fellow ghouls be allowed to
enter so as to live safe and comfortable lives inside. Gustavo harshly rejects Roy's
request, adding all kinds of racial slurs against ghouls. Roy disappears into the dis-
tance, uttering threats to the effect that he will find a way to get what he wants.
The player can now choose to go inside the premises and talk to Gustavo or to
follow Roy to his hideout in Warrington metro station. If he decides to talk to
Gustavo, he is given the offer to hunt down and kill Roy and his family, thus
removing the constant threat they pose to Tenpenny Tower, in exchange for a large
sum of money. Whether the player accepts the offer or not, the next stop takes him to
Roy in Warrington Station. After a conversation, Roy asks the player to help him to
get into Tenpenny Tower. The player has to open an emergency exit in the basement
of the tower, allowing Roy to send in his "feral brethren" who will almost certainly
kill all of Tenpenny's tenants.
At this point, the player has four different options. The first is to help Gustavo by
killing Roy and his family and then to return to Tenpenny Tower to receive his
reward (getting good karma by the morality system). The second option is to help
Roy by letting his "feral" friends into the tower who will then proceed to kill all the
tenants (receiving bad karma). A third option is to help Roy, not however by opening
Bosman 13
the backdoor but by killing all the tenants and security guards himself (also leading
to bad karma). A fourth option, the most difficult one, is to convince both Alister
Tenpenny and his tenants to willingly open the doors of their residence to Roy and
the other ghouls (good karma)
The morally problematic nature of the Tenpenny episode becomes very clear
when we examine the different conversations with Roy and his fellow ghouls and
with Tenpenny tenants more closely. Both sides in the standoff have some kind of
moral justification on their side. The tenants, while they are "human supremacists,"
correctly fear that the ghouls are fully prepared to use violence to accomplish their
goals. And the ghouls have every right to protest against the tenants' racist attitude.
The player is forced to weigh the tenants' and ghouls' respective moral claims in
order to come to a decision.
There is, however, a fourth option where it seems that the player is not forced to
pick a side. The player can try to persuade Alister Tenpenny and five designated (and
very bigoted) tenants to permit the ghouls into to tower to live with them. If the
player is successful, human and ghoul tenants can be seen roaming the corridors and
rooms of the tower, in what appears to be peaceful coexistence. This option seems to
be the best one from a moral perspective. But when the player returns after a couple
of in-game days, it transpires that Roy and his fellow ghouls have murdered all the
"smooth skins" after all, leaving the player with very mixed emotions about his
earlier choices. The morality system of the game amplifies this notion of moral
ambiguity by giving the player good karma for resolving the situation peacefully,
but neither good nor bad karma when the long-term consequences of your "good"
actions become clear.
There is no definite or "ideal" solution to the Tenpenny Tower episode. And even
the one solution that seems to be ideal (negotiation) has heavy and unwanted con-
sequences (the death of the tenants). As there is no ideal solution to this moral
problem, the player cannot abuse the game's saving/loading system in a practical
sense. Of course, it is quite possible to experiment with all four outcomes, discover
the long-term consequences of option 4, load an old save file, and choose another
option. But the discovery of the long-term consequences is merely accidental. There
is no need to go back to Tenpenny Tower in a strict sense. The only other quest
requiring you to go to the tower are very probably already done in an earlier stage of
the game. And even then, while it may be technically possible to return to a previous
save game after finding out the murdering of the Tenpenny residences, it is probably
highly impractical for the majority of players who do not collect multiple saves but
usually rely on fast save (overriding the previous one) and/or think it too heavy a
burden to redo everything they have done in-game since their last visit to the tower.
Summary and Further Research
Ethical gameplay can be an important asset in the development of video games. The
implementation of ethical gameplay can, however, take different forms and shapes,
14 Games and Culture XX(X)
depending on choices that the developers make. Ethical gameplay can be imple-
mented by the use of an (implicit or explicit) morality system, featuring either a
meter or a scale model. However, the implementation of such a system is no guar-
antee for successful ethical gameplay, as critics have already observed and as I have
shown in the different examples featured in this article.
When ethical gameplay is included in a game, that is, when the gamer is stimulated
to use narratologicalÂ­ethical thinking instead of ludostrategic thinking, the quality of
the moral problems posed can be quite different. I have tried to differentiate between
four levels of ethical gameplay in video games based on the concept of wicked
problems--tame, semi-, real, and super wicked problems. This differentiation is based
on the extent to which the specific problem stimulates narratologicalÂ­ethical game-
play, whether there is the possibility of solving the problem by exploiting the game's
loading/saving mechanism, whether the consequences of a particular choice are irre-
versible, and whether there is an "ideal solution" to the problem.
While a system of differentiating how ethical gameplay is actually executed in
video games--as I have proposed here--is a useful and necessary step in under-
standing how game designers handle moral issues in their products, there is need for
more research by both gamers and researchers. I believe that the most important field
of research concerns the range of presupposed ethical frameworks that game
designers use to base "judgments" of player actions and choices on.
Whatever the nature of the ethical gameplay--tame, semi-, real or super
wicked--the question of the foundation of these ethical frameworks still remains
unanswered. It is possible to examine all wicked (and even tame) moral problems in
video games from the perspective of consequentialist, deontological, and virtue
ethical theories. Which ethical framework have the designers used (game agency)?
And which ethical framework are games using to cope with the moral problems
(tame of wicked) presented by the game? Are the ethical frameworks of designers
and gamers compatible or not?
Perhaps the most appropriate way of thinking about morality and gameplay is a
virtue-based conception of morality, where the gamer slowly but surely develops his
or her moral compass, or increasingly aligns his or her moral decisions to the
presupposed ethical framework. As gamers, we learn something from the games
we are playing. The question is, however, what we learn through the agency of
playing them.
These questions merit further research in order to understand how ethical game-
play, morality systems, and wicked problems in video games "educate" the gamer to
behave in a certain way within the game, and/or stimulate him to evaluate his or her
own in-game behavior in the light of his own ethical thinking, and/or triggers him to
critically evaluate the ethical framework which the developer has used.
Declaration of Conflicting Interests
The author(s) declared no potential conflicts of interest with respect to the research, author-
ship, and/or publication of this article.
Bosman 15
Funding
The author(s) received no financial support for the research, authorship, and/or publication of
this article.
References
2 K Boston & 2 K Australia. (2007). Bioshock [PC game]. Novato, CA: 2 K Games.
4A Games. (2013). Metro Last Light [PC, Xbox, Xbox One, PlayStation 3, Playstation 4
game]. Planegge, Germany: Deep Silver.
Bethesda Game Studios. (2008). Fallout 3 [PC game]. Rockville, MD: Bethesda Softworks.
BioWare. (2007). Mass effect [Pc game]. Edmonton, Canada: Microsoft Game Studios, &
Electronic Arts.
BioWare. (2010). Mass effect 2 [PC game]. Edmonton, Canada: Electronic Arts.
BioWare. (2012). Mass effect 3 [PC game]. Edmonton, Canada: Electronic Arts.
Birch, A. (2014). The problem of morality in videogames. In Den of Geek. Retrieved
September 7, 2016, from http://www.denofgeek.com/games/29837/the-problem-of-moral
ity-in-videogames
Bosman, F. (2016). The Word has become Game. Researching religion in digital games.
Online. Heidelberg Journal for Religions on the Internet, 11, 28Â­45.
Boyan, A. (2015). A massively moral game? Mass Effect as a case study to understand the
influence of players' moral intuitions on adherence to hero or antihero play styles. Journal
of Gaming and Virtual Worlds, 7, 41Â­57.
Conklin, J. (2006). Dialogue mapping. Building shared understanding of wicked problems.
Chichester, England: Wiley.
Dotnod Entertainment. (2015). Life is strange [PC, Xbox, Xbox One, PlayStation 3,
Playstation 4 game]. Shinjuku, Japan: Square Enix.
Heidbrink, S., Knoll, T., & Wysocki, J. (2014). Theorizing religion in digital games. Perspectives
and approaches. Online--Heidelberg Journal of Religions on the Internet, 5, 5Â­50.
Heidbrink, S., Knoll, T., & Wysocki, J. (2015). "Venturing into the unknown" (?)
Method(ological) reflections on religion and digital games, gamers and gaming.
Online--Heidelberg Journal of Religions on the Internet, 7, 61Â­84.
Hellekson, K. (2001). The alternate history. Refiguring historical time. Kent: Kent State
University Press.
Hocking, C. (2007). Ludonarrative dissonance in Bioshock'. In Click nothing. Retrieved
September 17, 2016, from http://clicknothing.typepad.com/click_nothing/2007/10/ludo
narrative-d.html
Knoll, T. (2014, October 17). Laser-guided karma? Choice, agency & moral decision making
systems in videogames. Paper presented at game conference `Playing God', Utrecht, the
Netherlands.
Knoll, T. (2015). "Are those the only two solutions?" Dealing with choice, agency and religion
in digital games. Online. Heidelberg Journal for Religions on the Internet, 7, 207Â­226.
Lionhead Studios. (2004). Fable [PC, Xbox game]. Redmond, WA: Microsoft Game Studios.
16 Games and Culture XX(X)
Lionhead Studios. (2008). Fable 2 [PC, Xbox 360 game]. Redmond, WA: Microsoft Game
Studios.
LionheadStudios.(2010).Fable3[PC,Xbox360game].Redmond,WA:MicrosoftGameStudios.
Nguyen, R. (2016). Beyond the moral binary. Decision-making in video games. In With a
terrible fate. Retrieved on September 17, 2016, from https://withaterriblefate.com/2016/
04/25/beyond-the-moral-binary-decision-making-in-video-games/
Rio, C. (2014). The morality system in games has outlived its usefulness. In The Escapist.
Retrieved September 17, 2016, from http://www.escapistmagazine.com/articles/view/fea
tures/11266-The-Morality-System-in-Games-Has-Outlived-Its-Usefulness
Rittel, H., & Webber, M. (1973). Dilemmas in a general theory of planning. Policy Sciences,
4, 155Â­169.
Ryan, M. (2006). Avatars of story. Minneapolis: University of Minnesota Press.
Schulzke, M. (2009). Moral decision making in Fallout. Game Studies, 9. Retrieved
September 17, 2016, from http://gamestudies.org/0902/articles/schulzke
Sicart, M. (2010). Wicked games. On the design of ethical gameplay. In B. Christensen (ed.),
Proceedings of the 1st DESIRE Network Conference on creativity and innovation in
design. Lancaster, England: Desire Network, 101Â­111.
Sicart, M. (2013a). Moral dilemmas in computer games. Design Issues, 29, 28Â­37.
Sicart, M. (2013b). Beyond choices. The design of ethical gameplay. Cambridge: The MIT Press.
Sucker Punch Productions. (2009). Infamous [PlayStation 3 game]. San Mateo, CA: Sony
Interactive Entertainment.
Sucker Punch Productions. (2011). Infamous 2 [PlayStation 3 game]. San Mateo, CA: Sony
Interactive Entertainment.
Sucker Punch Productions. (2014). Infamous 3 [PlayStation 4 game]. San Mateo, CA: Sony
Interactive Entertainment.
Svelch, J. (2010). The good, the bad, and the player. The challenges to moral engagement. In
K. Schrier & D. Gibson (Eds.), Ethics and game design. Teaching values through play (pp.
52Â­68). New York, NY: Information Science Reference.
Takacs, M. (2013). 5 Mistakes every videogame with a morality system makes. Dorkly.
Retrieved September 17, 2016, from http://www.dorkly.com/post/56575/5-mistakes-
every-videogame-with-a-morality-system-makes
Zagal, J. (2009). Ethically notable videogames. Moral dilemmas and gameplay. Paper pre-
sented at the international DIGRA conference, London, UK. Retrieved September 17,
2016, from https://www.academia.edu/2809395/Ethically_notable_videogames_Moral_
dilemmas_and_gameplay
Author Biography
Frank G. Bosman is a cultural theologian at the Tilburg Cobbenhagen Center, Tilburg
University, the Netherlands. His dissertation in 2014 dealt with the German Catholic and
Dadaist Hugo Ball. Bosman is the author of many articles and books about the relation
between culture, theology, and faith, focusing on the role of religion and religious themes
in digital games.
Bosman 17
