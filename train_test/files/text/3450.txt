SAGE Open
July-September 2015: 1
­9
© The Author(s) 2015
DOI: 10.1177/2158244015607936
sgo.sagepub.com
Creative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License
(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of
the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages
(https://us.sagepub.com/en-us/nam/open-access-at-sage).
Article
Introduction
Recent years have seen a drive to implement positive
changes in English language support and development
practice in Australian higher education. This has been
spurred by Birrell, Hawthorne, and Richardson's (2006)
report evaluating Australia's General Skilled Migration
Categories, which noted that "many international students
enter and exit Australian courses at IELTS levels far below
the published guidelines" (p. 107). Another study by Birrell
(2006) reported that one in three international students did
not achieve an International English Language Testing
System (IELTS) score of 6.0 (typically required for entry to
tertiary institutions) by the end of their university programs.
These studies have placed the onus for ensuring adequate
language skills on institutions, forcing universities to reap-
praise their language support practices. Their findings
underline the necessity for appropriate academic and lin-
guistic support programs (Barrett-Lennard, Dunworth,
& Harris, 2011; Birrell, 2006; Briguglio & Howe, 2006) for
students who speak English as an additional language
(EAL).
One language support resource often employed at
Australian institutions is individual academic writing consul-
tations (Arkoudis & Starfield, 2007; Stevenson & Kokkinn,
2009; Wilson, Collins, Couchman, & Li, 2011). Academic
language and learning (ALL) advisors support students' aca-
demicwritingthroughtargetedone-to-onetutoring(Chanock,
2000) to assist students to gain sufficient linguistic and aca-
demic skills to become independent learners. The specific
practices vary between universities in terms of location and
context (e.g., within a library or faculty or in a dedicated
ALL unit or as part of a general support resource), the dura-
tion of sessions, the nomenclature (appointment, tutorial,
session, drop-in), how students access the service (self-
select, referral, or both), and how frequently they can access
607936
SGOXXX10.1177/2158244015607936SAGE OpenWalkinshaw et al.
research-article2015
1Griffith University, Queensland, Australia
2University of Victoria, British Columbia, Canada
Corresponding Author:
Ian Walkinshaw, School of Languages and Linguistics, Griffith University,
170 Kessels Road, Nathan, Queensland 4111, Australia.
Email: i.walkinshaw@griffith.edu.au
Individual Consultations: Academic
Writing Outcomes for International
Students
Ian Walkinshaw1, Todd Milford2, and Keri Freeman1
Abstract
Responding to calls for research into measurable English language outcomes from individual language support consultations
at universities, this study investigated the effect of individual consultations (ICs) on the academic writing skills and lexico-
grammatical competence of students who speak English as an additional language (EAL). Attendance by 31 EAL students
at ICs was recorded, and samples of their academic writing texts before and after a 9-month interval were compared.
Participants' academic writing skills were rated, and lexico-grammatical irregularities were quantified. No statistically
significant positive shifts manifested, due to the relatively short research period and limited participant uptake, but there
were encouraging predictors of future shifts given continued utilization of the service. First, although a Wilcoxon signed-rank
test showed no association between attendance at ICs and shifts in academic writing ability, a Spearman's rho calculation
suggested a tentative relationship to positive pre­post shifts in three academic writing sub-skills: Task Fulfillment, Grammar,
and Vocabulary. Second, instances of four common lexico-grammatical irregularities (subject/verb, wrong word, plural/
singular, and punctuation) declined at post-testing. Although only regular, sustained attendance would produce statistically
significant shifts, there is a potential association between participants' use of ICs and improved academic writing skills/lexico-
grammatical competence.
Keywords
academic language and learning, academic writing, English as an additional language, individual consultations
2 SAGE Open
it (limited or unlimited; Stevenson & Kokkinn, 2009).
Nevertheless, a commonality is that all such services manage
a myriad of language and learning needs that are specific to
individual students and which call for a targeted individual
response rather than a prepared lesson (Chanock, 2002).
Research has shown that the pedagogic attributes of indi-
vidual consultations (ICs) differ considerably from those of
classroom teaching. For example, the flexibility of ICs
allows teachers to focus on each student's specific language
and academic skill needs (Chanock, 2000). Consultations are
task driven, provide immediate formative feedback, and
allow students to learn, query, and experiment without judg-
ment by their peers, often increasing their engagement in the
consultations (Ewart, 2009). Chanock (2000) argues that as
well as improving students' academic writing and linguistic
skills, ICs may also positively influence the broader teaching
processes within universities: Their informal and confiden-
tial nature allows ALL advisors a more granular insight into
students' academic and linguistic needs, which may (if dis-
seminated) translate to a more targeted approach to class-
room teaching (cf. Shin, 2006).
The focus of the current research is a free one-to-one
English language consultation resource established by
Griffith University in 2007 to provide in-degree English lan-
guage support to EAL students and to encourage indepen-
dence in improving their English language skills. The service
provides weekly 45-min consultations on all five Griffith
University campuses and is accessed by several thousand
students each semester with an exponential year-on-year
increase.According to an internal report on Griffith's English
Language Enhancement Strategy (GELES; Griffith
University, 2012), 91.1% of users expressed satisfaction with
the service. Yet satisfaction does not necessarily impact
English language proficiency, as we shall see.
A primary issue for EAL students in Australia is the strug-
gle to assimilate to Western academic writing conventions
(Snow Andrade, 2006). Part of this is insufficient language
proficiency (Coxhead & Byrd, 2007), but other issues have
emerged as well. First, the educational backgrounds of many
EAL students differ from the Australian tertiary education
context. The issue is not necessarily one of ignorance: EAL
students frequently have a generic grasp of English for aca-
demic purposes, but are erroneously conforming to known
rules of good writing, which are not appropriate to the par-
ticular discipline (Pardoe, 2000). Second, students often
encounter a lack of information about the writing, format-
ting,orreferencingrequirementsoftheirdiscipline(Chanock,
2007). Unfortunately, support in this area may not be given
by discipline academics (Murray, 2010), who tend to see it as
outside their purview (Arkoudis & Starfield, 2007; Zhu,
2004). Discipline academics also tend to provide summative
rather than formative feedback, focusing on content not lin-
guistic competence--hence the need for EAL students' aca-
demic writing skills to be honed through targeted individual
instruction with a non-threatening, knowledgeable partner
(Chanock, 2000) to increase their likelihood of academic
success (Bretag, 2007).
Research Into Individual Consultation
Services
Despite the call for institutions to monitor the effectiveness
of language support strategies such as ICs (Hirsh, 2007), this
area has so far been under-explored, particularly in the
Australian context (Baik & Greig, 2009; Harryba, Guilfoyle,
& Knight, 2011; Hirsh, 2007). We will outline some of the
research done into the effectiveness of IC resources, begin-
ning with worldwide findings and then narrowing to the
Australian higher education context.
Williams (2004) explored the impact of ICs on the quality
of second language writers'draft writing at a U.S. university,
recording and analyzing five advisor­student interactions.
Both pre- and post-intervention texts were studied to deter-
mine the extent of the revisions made by the writers after
advisor feedback. The holistic grades for pre- and post-
intervention drafts were also compared to determine whether
the interventions had positive assessment outcomes.
Williams's (2004) study revealed that the interventions
encouraged small-scale revisions of sentence-level problems
but systemic text-level problems were less likely to be
revised. Also, issues explicitly raised by the advisor were
more likely to be revised than those implicitly treated. In
addition, student reaction to feedback was salient: Students
who wrote down advisors' comments about an issue were
more likely to revise the error than students who resisted or
ignored suggestions. Crucially, text revision did not always
lead to higher assessment outcomes.
In the U.K. context, a quantitative investigation of a uni-
versity's writing center was conducted by Yeats, Reddy,
Wheeler, Senior, and Murray (2010) to determine the impact
of attendance at ICs with advanced peer tutors on students'
achievement and academic progression. They compared the
academic records of 806 first-year students with their writing
center attendance and found that regular writing center attend-
ees recorded significantly higher levels of achievement (mea-
sured by recorded grades) than non-attendees. A higher
(though not statistically significant) number of attendees pro-
gressed to a more advanced course than non-attendees.
Notably, this service suffered from poor uptake (only 45 of
the 806 participants attended the writing center), perhaps
because it was staffed by peer tutors and not ALL specialists.
In Australia, Huijser, Kimmins, and Galligan (2008) eval-
uated the perceived effectiveness of ICs in mathematics and
academic writing with 55 students over a 2-week period
through student questionnaires and tutor logs. ICs were per-
ceived to have assisted the students to overcome inaccessible
and troublesome cognitive schemata ("stuck places"), as
well as providing a non-threatening emotional environment
for risk taking and error recovery. However, Huijser et al.'s
(2008) focus was limited to perceptions of the service rather
Walkinshaw et al. 3
than presenting measurable outcomes of its effectiveness. In
another Australian study, Woodward-Kron (2007) analyzed a
recorded IC with an EAL graduate student to probe student
learning processes. She found that the interaction largely
involved negotiation of surface-level errors, that is, linguistic
forms and text organization. Content was also addressed to a
certain extent, despite a faculty academic's advice to "fix the
grammar [but] don't touch the content" (p. 255). Wilson
et al. (2011) carried out a similar study with a mature-age
international student, concluding that ICs increased the stu-
dent's confidence, command of discipline-specific language,
use of academic literacy metalanguage, and technical com-
petencies such as structuring and paragraphing. These stud-
ies, despite their limited generalizability, illuminate some
core benefits of ICs. Again, however, they do not measure
outcomes in terms of developing academic writing skills.
Chanock (2002) points out that evaluating the effective-
ness of ICs is a challenging task. First, ALL work is con-
structed and positioned differently in different universities
and often sits outside their mainstream teaching evaluation
processes. So ALL departments often need to design and
implement their own evaluation mechanisms, reducing
comparability between institutions. Also, assessing what
students have learned and identifying how ALL instructors
contributed to that learning is challenging (Stevenson &
Kokkinn, 2009) because of all the other sources of language
input that second language (L2) learners are exposed to in a
target culture.
Although the studies above provide some insight into ICs
as a source of linguistic and academic support for EAL stu-
dents, empirical research is needed to quantitatively measure
linguistic development over time (Jun, Ramirez, & Cumming,
2010; Stevenson & Kokkinn, 2009; Williams, 2004). Also,
research to date has largely focused on student satisfaction
(Arkoudis & Starfield, 2007), rather than evaluating the link
to long-term student learning. The current study takes an ini-
tial step in addressing these issues by longitudinally examin-
ing some of the structural, lexical, and syntactic shifts in
EAL students' academic writing and attempting to identify
an association with attendance at ICs.
The preliminary and initiatory study outlined in this arti-
cle recorded participants' attendance at ICs and analyzed
their self-selected samples of academic writing pre- and
post-intervention (a 9-month interval). The study investi-
gated how students' academic writing ability might be influ-
enced by participation in ICs, as measured via attendance.
Our research questions were as follows:
Research Question 1: Does an association exist between
EAL students' participation in ICs and shifts in their aca-
demic writing skills and lexico-grammatical competence?
Research Question 2: Is there a relationship between the
extent of participants' utilization of this resource and the
degree of shift in academic writing skills and lexico-
grammatical competence?
We anticipated that there would be a relationship between
student participation in ICs and shifts in writing ability and
lexico-grammatical competence. Specifically, we hypothe-
sized the following:
Hypothesis 1a: Students who attended ICs during the
research period would increase their academic writing
ability and lexico-grammatical competence.
Hypothesis 1b: There would be no difference in develop-
ment across all four rating criteria for academic writing
ability (Task Fulfillment, Coherence and Cohesion,
Grammar and Vocabulary).
Hypothesis 2: There would be a relationship between the
number of ICs attended during the research period and
increases in academic writing ability and lexico-gram-
matical competence.
Data Collection Method and Its
Rationale
The effectiveness of the IC resource was measured through
written text analysis to illuminate criterion indicators of lan-
guage ability (Bachman, 1990). The two facets to the cur-
rent analysis were (a) rating written texts according to
established criteria to measure participants' academic writ-
ing skills and (b) identifying and quantifying specific lex-
ico-grammatical irregularities. The text types included in
the sample were reports and essays. All other text types
were rejected, as were texts which had been written collab-
oratively. Ethical clearance was obtained from the Griffith
University Office of Ethics.
Pre- and post-testing were carried out over a 9-month
research period to identify longitudinal shifts in academic
writing proficiency and lexico-grammatical skills. The ana-
lyzed texts were all grade-bearing, high-stakes assessment
items from the participants' discipline courses. The specified
minimum length was 1,000 words. In longer texts, lexico-
grammatical irregularities were counted from only a 1,000-
wordsectiontoensureoverallcomparabilitywhenquantifying
error density. Analysis was confined to the central portion of
these longer texts rather than the beginning or the end because
perusal of pre-intervention texts suggested a lower density of
errors at the beginning of texts and higher density toward the
end. Quantifying irregularities in these portions would there-
fore be misrepresentative of the overall text. Note that this
system applied only to the quantification of grammatical
irregularities: Overall academic skill ratings were based on
the entire text irrespective of length.
Rating Academic Writing Sub-Skills
Two raters separately gave each writing sample a score out of
20, that is, a score out of five for each of four criteria: Task
Fulfillment, Coherence and Cohesion, Grammar, and
Vocabulary. A simple product­moment correlation between
4 SAGE Open
the two raters' scores, determined to be an adequate measure
of the level of agreement, was calculated as r = .89, p < .000,
indicating a high level of agreement between raters. The four
rating criteria were broadly based on the assessment criteria
for the IELTS Writing Task 2 (Task Response, Coherence and
Cohesion, Lexical Resource, and Grammatical Range and
Accuracy; Shaw, 2002). Ratings for these four criteria were
calculated using a scale of English language proficiency based
on IELTS Writing Task 2 band descriptors, though employing
five assessment bands rather than the nine bands used in
IELTS descriptors. The assessment bands were limited to five
to simplify post-rating quantitative analysis, and also because
a higher number of bands produces significantly different rela-
tive mean scores in some rating instruments (cf. Dawes, 2008).
The descriptor was analytical rather than holistic, requiring
raters to focus judgments on specific writing features or skills.
This ensured reasonable agreement between raters such that a
reliable score could be formulated from dual ratings of a text.
It also allowed particular areas of language ability to be pro-
filed, which was useful for the analysis of participants whose
language skills were developing at varying rates.
The Task Fulfillment criterion was based on (a) the depth
of knowledge about the issue/s being discussed, and the
quality and relevance of the ideas presented; (b) whether a
clear and consistent argument was maintained throughout
the writing sample; and (c) whether academic conventions
(e.g., referencing, citation) were followed appropriately. The
Coherence and Cohesion criterion was based on (a) whether
the structure of the introduction and conclusion was appro-
priate for an academic text; (b) whether each body paragraph
contained a clear topic sentence and one main idea; (c)
whether ideas were developed, supported, and logically
grouped in paragraphs; and (d) whether there was appropri-
ate use of cohesive devices. The Grammar criterion encom-
passed (a) accurate and appropriate application of grammar,
density of lexico-grammatical irregularities, and communi-
cative effect; (b) whether there was a range of sentence struc-
tures; and (c) appropriate punctuation. Finally, theVocabulary
criterion consisted of (a) conveyance of precise meaning and
tone through choice of words; (b) the application of a range
of appropriate vocabulary, including discipline-specific
terms; and (c) accuracy of spelling.
Quantifying Lexico-Grammatical Irregularities
To afford a more granular insight into participants' lexico-
grammatical development, a taxonomy of 10 frequently
occurring lexico-grammatical irregularities was constructed:
·
· Subject/verb agreement (The topic of gun control are
controversial in the U.S.A.)
·
· Verb form (Australians enjoy to have democratic
freedom.)
·
· Tense (The assignment is submitted yesterday.)
·
· Word order (The exam one hour will be.)
·
· Wrong word used (The most of citizens are in favour
of euthanasia rights.)
·
· Word form (Privately educate is expensive in most
countries.)
·
· Count/non-count nouns (There are too many informa-
tions in this summary.)
·
· Plural/singular (There are three reason why smoking
should be banned.)
·
· Article (We have to take exam at the end of the
course.)
·
· Punctuation (india will host a united nations confer-
ence in july.)
Although other lexico-grammatical irregularities occur in
the sample, the taxonomy was limited to those listed above
as a broader analysis would have been outside the scope of
this research. Instances of the 10 irregularities were quanti-
fied in each pre- and post-intervention written text. They
were identified by the first rater and then verified or elimi-
nated by the second rater. After this calibration, pre­post
results were compared to illuminate shifts in the occurrence
of each irregularity.
Participants
The research was carried out on a convenience sample of 31
EAL students from a variety of nationalities and pathways of
entry to the university. The two criteria for inclusion were (a)
that participants were EAL students in their first semester of
study at the university, with an IELTS score of <7 or one or
more sub-scores (Reading, Writing, Speaking, or Listening)
of <6.5, and (b) that they were currently enrolled in a com-
pulsory one-semester English language enhancement course
(Fenton-Smith, Humphreys, Walkinshaw, Michael, & Lobo,
2015) at the university.Although attendance and engagement
in courses of this type tend to fluctuate (Lobo & Gurney,
2013), the attendance pattern of the 31 participants in this
study was relatively uniform: Their mean participation score
for their English language enhancement course (encompass-
ing attendance, engagement, and preparation) was 7.52 out
of 10 (standard deviation [SD] = 1.05), and the mode was 8,
indicating generally high attendance and engagement in the
course. This means that in principle the participants were
being exposed to a broadly similar amount of English lan-
guage support at their institution, and we tentatively posit
that any additional shifts in their academic writing skills or
lexico-grammatical competence were at least partly attribut-
able to their attendance at ICs.
We should note here the issue of attrition. Despite having
98 volunteers, only 31 usable written texts were received.
This issue is common in longitudinal studies of this type.
Craven's (2012) study of EAL students' English language
proficiency tested only 40 participants. O'Loughlin and
Arkoudis's (2009) study of EAL students at Australian uni-
versities had a sample of 63. Humphreys et al.'s (2012) study
Walkinshaw et al. 5
yielded 51 participants. Fortunately the current sample (n =
31) is sufficient for correlational research and to potentially
reach statistical significance (p < .05; Dornyei, 2007). To
determine an appropriate power level for this study, a sample
size calculation for the first research question (i.e., based
upon the potential association between students' participa-
tion in ICs and shifts in their academic writing ability and
lexico-grammatical competence) was calculated as n = 18
with an effect size of 0.7, power of 0.8, and alpha at .05
(Machin, Campbell, Fayers, & Pinol, 1997).
Procedure for Data Collection and Analysis
Volunteers were solicited through the distribution of flyers at
English language enhancement lectures. Anonymity was
ensured, reducing potential discrimination against non-par-
ticipants. Subsequently, writing samples were obtained from
participants at two points: the beginning of semester 1
(March) and the end of semester 2 (November). Participants'
attendance at ICs was recorded during the data-collection
period. Participants were advised that they could attend con-
sultations as often or as rarely as they chose, and received no
additional compensation for attendance. The development of
academic writing skill and lexico-grammatical competence,
and its tentative association with attendance at ICs, was mea-
sured by comparing pre- and post-testing academic writing
ratings and the density of lexico-grammatical irregularities
with the number of ICs attended over the research period.
Results
This section addresses the two research questions posed ear-
lier, that is, whether an association exists between IC atten-
dance and shifts in academic writing/lexico-grammatical
competence, and whether there is a relationship between
extent of IC utilization and degree of shift. Before addressing
these research questions, though, the first variable to consider
is participant uptake of the resource, due to its impact on other
findings. Table 1 presents the number of participants in this
study and their median level of attendance. The highest num-
ber of sessions attended was 20 (n = 1), and the lowest was 0
(n = 6); 48.1% (n = 15) attended four or more sessions, but
only 16.1% (n = 5) attended 10 or more sessions.
Because most participants only attended a small number
of consultations, a measurable shift in any aspect of their
academic writing competence was not expected. These nor-
mally occur over a much longer period; a 0.5 band improve-
ment in IELTS may require 4 to 6 months of contact
instruction (Birrell et al., 2006). In the present study, even
ten 45-min ICs would equate to only 7.5 hr of contact instruc-
tion. Hence, rather than use statistical significance as the sole
benchmark for success, we illuminate positive patterns,
which emerge after a limited period of IC attendance and
which might predict future significant shifts in academic
writing competence.
The ratings for each of the four academic sub-skills of
Task Fulfillment, Coherence and Cohesion, Grammar, and
Vocabulary are presented in Table 2. Table 2 offers mean val-
ues (as well as SD, range, and median) for the pre- and post-
testing ratings of each academic sub-skill as well as a total
value (i.e., the sum of each sub-skill).
All four ratings declined from pre- to post-testing. The
"Discussion" section will explore this finding in greater
detail.
Results from the raters' identification of the 10 common
lexico-grammatical irregularities are presented in Table 3.
Again, Table 3 offers mean values (as well as SD, range, and
median) for the pre- and post-testing ratings of each of the 10
irregularities.
Of note, more variability between pre- and post-testing
measures is evident in these data with six irregularity areas
increasing between pre- and post-testing (i.e., verb form,
tense, word order, word form, count/non-count, and article)
and four irregularity areas declining (i.e., subject/verb,
wrong word, plural/singular, and punctuation). We will
expand on this pattern in the "Discussion" section.
Sample text ratings were balanced against participants'
attendance at ICs to shed light on the two research questions.
The first research question asked whether an association
existed between EAL students'participation in ICs and shifts
in academic writing ability/lexico-grammatical competence.
To investigate this question, the academic writing sub-skill
ratings of participants who attended at least one session (n =
25) were compared. Because these data did not meet nor-
malcy assumptions for parametric analysis, the question of
shift in writing ability and IC attendance was addressed with
a Wilcoxon signed-rank test--a test based on the differences
between scores in the two conditions being compared. In this
case, participant ratings pre- and post-intervention were
compared. The Wilcoxon signed-rank test tests the null
hypothesis that there would be no difference (i.e., improve-
ment) in the ratings of students' written samples between
pre- and post-testing. The differences in the academic sub-
skills are computed as positive numbers. Data from the tabu-
lated results were entered into PASW SPSS 18 (IBM SPSS,
2010). No significant difference was found for participants
whose ratings in the four sub-skills increased after attending
at least one IC (T = 9, p = .55, r = -.27).
A Wilcoxon signed-rank test was also used to further
analyze each of the four academic sub-skills ratings in turn
to test the null hypothesis that there would be no positive
shift in the ratings of participants' written samples pre- and
post-intervention. This time, using a Wilcoxon signed-rank
test with a Bonferroni correction for inflated type 1 error
Table 1. Attendance at ICs Over the Research Period.
Number of participants Median attendance Range
31 3.00 20
6 SAGE Open
(i.e., p = .05/4 = .0125), no significant difference was found
for participants whose written sample showed a higher rat-
ing for Task Fulfillment (T = 8, p = .61, r = -.003), Coherence
and Cohesion (T = 9, p = .25, r = -.17), Grammar (T = 5,
p = .02, r = -.33), and Vocabulary (T = 7, p = .05, r = -.27)
after attending at least one consultation. With adjustments,
no support was found for rejecting the null hypothesis.
However, both Grammar and Vocabulary approached statis-
tical significance with reasonable effect sizes, suggesting an
association--though no definite statistical link at this
stage--between attendance at ICs and shifts in these two
sub-skills.We will expand on this finding in the "Discussion"
section.
In addition, Spearman's rho was used to measure the
strength of the relationship between attendance at ICs and
shifts in sub-skill ratings pre- and post-intervention, again
with a Bonferroni correction (i.e., p < .01). The findings are
presented in Table 4. In all, no significant increasing or
decreasing relationships were uncovered between any of
these paired variables.
Lack of statistical significance notwithstanding, some
potentially interesting patterns emerged. The majority of the
relationships were positive and offered some evidence that the
more consultations participants attended, the more their aca-
demic writing sub-skill ratings improved. The pattern is not
particularly strong except in the Grammar sub-skill, but may
predict a positive shift in written language proficiency given
continued use of this resource over a sustained period of time.
The "Discussion" section will further unpack this finding.
The second research question investigated the relation-
ship between the utilization of ICs and the degree of shift in
academic writing skills/lexico-grammatical competence. To
address this, we again employed a Wilcoxon signed-rank test
to explore each of the common irregularities in turn. The null
hypothesis was that there would be no increase or decline in
the number of grammatical irregularities in participants'
written samples pre- and post-intervention. A Wilcoxon
signed-rank test with a Bonferroni correction for inflated
type 1 error revealed no significant difference after attending
at least one consultation for the following irregularities: sub-
ject/verb (T = 10, p = .86, r = -.02), tense (T = 10, p = .85, r
= -.03), wrong word (T = 11, p = .65, r = -.06), count/non-
count (T = 5, p = .31, r = -.14), plural/singular (T = 11, p =
.31, r = -.14), article (T = 12, p = .79, r = -.03), and punctua-
tion (T = 11, p = .66, r = -.06). Instances of three irregularity
types increased post-intervention: verb form (T = 6, p = .04,
r = -.29), word order (T = 5, p = .02, r = -.24), and word
form (T = 8, p = .09, r = -.24), and would actually be signifi-
cant but for the post hoc adjustment to alpha. Again, no sup-
port was found for rejecting the null hypothesis for any of
these tests in a direction that indicated improvement.
Table 3. Lexico-Grammatical Irregularities Identified by Analysis of Written Submissions (Pre- and Post-Testing).
Subject/verb Verb form Tense
Word
order
Wrong
word Word form Count
Plural/
singular Article Punctuation
Error Pre Post Pre Post Pre Post Pre Post Pre Post Pre Post Pre Post Pre Post Pre Post Pre Post
N 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31
M 4.03 3.41 8.45 11.97 8.39 9.00 2.32 3.93 23.0 22.8 6.48 9.38 0.97 1.48 9.81 8.9 19.5 22.54 26.4 23.4
SD 3.44 2.43 6.89 7.46 5.99 6.80 2.19 2.59 11.59 10.48 4.40 6.43 2.02 1.43 7.56 9.44 10.4 10.9 18.36 10.4
Range 14.0 8.0 30.0 29.0 22.0 25.0 7.0 10.0 41.0 40.0 15.0 15.0 22.0 5.0 36.0 47.0 44.0 39.0 90.0 51.0
Median 3.00 3.00 6.00 11.00 7.00 8.00 2.00 4.00 21.00 22.00 6.00 8.00 0.00 1.00 8.00 6.00 19.00 20.00 22.00 23.00
Table 4. Attendance Record for Research Participants Over
Study Period.
Academic sub-skill rho p
Task Fulfillment .033 .86
Coherence and Cohesion -.080 .67
Grammar .140 .44
Vocabulary .058 .76
Total .048 .79
Table 2. Academic Sub Skills Identified by Analysis of Written Submissions (Pre- and Post-Testing).
Task Fulfillment
Coherence and
Cohesion Grammar Vocabulary Total
Sub-skill Pre Post Pre Post Pre Post Pre Post Pre Post
N 31 31 31 31 31 31 31 31 31 31
M 3.35 3.29 3.17 3.12 2.86 2.54 2.89 2.56 12.28 11.55
SD 0.77 0.73 0.70 0.69 0.78 0.75 0.72 0.76 2.69 2.66
Range 3.00 2.75 2.75 3.00 3.00 2.75 3.25 2.75 11.75 10.25
Median 3.50 3.25 3.25 3.25 3.00 2.50 3.00 2.50 12.5 11.25
Walkinshaw et al. 7
Discussion
We now attempt to interpret these findings. Before doing so,
though, we need to reiterate that there was only a small
degree of shift in language proficiency over 9 months, partly
because of participants' relatively low uptake of the service.
Indeed, the low uptake is an important finding in itself:
Although several thousand IC sessions are conducted at
Griffith University each semester, each individual normally
only attends a few sessions. Given the considerable time-on-
task normally required to demonstrably increase language
proficiency, it is unsurprising that only a limited shift
occurred during the research period. That said, several posi-
tive patterns emerged in the data, potentially pointing to a
more notable shift in linguistic competence after a longer
investigation period and with sustained participant utiliza-
tion of the service. We will examine the patterns here.
Pattern 1: Irregularity Areas Declined at Post-Test
Four lexico-grammatical items that participants frequently
used erroneously in the initial phase were less evident at
post-test: subject/verb, wrong word, plural/singular, and
punctuation (Table 3). Interestingly, these items all require
little or no morphological modification (e.g., changing a verb
form) to produce an appropriate variant. Conversely, several
of the six irregularity areas that increased in frequency over
the research period did call for morphological modification:
verb form, word form, and tense. Given the number of vari-
ables in play in second language acquisition, it would be sim-
plistic to argue that the items which participants did not need
to modify morphologically were more easily processed and
used than those they did. At this early stage, we merely spec-
ulate that less cognitive processing was required for one than
the other (Ellis, 1985, 2008), helping to accelerate process-
ing and appropriate production of the item. Future research
will investigate this phenomenon in more detail.
Pattern 2: Sub-Skill Ratings Approached
Significance Pre- and Post-Intervention
Two sub-skill ratings--Grammar and Vocabulary--
approached statistical significance between pre- and post-
testing, tentatively implying that a perceptible shift in
lexico-grammatical competence took place over the research
period. This encouraging result may reflect the greater focus
of ICs on lexico-grammar than on other academic skills
(Freeman, 2011; Moussu, 2013), potentially accelerating
lexico-grammatical intake. Other variables in play include
the targeted nature of IC services, their individual focus, and
the provision of immediate feedback on learner output
(Atwood, Turnbull, & Carpendale, 2010). Though not excep-
tional, this finding could foreshadow an eventual statistically
significant shift in lexico-grammatical competence among
the sample.
Pattern 3: Positive Association Between IC
Attendance and Sub-Skill Rating Shifts
The third positive pattern comes from analysis of the rela-
tionship between the extent of attendance at ICs and shifts in
sub-skill ratings (Table 4). None of the ratings approached
statistical significance, yet all except Coherence and
Cohesion shifted in a positive direction--particularly
Grammar, which as we mentioned before is a frequent focus
of IC sessions (Freeman, 2011). While a positive result for
only one sub-skill could be dismissed as a random occur-
rence, the apparently similar positive shift in three of the four
sub-skill ratings indicates a possible association between
extent of attendance at ICs and shifts in sub-skills. Given that
these shifts occurred despite limited attendance at ICs, it is
reasonable to speculate that more pronounced shifts might be
discernable after sustained attendance over a longer time
frame.
Concluding Remarks
In Australia's results-focused higher education sector
(Stevenson & Kokkinn, 2009), it would be desirable to
demonstrate that IC services measurably affect EAL stu-
dents' academic writing skills. The current research con-
tributes by identifying a likely association between EAL
students' attendance at ICs and gains in their academic
writing skills and lexico-grammatical competence. While
attending a small number of consultations makes only lim-
ited difference to an EAL student's writing ability, there are
predictors that regular attendance over a sustained period
will reap benefits.
As we mentioned earlier, this is an initiatory study,
intended more to guide future enquiry than to propose robust
findings itself. In future, longitudinal research may investi-
gate what degree of positive shift is most likely to occur over
time, and in which particular aspects of academic writing. To
compensate for our necessarily brief and incomplete taxon-
omy of lexico-grammatical irregularities, we also propose
that future research explore the potential effect of ICs on
other such lexico-grammatical irregularities in EAL stu-
dents' academic writing. In the meantime, we can report that
even if the EAL students in this study have not yet advanced
very far, the preliminary data indicate that they have taken
initial steps in the right direction.
Acknowledgments
The authors are grateful to Margaret Brigg, Simon Howell, Pamela
Humphreys, and Ian Johnson for their assistance. Thanks also to the
anonymous reviewers for their constructive feedback.
Declaration of Conflicting Interests
The author(s) declared no potential conflicts of interest with respect
to the research, authorship, and/or publication of this article.
8 SAGE Open
Funding
The author(s) disclosed receipt of the following financial support for
the research and/or authorship of this article: The Office of the
Deputy Vice Chancellor (Academic) at Griffith University, Professor
Sue Spence.
References
Arkoudis, S., & Starfield, S. (2007). In-course English language
development and support. Canberra: Australian Education
International.
Atwood, S., Turnbull, W., & Carpendale, J. I. M. (2010). The
construction of knowledge in classroom talk. Journal of the
Learning Sciences, 19, 358-402. doi:10.1080/10508406.2010
.481013
Bachman, L. F. (1990). Fundamental considerations in language
testing. Oxford, UK: Oxford University Press.
Baik, C., & Greig, J. (2009). Improving the academic outcomes
of undergraduate ESL students: The case for discipline-based
academic skills programs. Higher Education Research &
Development, 28, 400-416. doi:10.1080/07294360903067005
Barrett-Lennard,S.,Dunworth,K.,&Harris,A.(2011).Thegoodprac-
tice principles: Silver bullet or starter gun? Journal of Academic
Language and Learning, 5(2), A99-A106. Retrieved from http://
www.journal.aall.org.au/index.php/jall/article/view/166/112
Birrell, B. (2006). Implications of low English standards among
overseas students at Australian universities. People and Place,
14(4), 53-64. Retrieved from http://search.informit.com.au/doc
umentSummary;dn=332480460154352;res=IELHSS
Birrell, B., Hawthorne, L., & Richardson, S. (2006). Evaluation of
the general skilled migration categories. Canberra, Australia:
Department of Immigration and Multicultural Affairs.
Retrieved from http://www.immi.gov.au/media/publications/
research/gsm-report/index.htm
Bretag, T. (2007). The emperor's new clothes: Yes, there is a link
between English language competence and academic stan-
dards. People and Place, 15(1), 13-21. Retrieved from http://
search.informit.com.au/documentSummary;dn=33486548047
5401;res=IELHSS
Briguglio, C., & Howe, J. (2006). Critical perspectives: Students'
expectations of difficulties they may face in undertaking their
degree. Research and Development in Higher Education, 29,
50-56.
Chanock, K. (2000, September 21-23). Evaluating one-to-one
support for academic literacy: From institution to docu-
mentation. Paper presented at the Australian Council for
Adult Literacy International Conference, Lens on Literacy,
Fremantle, Australia.
Chanock, K. (2002). Problems and possibilities in evaluating one-
to-one language and academic skills teaching. In J. Webb &
P. McLean (Eds.), Academic skills advising: Evaluation for
program improvement and accountability (pp. 199-221).
Melbourne, Australia: Victorian Language and Learning
Network.
Chanock, K. (2007). Valuing individual consultations as input into
other modes of teaching. Journal of Academic Language and
Learning, 1(1), A1-A9. Retrieved from http://www.journal.
aall.org.au/index.php/jall/article/view/1/4
Coxhead, A., & Byrd, P. (2007). Preparing writing teachers to
teach the vocabulary and grammar of academic prose. Journal
of Second Language Writing, 16, 129-147. doi:10.1016/j.
jslw.2007.07.002
Craven, E. (2012). The quest for IELTS 7.0: Investigating English
language proficiency of international students in Australian
universities (IELTS Research Reports Vol. 13). Retrieved
from http://www.ielts.org/researchers/research/volume_13.
aspx
Dawes, J. (2008). Do data characteristics change according
to the number of scale points used? An experiment using
5-point, 7-point and 10-point scales. International Journal of
Market Research, 50, 61-77. Retrieved from http://ssrn.com/
abstract=2013613
Dornyei, Z. (2007). Research methods in applied linguistics.
Oxford, UK: Oxford University Press.
Ellis, R. (1985). Understanding second language acquisition.
Oxford, UK: Oxford University Press.
Ellis, R. (2008). The study of second language acquisition (2nd
ed.). Oxford, UK: Oxford University Press.
Ewart, D. E. (2009). L2 writing conferences: Investigating teacher
talk. Journal of Second Language Writing, 18, 251-269.
doi:10.1016/j.jslw.2009.06.002
Fenton-Smith, B., Humphreys, P., Walkinshaw, I., Michael, R., &
Lobo, A. (2015). Implementing a university-wide credit-bear-
ing English language enhancement program: Issues emerging
from practice. Studies in Higher Education. Advance online
publication. doi:10.1080/03075079.2015.1052736
Freeman, K. (2011). Investigating the teaching strategies used in
one-on-one academic writing consultations (Master's thesis).
Griffith University, Brisbane, Australia.
Griffith University. (2012). Report on GELES outcomes and activi-
ties 2012. Nathan, Australia: Griffith University.
Harryba, S. A., Guilfoyle, A., & Knight, S. (2011, February 1-2).
Staff perspectives on the role of English proficiency in pro-
viding support service. In Proceedings of the 20th Annual
Teaching Learning Forum. Perth, Australia: Edith Cowan
University. Retrieved from http://otl.curtin.edu.au/tlf/tlf2011/
refereed/contents-refereed.html
Hirsh, D. (2007). English language, academic support and academic
outcomes: A discussion paper. University of Sydney Papers in
TESOL, 2, 193-211.
Huijser, H., Kimmins, L., & Galligan, L. (2008). Evaluating indi-
vidual teaching on the road to embedding academic skills.
Journal of Academic Language and Learning, 2(1), 23-38.
Retrieved from http://www.journal.aall.org.au/index.php/jall/
article/view/61/54
Humphreys, P., Haugh, M., Fenton-Smith, B., Lobo, A., Michael,
R., & Walkinshaw, I. (2012). Tracking international students'
English proficiency over the first semester of undergraduate
study. Canberra: IELTS Australia.
IBM SPSS. (2010). PASW STATISTICS 18.0 command syntax ref-
erence. Chicago, IL: SPSS.
Jun, S. W., Ramirez, G., & Cumming, A. (2010). Tutoring ado-
lescents in literacy: A meta-analysis. McGill Journal of
Education, 45, 219-238. Retrieved from http://mje.mcgill.ca/
article/view/4770
Lobo, A., & Gurney, L. (2013). An investigation of the links
between international students' expectations and reality in the
English Language Enhancement Course. Journal of Further
and Higher Education, 38, 730-754. doi:10.1080/03098
77X.2013.817002
Walkinshaw et al. 9
Machin, D., Campbell, M., Fayers, P., & Pinol, A. (1997). Sample
size tables for clinical studies (2nd ed.). Oxford, UK: Blackwell
Science.
Moussu, L. (2013). Let's talk! ESL students' needs and writing cen-
tre philosophy. TESL Canada Journal, 30(2), 55-68.
Murray, N. (2010). Considerations in the post-enrolment assess-
ment of English language proficiency: Reflections from the
Australian context. Language Assessment Quarterly, 7, 343-
358. doi:10.1080/15434303.2010.484516
O'Loughlin, K., & Arkoudis, S. (2009). Investigating IELTS exit
score gains in higher education (IELTS Research Reports Vol.
10, No. 3). Retrieved from http://www.ielts.org/researchers/
research/volume_10.aspx
Pardoe, S. (2000). A question of attribution: The indeterminacy
of "learning from experience." In M. Lea & B. Stierer (Eds.),
Student writing in higher education: New contexts (pp. 125-
146). Buckingham, UK: SRHE and Open University Press.
Shaw, S. D. (2002). IELTS writing: Revising assessment criteria
and scales (Phase 2). Research Notes, 10, 10-13. Retrieved from
http://www.cambridgeenglish.org/Images/23124-research-
notes-10.pdf
Shin, S. J. (2006). Learning to teach writing through tutoring and
journal writing. Teachers and Teaching: Theory and Practice,
12, 325-345. doi:10.1080/13450600500467621
Snow Andrade, M. (2006). International students in English-
speaking universities. Journal of Research in International
Education, 5, 131-154. doi:10.1177/1475240906065589
Stevenson, M. D., & Kokkinn, B. A. (2009). Evaluating one-to-
one sessions of academic language and learning. Journal
of Academic Language and Learning, 3(2), A36-A50.
Retrieved from http://journal.aall.org.au/index.php/jall/article/
view/86/66
Williams, J. (2004). Tutoring and revision: Second language writ-
ers in the writing centre. Journal of Second Language Writing,
13, 173-201. doi:10.1016/j.jslw.2004.04.009
Wilson, K., Collins, G., Couchman, J., & Li, L. (2011).
Co-constructing academic literacy: Examining teacher-
student discourse in a one-to-one consultation. Journal
of Academic Language and Learning, 5(1), A139-A153.
Retrieved from http://www.journal.aall.org.au/index.php/jall/
article/view/138/103
Woodward-Kron, R. (2007). Negotiating meanings and scaffold-
ing learning: Writing support for non-English speaking back-
ground postgraduate students. Higher Education Research &
Development, 26, 253-268. doi:10.1080/07294360701494286
Yeats, R., Reddy, P., Wheeler, A., Senior, C., & Murray,
J. (2010). What a difference a writing centre makes: A
small scale study. Education & Training, 52, 499-507.
doi:10.1108/00400911011068450
Zhu, W. (2004). Faculty views on the importance of writing, the
nature of academic writing, and teaching and responding to
writing in the disciplines. Journal of Second Language Writing,
13, 29-48. doi:10.1016/j.jslw.2004.04.004
Author Biographies
Ian Walkinshaw is a lecturer in English at the School of Languages
and Linguistics, Griffith University, in Queensland, Australia.
Todd Milford works in educational psychology and leadership
studies at the University of Victoria in Canada.
Keri Freeman is a doctoral candidate in the School of Education
and Professional Studies, Griffith University, in Queensland,
Australia.
