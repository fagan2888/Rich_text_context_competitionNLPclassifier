Creative Commons Non Commercial CC-BY-NC: This article is distributed under the terms of the Creative Commons
Attribution-NonCommercial 3.0 License (http://www.creativecommons.org/licenses/by-nc/3.0/) which permits non-commercial use,
reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open
Access pages (https://us.sagepub.com/en-us/nam/open-access-at-sage).
Methodological Innovations
Volume 9: 1­11
© The Author(s) 2016
Reprints and permissions:
sagepub.co.uk/journalsPermissions.nav
DOI: 10.1177/2059799115622763
mio.sagepub.com
Introduction
In recent years, the ability of people to connect across the
globe has dramatically increased due to technological inno-
vations related to the Internet. Ongoing worldwide com-
puterization provides great opportunities for scientists to
enhance our understanding of the complex systems in which
humans live today. Increasing availability of massive social
media data abets efforts trying to explain collective behavior
with methods stemming from the natural and computational
sciences (Buldyrev et al., 2010; Goel et al., 2010; Golder and
Macy, 2011; Heiberger, 2014, 2015; King, 2011; Lazer et al.,
2009; May et al., 2008; Schweitzer et al., 2009).
Rising computer power enables and enhances this devel-
opment. The capacity to collect and analyze large amounts of
data with computational techniques has already transformed
physics (quantum computing; Steane, 1998) and biology
(computational biology; Kitano, 2002). However, in the
most influential journals of the social sciences, the potential
of Internet data and computational methods is only starting
to take off, although large companies are worth hundreds of
billions of dollars mainly because of their understanding to
utilize "big (social) data" (e.g. Google, Facebook, Twitter)
and state institutions are using similar techniques for the bet-
ter and worse of their citizens (most prominently the National
Security Agency [NSA]). Thus, "computational social
science" (CSS) is occurring. The question is whether it
happens with or without social scientists.
Installing computational social science:
Facing the challenges of new information
and communication technologies in social
science
Raphael H. Heiberger1 and Jan R. Riebling2
Abstract
Today's world allows people to connect over larger distances and in shorter intervals than ever before, widely monitored by
massive online data sources. Ongoing worldwide computerization has led to completely new opportunities for social scientists
to conceive human interactions and relations in unknown precision and quantities. However, the large data sets require
techniques that are more likely to be found in computer and natural sciences than in the established fields of social relations.
In order to facilitate the participation of social scientists in an emerging interdisciplinary research branch of "computational
social science," we propose in this article the usage of the Python programming language. First, we carve out its capacity to
handle "Big Data" in suitable formats. Second, we introduce programming libraries to analyze large networks and big text
corpora, conduct simulations, and compare their performance to their counterparts in the R environment. Furthermore, we
highlight practical tools implemented in Python for operational tasks like preparing presentations. Finally, we discuss how the
process of writing code may help to exemplify theoretical concepts and could lead to empirical applications that gain a better
understanding of the social processes initiated by the truly global connections of the Internet era.
Keywords
Computational social science, Python, R, data management, research practices, theory development
1Institute for Sociology, University of Bremen, Bremen, Germany
2Otto-Friedrich-Universität Bamberg, Bamberg, Germany
Corresponding author:
Raphael H. Heiberger, Institute for Sociology, University of Bremen,
Mary-Somerville-Str. 9, 28359 Bremen, Germany.
Email: raphael.heiberger@uni-bremen.de
622763
MIO0010.1177/2059799115622763Methodological InnovationsHeiberger and Riebling
research-article2016
Original Article
2 Methodological Innovations
To be sure, there have been recently some prominent pub-
lications that, for instance, are using computational text anal-
ysis (Bail, 2012), Ebay auction data (Diekmann et al., 2014),
the Internet movie database (Lutter, 2015), Facebook friend-
ship networks (Wimmer and Lewis, 2010), or even career
histories of video game developers and their creative prod-
ucts (De Vaan et al., 2015). Yet these efforts, valuable as they
may be, still seem very few when compared to the overall
research endeavor of the Social Sciences. In an age of
increasing technological means and challenges, this relative
reluctance seems ill-advised.
Given our profession as trained sociologists, we clearly
opt for a more active participation of our discipline in this
new research paradigm. This article aims to accomplish this
in two ways: on one hand, we want to discuss the chal-
lenges as well as the potential CSS poses for research
efforts in the field of Social Science. Since CSS has some-
times been relegated to either Big Data applications or
some very specific methods (mostly Social Network
Analysis [SNA]), we want to instead emphasize the broad
influence and transformative power CSS will have on the
Social Sciences in general. On the practical side, we illus-
trate the usage of computational methods and techniques in
the Python language, which serves as a generalized pro-
gramming framework to conduct all steps of a "CSS analy-
sis." Being far from the only programming language to
cater to the needs of CSS researchers, Python offers some
distinct advantages. Most prominent is its focus on the
readability and accessibility of code, which is especially
important to social scientists, who in general have received
little to no training in programming and coding. Python is
also easily extendable with a wide variety of libraries for
scientific computing. Since most of these extensions are
maintained by professional programmers and a very active
community, they are exceptionally well documented and
help is never far away.
For this purpose, we first discuss the position of social
scientists in the young but growing research area of CSS
and the challenges that may have led to the relative
absence. Next, we illustrate the capabilities of CSS with
regard to four major areas of the social scientific research
process. The first is the capacity to manage, gain access,
and analyze a wide variety of data structures, which is one
of the core properties of CSS. Second, we take a look at
some innovative methods which are normally associated
with CSS, more specifically SNA and quantitative text
analysis. These two steps--handling data and applying
methods with adequate speed--are strongly related to gen-
eral problems of CSS (Lazer et al., 2009). From these basic
virtues, we elaborate on further opportunities of CSS in
general and Python specifically. Thus, third, we highlight
the practical tools implemented in Python, for example,
techniques to prepare presentations or lectures. Finally, we
discuss some ideas about theory building, especially how
the process of writing code can help to exemplify
theoretical concepts. Altogether, we want to picture the
general usefulness of CSS for the "whole" research pro-
cess in Social Sciences, especially with regard to the chal-
lenges and opportunities provided by the Internet as a
driving force behind the revolution of data describing and
reflecting the social world.
Social scientists and CSS
The claim of CSS was first made prominently by Lazer et al.
(2009). They summarized the possibilities (and problems)
that arise with the availability of massive social data pro-
duced by the usage of the Internet.1 Most techniques neces-
sary to analyze these kinds of data are adapted from
computer science since social scientists are usually not
trained to handle "Big Data." However, the principal ques-
tions arising from growing global interconnectedness are
very much social. For instance, who is related to whom and
who has the most influential positions (Lewis et al., 2008)?
What impact has the structure of particular societies on
these relations (Onnela et al., 2007)? What are general prop-
erties of human communications (Karsai et al., 2011)? Thus,
"computer-science students had much better methodologi-
cal chops than their sociology counterparts, but the sociolo-
gists had much more interesting questions," as renowned
physicist Duncan Watts puts it (cited in Giles, 2012: 450).
The diagnosis of advantageous methodical knowledge
seems to be true not only for computer scientists as "natural
inhabitants" of the new world of digital connections, posts,
and tweets but also for physicists who are highly skilled in
the analysis of large amounts of data and complex systems.
Consequently, there exists a growing movement within phys-
ics that tries to take advantage of the increasingly growing
amount of online data. In stark contrast to the Social Sciences,
there is an atmosphere of departure that enables them to
write a "manifesto" (Conte et al., 2012) and to make a strong
claim on the analysis of large social (online) data. They pro-
pose a computer-based approach that could lead to predictive
and explanatory models that utilize the large data sets on
every level of behavior (i.e. individuals and their various
aggregations). A member of this group also published the
first textbook on CSS (Cioffi-Revilla, 2014). He also identi-
fies all Social Sciences as potential application areas and,
very wisely, does not narrow CSS to certain methods like
SNA nor to certain type or scale of data.
However, it is common sense among these authors that
Information and Communication Technologies (ICT) play a
key role in CSS since the possibilities provided by connected
objects like computers, smartphones, cars, and even houses
(as well as many more to come) have produced a worldwide
system that rivals our planet's ecology in its sheer complexity.
The ICT are transforming (already complex) social systems,
most visibly the economy and the financial markets, but also
the way we communicate and live in general. These structures
can be thought of as "Artificial Social Systems" (Helbing,
Heiberger and Riebling 3
2012: 6). They are man-made, yet at the same time give rise
to a far greater complexity than intended and understood by
their original creators. Consequently, many current societal
problems can be traced back to a lack of expertise in dealing
with these new social phenomena, including but not limited to
economic instabilities, environmental change, and cyber
warfare.
To mitigate present and future challenges regarding
the ICT, physicists already created the project initiative
"FutureICT" (www.futurict.eu/), funded by the European
Union (EU) as a "Flagship Pilot Project," which participated in
the race for the EU's US$1.3billion provided "to move the
ICT frontier." However, for social scientists, their own absence
should be more noteworthy than the overall funding scheme.
The project's Principal Investigators (PIs) are physicists, and
the list of disciplines involved in the "best of all relevant knowl-
edge" does not even include sociology or political sciences.
This underlines the fact that in the Social Sciences, efforts
to break into CSS seem rather modest. To be sure, there have
been studies conducted by social scientists that make use of
the new possibilities, especially in terms of networks
(Lehmann et al., 2015; Lewis et al., 2008; Qin et al., 2015;
Watts, 2004). However, compared to the publication and col-
laboration efforts in the computer and natural sciences, the
utilization of computational methods and large social data
sets of social scientists is rather expandable.
To be one of the disciplines participating in, by definition,
interdisciplinary CSS and not being marginalized from the
beginning, social scientists have to rethink their tools and
"computerize" their methods and theories. This is reminis-
cent of the situation in the SNA community around the mil-
lennium. SNA tries to explore empirical social interactions
with elaborated mathematical modeling (Scott and
Carrington, 2011; Wassermann and Faust, 1994)--and is
somehow ignored by physicists (Freeman, 2011). For a long
time, there existed many approaches in the Social Sciences
for the explanation and analysis of cohesive groups with
regard to social networks (Freeman and Webster, 1994;
Homans, 2003). Physicists widely ignored such efforts until
their colleagues Girvan and Newman (2002) developed an
algorithm to detect those communities. The missing mutual
recognition is also evident in regard to the "Small World"
structure (Milgram, 1967; Watts and Strogatz, 1998). This
formal approach to describe certain properties of networks
resulted in more papers and citations by natural scientists in
a few years than Social Science produced in 45
years
(Freeman, 2011). Knowing this story, one feels unsurprised
that the CSS manifesto mentioned above proposes "tradi-
tional tools of social sciences would at most scratch the sur-
face of these issues [of ICT related phenomena], whereas
new tools can shed light onto social behaviour from totally
different angles" (Conte et al., 2012: 327).
To support the development of new tools that are undoubt-
edly needed for the interconnected world of the 21st century,
we propose a technical instrument that allows the integration
of all necessary steps for the analysis: the Python language.
As a kind of minimum common sense in the existing litera-
ture (Cioffi-Revilla, 2014; Conte et al., 2012; Lazer et al.,
2009), CSS approaches focus the utilization of the ever-
growing computer power and large data sets stemming from
the Internet. We see at least two substantial (and intertwined)
barriers: first, to access terabytes of data is not part of stand-
ard statistical programs used in Social Sciences. The trace
left by the description of real-time interactions of entire pop-
ulations of humans is far greater than the largest longitudinal
social surveys are handling today. Second, existing methods
of analysis and theories are based on those surveys (and
other rather coarse observations) to conceive social behavior
and relations. In network theory, for instance, most theories
and methods are built on groups of maybe hundreds or, less
often, thousands of people, but are most definitely not
adapted to analyze data sets of millions of people, including
additional information about their locations, preferences, or
other attributes. One first step for social scientists to develop
such tools and, hence, to participate in the application of
computer-aided methods is a flexible programming lan-
guage. In our view, it seems preferable to choose a holistic
language for this purpose and to use the same language in all
steps of analysis, from data mining and transformation to
applying methods in practice. In the next sections, we are
going to elaborate on each of these steps and show the ben-
efits of using a general programming language.
New types of data
The digital revolution has greatly transformed one of the
central domains of Social Science, our data. We concur with
Savage and Burrows (2007) that the rise of new types of data
can be considered a fundamental "crisis of empirical sociol-
ogy." This follows from the fact that the careful acquisition
and quality of empirical data can be considered one of the
cornerstones of the Social Sciences claim to actually be part
of the sciences and not just social commentary. Among the
many challenges and problems stemming from the rise of
new data sources, two of them stand out. First, there is the
sheer amount of data generated by digital transactions, which
is sometimes labeled as "Big Data." Second, the emergence
of new data sources with the promise of solving central ques-
tions of the Social Sciences, which are not too big, but are
otherwise not suitable for analysis right away. The problem
here stems from the fact that much of these data are provided
and structured in ways unfamiliar to most social scientists.
We call this "Medium Data."
Big Data has become something of a buzz word in recent
years which seems to have finally reached the Social Sciences
although it has not been a very warm welcome (Burrows and
Savage, 2014; Ruths and Pfeffer, 2014; Uprichard, 2013).
Generally, the term refers to data which "exceeds the process-
ing capacity of conventional database systems" (Dumbill,
2012). Data of this magnitude are produced either as
4 Methodological Innovations
user-generated data in social media and networks (e.g. email,
video-streaming, online discussion groups) or as process-
generated data (e.g. administrative processes, server logs,
machine transactions). To get grasp of what "Big" means in
this context, we can take a look at some of the leading compa-
nies in this sector.According to Kerzner and Maniyam (2013),
these are some of the estimates for active data storage:
·
· Facebook: 40
petabyte of data storage/100
terrabyte
captured a day;
·
· Yahoo: 60pb a day;
·
· Twitter: 8tb a day.
These figures pale in comparison with the very rough esti-
mates on Google's active storage, which based on the power
consumption of Google's data centers is somewhere in the
range of 10exabytes per day.2
The problem Big Data poses for the Social Sciences is
twofold. On one hand, it is a technical problem; on the other
hand, it is mostly a problem on the conceptual level. From a
technical perspective, Big Data requires expertise in handling
large hierarchical data structures (e.g. HDFS, HBase, S3) and
using parallel programming techniques (i.e. MapReduce) to
analyze these data. While the statistical models are mostly the
same as in standard Social Science methodology, it is the
overall framework in which these models are implemented
with regard to software and hardware specification that is
challenging social scientists. Most of the Big Data applica-
tions are oriented around specific programming techniques,
like functional programming or similar models, which are
easy to grasp for programmers but at the same time are barely
known among social scientists.
In our opinion, this limited understanding of the technical
aspect sometimes spills over into the Social Sciences percep-
tion of Big Data. In general, Big Data is considered to be a
threat to the methodology and the empirical claims of Social
Science. Instead of incorporating it into the research method-
ologies, its conceptual and ethical problems are discussed
(e.g. Bail, 2014; Uprichard, 2013). Although there are plenty
of reasons to be concerned regarding Big Data, without
much practical knowledge about its implementation Social
Sciences stance on Big Data is in danger of sounding unin-
formed, whereas other disciplines are already making use of
the new possibilities.
Whether we like it or not, Big Data is here to stay. To
participate in its ongoing development, social scientists will
need to develop the technical expertise to at least understand
the basic concepts. Beyond that, there is and will be a grow-
ing demand for professionals inside and outside of academia
able to actually carry out Big Data analysis. This is espe-
cially true with regard to CSS.
Python seems to be a good choice in helping our disci-
pline in getting to grasps with Big Data. There are many
packages for interacting with large data sets as well as algo-
rithms designed for parallel computing.3 In addition to the
on-board functionality of Python distributions geared toward
scientific computing--most notably the IPython Anaconda
distribution--there are also specialized Big Data frameworks
(e.g. Hadoop, Sparks) which provide interfaces for high-
level languages like R or Python. Besides making the techni-
cal entry hurdles much less intimidating, Python provides an
easy access to the basics of computer science. It is easily
accessed and focuses on readable and easy to maintain code.
In short, one of the easiest ways to think like a computer
scientist is to "Think Python" (Downey, 2012).
Chances are that the majority of social scientists are never
going to work with actual Big Data. The tricky part here is
the word "actual." Since Big Data is usually defined as
"being too big for conventional means," the problematic
nature of data has to be considered with regard to the meth-
ods and techniques common in a discipline.4 Much of the
new data structures encountered in the Social Sciences would
not be seen as Big Data by computer scientists because they
are familiar with conventional means to tackle these kinds of
structures. We will refer to such data that are too big and
unfamiliar for social scientist, yet not big enough to warrant
Big Data analytics as "Medium Data."
So what are those conventional means defining the Social
Sciences in terms of data structures? Ask any social scientist
to visualize data; chances are they will picture a rectangular
table consisting of observations along the rows and variables
as columns. Since this is what we are taught in every under-
graduate course on methods, this is what data produced by
prestigious surveys looks like, and last but not least, this is
what most of the computer programs we use expect as input.
This tendency to equate data with tables has problematic
consequences for research practices and for the ability to
access new and unorthodox data structures.
If every row corresponds to one observation and most
variables have at least a chance to be present, the data frame
is one of the best solutions. Yet, if the sparsity of the data is
very high, meaning many cells of the data frame will be left
empty, the table structure becomes very cumbersome. This
is almost always the case when we look at social network or
textual data. For example, the number of nodes occurring in
a network is mostly orders of magnitudes greater than the
number of edges one node is connected to. Thus, a network
consisting of 1000 nodes and 15,000 edges would result in a
table of 1000 rows and 1000 columns (1million cells) while
representing the same data as a list of edges would yield a
data structure with a magnitude of only 15,000 units.
Network data are also a good example for the general
problem of complex, that is, hierarchical data. Consider a
network made up of social relationships among a group of
people. Besides the edges, there can be many different lev-
els of data attached to this structure. There could be data on
the intensity of the relationships or data concerning the per-
sons (e.g. age, sex) as well as meta-data about the entire
network (i.e. date of collection, context, etc.). Adding this
information to a table would result in many duplicates across
lines and if done extensively enough would make the whole
Heiberger and Riebling 5
thing indecipherable. The main advantage of using hierar-
chical data structures (e.g. XML) or relational databases
(SQL) over simple tables lies in their ability to manage
entire projects within one well-defined data framework.
From this data repository, data frames can be easily extracted
for further analysis. Instead of focusing on one data struc-
ture, CSS emphasizes techniques of converting data between
different data structures according to the needs of the overall
research goals.
Knowing how to manage hierarchical data is even more
important if we consider the new data generated by the ICT.
Most of the social data available online already exist in a
hierarchical standardized form. Webpages, for example, are
written in HTML, which is simply a hierarchical ordering of
elements. One of the most promising new data sources comes
in form of WebAPIs (Web-based Application Programming
Interfaces). In this model, a request for specific data points is
sent to a server, often mitigated through a wrapper in a spe-
cific language, for example, Python. Barring any connection
problems, the server responds by sending the requested data
to the client. Most of these data come in a hierarchical struc-
tured form, mostly XML or JSON. There are many interest-
ing WebAPIs for Social Science research.5 Most of the big
online social networks like Facebook and Twitter provide at
least limited access. Data repositories are also starting to
implement WebAPIs, for example, the World Bank
Indicators, Yahoo! Finance, Google Analytics, which can be
directly called from Python's Pandas package (together with
some other open data sources).
Innovative methods
The types of data delivered by ICT are mostly interconnected
by the design of the Internet as a network of billions of nodes.
Network analysis is therefore a direct candidate for under-
standing the structure of relations between diverse actors
around the globe. Furthermore, the Internet produces large
amounts of text in blogs, posts, messages, or news. They are
an essential part of today's communications, regardless of
whether one-to-one (e.g. Skype, Facebook messaging), one-
to-many (blogs, comments), many-to-one (Twitter accounts
of prominent people), or many-to-many (group conversa-
tions, forums). The potential of classic qualitative approaches
to understand these texts through "manual" reading is clearly
limited because they do not scale very well. A more quantita-
tive understanding as provided by "natural language process-
ing" is needed.
For both methods, convenient solutions are already imple-
mented in Python in terms of the graph-tool (Peixoto, 2015)
or NetworkX (Hagberg et al., 2008) as well as the Natural
Language Toolkit (NLTK) (Bird et al., 2009). As discussed
in the section "New types of data," the volume of Big Data
sets makes fast solutions more necessary than ever. To
support our arguments, we will test the performance of the
Python applications in comparison with the R environment
and its respective solutions since R is often seen as stand-
ard solution for statistical analysis in Social Sciences
(McCullough, 2010).6
To demonstrate the performance of Python in regard to
networks, we rely on a well-documented test that is con-
ducted by the author of the graph-tool package (Table 1).7
The network in question is a directed graph, with 39.796
nodes and 301.498 edges. Only calculations with one core
are considered (i.e. no multi-threading). As is expected,
betweenness centrality as a computational complex measure
takes most time (Brandes, 2001). The performance differ-
ences between packages are striking, but are not primarily
occurring between Python and R, but if the respective pack-
ages are assembled in C++. Both graph-tool and igraph
use C++ and their performance is rather alike, with slight
advances for graph-tool except for the calculation of
betweenness centrality. NetworkX, in contrast, is a pure
Python implementation and is by far the slowest of the pack-
ages. Thus, it is not the language alone that decides the
performance, but the package implementation.
With regard to text analysis, until now no comparison
between Python and R exists. The most elaborated solution
for text analysis in R is included in the tm package (Feinerer
et al., 2008). We test the performance by using the "Brown
corpus" created in 1961 at Brown University.8 It was the first
electronic corpus in English with more than 1million words
(N=1,161,192) and is widely used in quantitative linguistics
for "Part-of-speech tagging." The comparison has three steps
and starts with the same "corpus" consisting only of
sequences of tokens (i.e. no sentence or document structure):
first, we run a basic cleaning procedure by removing a list of
"stop words" (174 words used most often in the English lan-
guage) and write all words in lower cases to avoid
Table 1. Performance of packages in Python and R regarding social network analysis.
Measure Python graph-tool Python NetworkX R igraph
Single-source shortest path 0.0063s 0.127s 0.012s
PageRank 0.555s 34.26s 0.781s
K-core 0.0250s 0.9586s 0.0181s
Minimum spanning tree 0.0296s 0.413s 0.0397s
Betweenness 1977.6s (~33min) 53,716.692s (~14.9h) 1182.6s (~19.7min)
6 Methodological Innovations
ambiguities. Second, we calculate the word frequency of all
words in the "cleaned" corpus. Third, the incorporation of a
more elaborated detection of topics within the corpus is con-
ducted using a "Latent Semantic Analysis" (Deerwester
et al., 1990), which is implemented in the "genism" package
in Python (Rehurek and Sojka, 2010) and the "lsa" package
in R (Wild, 2015). For this purpose, all words of each cate-
gory are treated as one document, and the number of catego-
ries (15 in total) is used as the predefined number of topics
that should be retrieved.
The results in Table 2 show that Python and the NLTK
package largely outperform R. This is true for the simple
cleaning procedures as well as for the calculation of the word
frequencies, indicating that R has problems with "strings"
and, consequently, manipulating and/or counting text ele-
ments since it is designed for statistical analysis using vector
matrices. The NLTK package, in contrast, provides a very
fast and convenient way to analyze large amounts of text. As
we have already seen with the analysis of networks, the per-
formance depends very much on the package in use. Striking
as the differences between Python and R in terms of simple
word transformations may be, the performance of the LSA
package is much closer to its Python counterpart. Still, the
time R needs for the transformation of the "bag-of-words" in
a semantic space is nearly twice of Python.
The merit of this exercise lies not only in comparing dif-
ferent tools and packages but also in showing the differ-
ences across the ever-growing number of methods and
toolset. Besides contributing heavily to the development of
new methods and software solutions, CSS also offers the
expertise to decide which tool fits the job. Knowing how to
test and compare different implementations of the same
method becomes increasingly important. Without some
familiarity with algorithms and a basic knowledge of at
least one programming language, it is difficult to adequately
judge or increase the performance of software. The digital
literacy provided by CSS can be seen as one of the greatest
merits this emerging field has to offer. Yet, this contribution
of CSS can only be properly utilized if it becomes part of
the professional training of social scientists. A task for
which Python seems to be especially well suited because of
the easy access it provides to basic programming tech-
niques, as exemplified by Allen Downey's (2012) aptly
titled book Think Python. How to Think Like a Computer
Scientist.
Doing sociology in the 21st century
It is not only the data sources and methods of Social Sciences
that are transformed by ICT. The same can be said about the
day-to-day practices, meaning the way we do research, teach,
review literature, write articles, and so on. While we do
devote conferences, articles, and books to abstract models
and research techniques, there is not much discussion about
the actual way scientists engage in their daily work life.
Some disciplines may have manuals and protocols for inter-
acting with dangerous or valuable equipment, but most
professional expertise of scientists can be considered tacit
knowledge, which is mostly acquired on the job.
Since most of our work is nowadays in some way con-
nected or mitigated through digital media, CSS offers a
chance to make research more effective. Most of the practi-
cal work of scientists involves processing information in one
way or the other: sending emails, making presentations, for-
matting articles, preparing courses, just to name a few. Most
of these tasks are necessary byproducts or pre-conditions for
doing actual research.
Observing our own work flows and those of our col-
leagues, we found that there are two main problems that
seem to be responsible for a significant loss of time: first,
doing a machine's work the way a machine would do it; sec-
ond, using a patchwork of different, specialized programs
most of which are proprietary, thereby making it almost
impossible to know their exact inner workings or definitions
and resulting in an inflexible workflow.9
The overall usefulness of machines lies in the fact that
they do exactly what they are told in a repetitive fashion.
Humans would fail miserably if they would be given special-
ized machine tasks, while on the other hand machines would
fail at tasks most humans, regardless of their training, would
excel at. While we are generalists, being able to switch seam-
lessly between different tasks, machines are specialists
whose essential specialty is repetition. If you have ever
worked in the Social Sciences, chances are you were asked
to do machine tasks. Copying something from one Excel
spreadsheet to another, albeit in a different layout, is still
surprisingly (and horrifyingly) common.10 Most of this work
is apparently delegated to student workers, which basically
makes sure that future generations of social scientists will
have internalized bad practices from the start.
Besides the essentially dehumanizing aspects, there are
many practical reasons to avoid giving machine jobs to
Table 2. Performance of packages in Python and R regarding text analysis.
Procedure Python NLTK R tm
Cleaning (i.e. lower cases, remove stop words) 2.627s 799.2216s (~13min)
Frequency distribution 0.4869s 739.971s (~12min)
LSA 3.1729s 5.8021s
NLTK: Natural Language Toolkit; LSA: Latent Semantic Analysis.
Heiberger and Riebling 7
humans. Most prominently: humans are bad at these tasks.
Our species is prone to making errors when performing
repetitive tasks. Because a machine is instructed by humans
via code, their errors are essentially our errors as well, but in
this case we can find the error by looking at the code. More
precisely, human error seems to be mostly erratic, while
machine errors are systematic and can therefore be fixed.
Tragedies like the "Excel Depression" in economics
(Herndon et al., 2014; Reinhart and Rogoff, 2011) should
remind us of the separation between human tasks and
machine ones. In this case, errors of experienced researchers
and the reluctance to use reproducible code led to empirical
inadequate political advice in regards to the financial crisis
and contributed to the suffering resulting from the imple-
mented austerity policies.
Instead of doing a machine's job, CSS reminds us of the
human job at hand. We are the ones constructing and instruct-
ing the machines. Only by learning complete programming
languages and gaining at least some partial understanding of
digital technologies will we be able to delegate machine
tasks effectively. Because these are relatively new skills for
social scientists, we cannot rely on a pool of well-trained
professionals to make this transition for us. Those of us who
do engage in CSS do so for the sake of their own research
agendas and not to provide tech support to the rest of the
discipline. Therefore, an easy accessible programming lan-
guage like Python seems to be the right tool to bring digital
literacy to the Social Sciences. A simple understanding of
what a machine can do and how one can access these capa-
bilities to free oneself from the burdens of repetitive tasks in
order to have more time for actual research should be enough.
Because Python is rather flexible, fast, and can be easily
extended through modules, it is an excellent candidate for an
integrated framework for Social Science research (see also
the section `Innovative Methods'). Looking at the standard
practices of the social scientists around us, we found that
they employ a mixture of different programs. For example,
they would manage their data using one program, analyze it
in a second one, write it down in a third one, and finally use
a fourth one to create the presentation. Often other more spe-
cialized programs like citation management software were
added to the mix. This is not necessarily detrimental to the
speed and effectiveness of the work process because people
can become very accustomed to these procedures. The prob-
lem is the loss of flexibility and reproducibility because the
entire work flow can become broken when some of the steps
change. Technical or methodological requirements can
change, leading, for example, to data formats no longer being
compatible with the programs used for analysis. The chain of
programs can break at any point because in such a work flow
all points are interconnected but not necessarily maintained
in one framework. This problem is enhanced by the use of
proprietary software. A closed format has the consequence
that the user has to rely on the developers for ensuring com-
patibility which results in work flows often being guided by
the implicit demands of the software instead of the explicit
requirements of the subject matter.
An integrated framework can help to lessen some of these
problems. However, the flexibility offered by such a frame-
work will inevitably come at the cost of reorientation and
makes it necessary to acquire at least some basic technical
knowledge. The Jupyter (former IPython) Notebook keeps
this price very low, while at the same time offering a huge
functionality. Basically, the notebook is a browser-based edi-
tor which functions as a client connected to a kernel. Code
can be written inside a notebook and sent to the kernel which
will then return the results to this notebook. Since the project
became language agnostic, many different additional kernels
from various programming languages are offered (e.g. R,
Julia, C, Perl). Besides its capability to execute code, the
Notebook allows for easy text formatting in Markdown and
HTML and provides native support for the rendering of
mathematical equations through MathJax. The resulting
notebook can be converted to many different formats, which
given a specific style template can be publication-ready,
including figures and tables. Thanks to easy installable
plugins like RISE, the notebook can also be rendered as a
JSON slideshow by the click of a button. This slideshow is
live, meaning one can type in and execute code within the
running presentation, which is especially helpful when it
comes to teaching and giving workshops. Jupyter Notebooks
therefore provide an integrated, open-source framework with
all the functionality one could hope for.
Computational theory building
Theory is an instrument to explain what we observe and to
put single elements in (abstract) relations. In other words,
theories are ideas about the mechanism behind the evidence
that a researcher gathers in order to systematize her observa-
tions (Harrington, 2005: 3). These ordering frames should
not rely on certain schools of thoughts but on general rela-
tionships between elements, their assumptions, and restric-
tions (as done, for instance, in Friedkin (1986)). The best
way to do this would be as a formal model because only as
such a critical discourse can be ensured. A formal language
allows us to focus on the results and their theoretical implica-
tions rather than discuss the choice of words or argue
semantics.
Although not much thought regarding theory has been
published in the current CSS literature, there exist attempts
to model relations of actors to analyze social systems through
the interaction among autonomous, cognitive individuals
(Conte et al., 2001). Theories of social choice point in the
same general direction. They are highly intertwined with
computational methods and concentrate on social phenom-
ena also known from game theory regarding, for instance,
resource allocation and fair division of goods (Chevaleyre
et al., 2007). These approaches are mostly used in combina-
tion with social simulations, in which theoretically derived
8 Methodological Innovations
rules are tested in varying virtual contexts and are considered
one especially fruitful approach in CSS (Conte et al., 2012).
However, agent-based modeling faces problems when it
comes to the aggregation of individual actions, which is why
these variants of rational choice theory have been heavily
criticized in Social Sciences (for a recent overview, see Watts
(2014: 320)). The general opinion is that they lack (to a dif-
ferent degree) the second basic element of social theory in
addition to individual action: structure. Not speaking for all
theories of social action in general, we nevertheless argue
that we are describing a common ground of theoretical think-
ing about social phenomena. For almost all theories, the rela-
tion between structure and action is central, regardless of
whether it is spheres and individuals in Weber's work
(Kalberg, 1980), structures and practices in field theory
(Bourdieu, 1977; Fligstein and McAdam, 2012), systems and
communications (Bailey, 1994), or, in contemporary rational
choice, whether it is the interplay ("bridges") between the
frame of actions and the rational agent (Kroneberg and
Kalter, 2012). We agree with Watts (2014) that these are all
variations on the concept of "rationalizable action" (p. 316)
in the sense that rational (and computable) actions are
assumed to be limited by some sort of boundary. This has
been noted earlier and essentially led to the now famous
notion of a "bounded rationality" (Simon, 1982) of actors.
Assuming that this general pattern of interdependence
between structure and individual in social theory exists, we
want to transfer it to the process of coding. We think that
spelling out each theory is a necessary step to write any use-
ful code for empirical studies since any code must be trans-
lated in a formal language that the computer understands. In
order to do this, the theoretical concepts in mind must be
rewritten, that is, they have to be formalized. We exemplify
four steps that are essential for theory building, or even bet-
ter, for theoretical application since most theories should be
"testable" with that approach.
(1) The objects (agents) in question have to be defined
and, hence, operationalized. In sociology, this can be indi-
viduals, organizations, or any other form of (collective)
actor. (2) The agents have certain attributes that can be latent
(e.g. beliefs, expectations) or manifest (gender, age). The
attributes are programmatically inherited by Python's
classes. This means that properties of objects are stemming
from their affiliation to a certain class, resulting in a pattern
of succession for derivations of these objects. (3) The objects
have certain relations with each other. This step has to be
specified, including whether self-loops (i.e. self-references)
are useful. In the social world, these relations translate into
interactions between actors, for example, by ego communi-
cating with alter, which may implicate ego as a person (or
nation, organization, etc.) to a certain part. (4) The patterns
of relations between the attributes of the interacting agents
from the relations in (3) resemble Heinz von Foerster's
(2007) notion of "order from noise" (p. 13). This means that
the cooperation of elements runs along intrinsic ordering
properties of a "system," which can be any assemblage of
elements. In sociological terms, we then observe structure
in a sense that not every relation between every agent has an
equal probability, but some relations "are more equal than
others." This selection process stems directly from the irri-
tations due to the attributes (and accompanying expecta-
tions) of the actors in (2) since ego has to be aware of the
expectations of alter to arrange his own expectations. By
doing so (and not doing other things), certain patterns will
emerge that can be generally interpreted as structures, for
example, cultural preferences, shared beliefs, or common
personal histories.
The process from (1) to (4) is thought to be recursive,
meaning that the "heritage" in terms of classes is memorized,
but updated continuously by every loop. In this manner,
change is incorporated in the model. This corresponds to the
concept of "boundary objects" that "are plastic enough to be
adaptable across multiple viewpoints, yet maintain continu-
ity of identity" (Star, 1989: 37). The basic objects have such
a--programmatically inherited--contingency that they can
be defined as the researcher seems it appropriate but are open
enough to change according to interaction and structure. In
this sense, a code application of the elements of general
social theory avoids to think of interaction as a fixed mode in
reality, but as something that is continually renegotiated.
Also, it is not the efficiency of agents (and their models)
alone but mutual interaction and the iterative derivation of
structure and the recursive impact of this structure that con-
dition action.11 Setting up a model in Python, the general lay-
out of the language enforces a researcher to think along these
lines.
In addition to the general structuring of theories by a
formal language, Python also provides ways for the easy
implementation and construction of simulations. Specialized
packages like SimPy12 and nxsim already exist, which are
implemented in an object-oriented fashion. As described
under step (1), the object-oriented framework lends itself
especially well to agent-based simulations. In this case, we
can define the base agents as objects with basic strategies
(like cooperation and defection in the prisoner's dilemma)
and subsequently use these objects as templates for more
elaborate types of agents. This way we can progress from
simple games to iterative games to evolutionary and topologi-
cal simulation (demonstrated in pure Python by Isaac, 2008).
The main advantage of using such an approach to simu-
lation and modeling is twofold. First, it forces the scientist
to be explicit in the construction of the model. Every step of
the model needs to be created in a formal language, leading
to a precise and readable theory. Second, it allows for trial-
and-error theory development. To test a new idea, ad hoc
hypotheses or strategies can be easily incorporated in the
simulation, thereby creating a kind of experimental setting
to explore new ideas and get a feeling for the far-reaching
consequences they might have when introduced to complex
systems.
Heiberger and Riebling 9
Outlook
The Internet has not only revolutionized our daily lives,
global economic trade, or the work of intelligence agencies
but also the possibilities for researchers. In this article, we
discussed certain obstacles of this development and why
social scientists are until now bystanders in conducting
"CSS," a branch that studies the data delivered by the online
social realm. While physicists and other natural scientists are
already exploiting the digital connections and their social
consequences, we diagnose that social scientists are gener-
ally not well-prepared for this endeavor.
As an initial countermeasure, we proposed the usage of
Python as an easy-to-learn, general-purpose programming
language to facilitate the entrance to computational methods
and complex new data. We argue that Python is a very con-
venient choice since it provides researcher with ample tools
to handle the growing amount of rich data on human interac-
tions and offers the prospect of addressing major, and funda-
mentally interdisciplinary, scientific and social challenges.
We discussed its advantages in terms of appropriate struc-
tures for the huge collections of data, the easy and fast imple-
mentation of methods, the high practicability for operational
tasks, and the usefulness of writing code in order to derive
empirical applications from theoretical ideas. Beyond this, it
is mostly the superior readability and accessibility that makes
Python seem like a good choice to promote digital literacy
among Social Scientists and thereby opening up the emerg-
ing field of CSS.
A growing utilization of Python in Social Sciences may
also lead to an enhanced applicability of social scientists'
research results. Consultation of practitioners could
improve from (rather costly) samples, their distributions,
and correlations to very accurate, near real-time analysis of
empirical social behavior that we can observe now "live
and in action," that is, how people relate to each other in
various social contexts and not "only" agglomerations
about such social connections or limited examples with
specific properties. In this sense, the adaption of computa-
tional techniques could bring many new opportunities to
social scientists in order to share their expertise and to
derive everyday-life applications out of our efforts--which
would also increase the probability of getting heard in pub-
lic discussions and by decision makers. For instance, it
would be very practical in many circumstances to develop
more efficient ways to connect people and/or ideas over
large geographical distances (Heiberger and Riebling, in
press). Theoretically and methodically, this would mean to
close structural holes, a procedure that is already well
established in SNA (Burt, 1995). The challenge at hand
would be to adapt these solutions developed for rather
small groups on a much larger scale, that is, in fact, the
whole globe. What is already done in some privileged cor-
porations and consultancies may be worthwhile to be
explored by social scientists. In this way, social scientists
could contribute to a better understanding of the complex
social system that is now connected by a giant global infra-
structure with more transparent processes than any before.
Declaration of conflicting interests
The author(s) declared no potential conflicts of interest with respect
to the research, authorship, and/or publication of this article.
Funding
The author(s) received no financial support for the research,
authorship, and/or publication of this article.
Notes
 1. We will not further elaborate in this article on general prob-
lems of "computational social science." This is done in other
articles in greater detail (Lazer et al., 2009, 2014; Ruths and
Pfeffer, 2014).
 2. Calculated by Randal Munroe in his "What If" Blog. This fig-
ure does not contain data in "cold" storage.
 3. An overview over the essential packages needed to take a look
into Big Data analytics using Python and/or R can be found
here.
4. There is a second, much more subtle reason to be skeptical
about the urgency to utilize Big Data methods in the Social
Sciences--the general timeframe in which a task should be
executed. For example, no social network could afford to make
its customers wait a week to connect with their friends. In the
context of research and the construction of abstract models,
there is no need to rely on almost instant results.
 5. We provided mostly hyperlinks to python wrappers for the
general Application Programming Interfaces (APIs) since
we focus on Python in this article. It should be mentioned,
however, that wrappers in many different languages exist.
 6. The tests were run on an Intel Core i5-4300M CPU with 8GB
RAM.
7. https://graph-tool.skewed.de/performance
8. http://clu.uni.no/icame/brown/bcm.html
 9. Of course, there are many more inefficiencies and nonsensi-
cal time-consuming activities forced upon scientists which
are essentially beyond our own control. For example, journals
not providing formatting templates or administrative red-tape
doled out generously by universities.
10. To give short anecdotal evidence of the "tantalusian" conse-
quences: at the university of one of the authors, a research
assistant was specifically hired to transfer data from a website
into an Excel sheet and to update that Excel sheet whenever
the data on the site changed. The real tragedy stems from the
fact that the website essentially serves XML data. Years ago,
we had been asked to do a similar task; using an ordinary
phone we called the site's administrator and simply asked him
politely to send us a copy of the data in question. This helps to
show that the problem lies not only in the absence of techni-
cal expertise. As long as we are willing to do a machine's job,
someone else gets to do the human job.
11. These issues of mutual influence within and between com-
plex social entities are, for instance, also discussed in Niklas
Luhmann's (1990) comprehensive work about social systems.
10 Methodological Innovations
His ideas, in turn, are strongly based on findings about mecha-
nisms of self-organization and perpetuation in biological sys-
tems (Maturana and Varela, 1973).
12. A module for process-oriented discrete simulations.
References
Bail CA (2012) The Fringe Effect Civil Society Organizations
and the evolution of media discourse about Islam since the
September 11th attacks. American Sociological Review 77:
855­879.
Bail CA (2014) The cultural environment: Measuring culture with
big data. Theory and Society 43: 465­482.
Bailey KD (1994) Sociology and the New Systems Theory: Toward
a Theoretical Synthesis. Albany, NY: SUNY Press.
Bird S, Klein E and Loper E (2009) Natural Language Processing
with Python--Analyzing Text with the Natural Language
Toolkit. Sebastopol, CA: O'Reilly Media.
Bourdieu P (1977) Outline of a Theory of Practice. Cambridge,
UK: Cambridge University Press.
Brandes U (2001) A faster algorithm for betweenness centrality.
Journal of Mathematical Sociology 25: 163­177.
Buldyrev SV, Parshani R, Paul G, et al. (2010) Catastrophic cas-
cade of failures in interdependent networks. Nature 464:
1025­1028.
Burrows R and Savage M (2014) After the crisis? Big Data and the
methodological challenges of empirical sociology. Big Data
& Society 1: 1­6.
BurtRS(1995)StructuralHoles:TheSocialStructureofCompetition
(reprint edition). Cambridge, MA: Harvard University Press.
Chevaleyre Y, Endriss U, Lang J, et al. (2007) A short introduction
to computational social choice. In: van Leeuwen J, Italiano
GF, van der Hoek W, et al. (eds) SOFSEM 2007: Theory and
Practice of Computer Science. Berlin, Heidelberg: Springer,
pp. 51­69.
Cioffi-Revilla C (2014) Introduction to Computational Social
Science (Texts in Computer Science). London: Springer.
ConteR,EdmondsB,MossS,etal.(2001)Sociologyandsocialtheory
in agent based social simulation: A symposium. Computational
& Mathematical Organization Theory 7: 183­205.
Conte R, Gilbert N, Bonelli G, et al. (2012) Manifesto of compu-
tational social science. European Physical Journal: Special
Topics 214: 325­346.
De Vaan M, Stark D and Vedres B (2015) Game changer: The
topology of creativity. American Journal of Sociology 120:
1144­1194.
Deerwester S, Dumais ST, Furnas GW, et al. (1990) Indexing by
latent semantic analysis. Journal of the American Society for
Information Science 41: 391­407.
Diekmann A, Jann B, Przepiorka W, et al. (2014) Reputation for-
mation and the evolution of cooperation in anonymous online
markets. American Sociological Review 79: 65­85.
Downey A (2012) Think Python: How to Think Like a Computer
Scientist. Sebastopol, CA: O'Reilly Media.
Dumbill E (2012) What Is Big Data? O'Reilly Media. Available
at: https://beta.oreilly.com/ideas/what-is-big-data (accessed 3
August 2015).
Feinerer I, Hornik K and Meyer D (2008) Text mining infrastruc-
ture in R. Journal of Statistical Software 25: 1­54.
Fligstein N and McAdam D (2012) A Theory of Fields. New York:
Oxford University Press.
Freeman LC (2011) The development of social network analysis--
With an emphasis on recent events. In: Scott J and Carrington
PJ (eds) The SAGE Handbook of Social Network Analysis.
London: SAGE, pp. 26­54.
Freeman LC and Webster CM (1994) Interpersonal proximity in
social and cognitive space. Social Cognition 12: 223­247.
Friedkin NE (1986) A formal theory of social power. Journal of
Mathematical Sociology 12: 103­126.
Giles J (2012) Computational social science: Making the links.
Nature News 488: 448.
Girvan M and Newman ME (2002) Community structure in social
and biological networks. Proceedings of the National Academy
of Sciences 99: 7821­7826.
Goel S, Hofman JM, Lahaie S, et al. (2010) Predicting consumer
behavior with Web search. PNAS 107: 17486­17490.
Golder SA and Macy MW (2011) Diurnal and seasonal mood
vary with work, sleep, and daylength across diverse cultures.
Science 333: 1878­1881.
Hagberg AA, Schult DA and Swart PJ (2008) Exploring net-
work structure, dynamics, and function using NetworkX. In:
Varoquaux G, Vaught T and Millman J (eds) Proceedings of
the 7th Python in Science Conference (SciPy2008): Presented
at the SciPy2008. Pasadena, CA, pp. 11­15. Available at:
http://conference.scipy.org/proceedings/scipy2008/paper_2/
Harrington A (2005) Modern Social Theory. Oxford: Oxford
University Press.
Heiberger RH (2014) Stock network stability in times of crisis.
Physica A: Statistical Mechanics and its Applications 393:
376­381.
Heiberger RH (2015) Collective attention and stock prices:
Evidence from Google Trends Data on Standard and Poor's
100. PLoS ONE 10: e0135311.
Heiberger RH and Riebling J (2015) U.S. and whom? Structures
and communities of international economic research. Journal
of Social Structure 16: 1­12.
Helbing D (2012) Introduction: The FuturICT knowledge accelera-
tor towards a more resilient and sustainable future. European
Physical Journal: Special Topics 214: 5­9.
Herndon T, Ash M and Pollin R (2014) Does high public debt con-
sistently stifle economic growth? A critique of Reinhart and
Rogoff. Cambridge Journal of Economics 38: 257­279.
Homans GC (2003) The Human Group. New Brunswick, NJ:
Transaction Publishers.
Isaac AG (2008) Simulating evolutionary games: A Python-
based introduction. Journal of Artificial Societies and Social
Simulation 11: 8.
Kalberg S (1980) Max Weber's types of rationality: Cornerstones
for the analysis of rationalization processes in history.
American Journal of Sociology 85: 1145­1179.
Karsai M, Kivelä M, Pan RK, et al. (2011) Small but slow world:
How network topology and burstiness slow down spreading.
Physical Review E 83: 025102.
Kerzner M and Maniyam S (2013) Hadoop Illuminated. Hadoop
Illuminated LLC. Available at: http://hadoopilluminated.
com/hadoop_illuminated/hadoop-illuminated.pdf
King G (2011) Ensuring the data-rich future of the social sciences.
Science 331: 719­721.
Heiberger and Riebling 11
Kitano H (2002) Computational systems biology. Nature 420:
206­210.
Kroneberg C and Kalter F (2012) Rational choice theory and empir-
ical research: Methodological and theoretical contributions in
Europe. Annual Review of Sociology 38: 73­92.
Lazer D, Kennedy R, King G, et al. (2014) The parable of Google
Flu: Traps in Big Data analysis. Science 343: 1203­1205.
Lazer D, Pentland A, Adamic L, et al. (2009) Computational Social
Science. Science 323: 721­723.
Lehmann TC, Rolfsen JA and Clark TD (2015) Predicting the
trajectory of the evolving international cyber regime:
Simulating the growth of a social network. Social Networks
41: 72­84.
Lewis K, Kaufman J, Gonzalez M, et al. (2008) Tastes, ties, and
time: A new social network dataset using Facebook.com.
Social Networks 30: 330­342.
Luhmann N (1990) Essays on Self-Reference. New York: Columbia
University Press.
Lutter M (2015) Do women suffer from network closure? The
moderating effect of social capital on gender inequality
in a project-based labor market, 1929 to 2010. American
Sociological Review 80: 329­358.
McCullough BD (2010) Econometric computing with R. In: Vinod
HD (ed.) Advances in Social Science Research Using R. New
York: Springer, pp. 1­21.
Maturana HR and Varela F (eds) (1973) Autopoiesis and Cognition:
The Realization of the Living. Dordrecht: D. Reidel.
May RM, Levin SA and Sugihara G (2008) Complex systems:
Ecology for bankers. Nature 451: 893­895.
Milgram S (1967) The small world problem. Psychology Today 2:
60­67.
Onnela J-P, Saramäki J, Hyvönen J, et al. (2007) Structure and
tie strengths in mobile communication networks. PNAS 104:
7332­7336.
Peixoto TP (2015) graph-tool: Efficient network analysis with
python. Available at: https://graph-tool.skewed.de/ (accessed
29 July 2015).
Qin X, Cunningham P and Salter-Townshend M (2015) The
influence of network structures of Wikipedia discussion
pages on the efficiency of WikiProjects. Social Networks
43: 1­15.
Rehurek R and Sojka P (2010) Software framework for topic mod-
elling with large corpora. In: Proceedings of the LREC 2010
workshop on new challenges for NLP frameworks, 22 May,
pp. 45­50. Malta: ELRAValetta.
Reinhart CM and Rogoff KS (2011) The forgotten history of
domestic debt. The Economic Journal 121: 319­350.
Ruths D and Pfeffer J (2014) Social media for large studies of
behavior. Science 346: 1063­1064.
Savage M and Burrows R (2007) The coming crisis of empirical
sociology. Sociology 41: 885­899.
Schweitzer F, Fagiolo G, Sornette D, et al. (2009) Economic
networks: The new challenges. Science 325: 422.
Scott J and Carrington PJ (2011) The SAGE handbook of social
network analysis. Los Angeles, CA: SAGE.
Simon HA (1982) Models of Bounded Rationality: Empirically
Grounded Economic Reason. Cambridge, MA: MIT Press.
Star SL (1989) The structure of Ill-structured solutions: Boundary
objects and heterogeneous problem solving. In: Gasser LM
and Huhns N (eds) Distributed Artificial Intelligence. London:
Pitman, pp. 37­54.
Steane A (1998) Quantum computing. Reports on Progress in
Physics 61: 117­173.
Von Foerster H (2007) Understanding Understanding: Essays
on Cybernetics and Cognition. New York: Springer
Science+Business Media.
Uprichard E (2013) Big Data, Little Questions? Discover Society.
Available at: http://www.discoversociety.org/focus-big-data-
little-questions (accessed 11 January 2016).
Wassermann S and Faust K (1994) Social Network Analysis:
Methods and Applications. Cambridge, MA: Cambridge
University Press.
Watts DJ (2004) The "New" science of networks. Annual Review of
Sociology 30: 243­270.
Watts DJ (2014) Common sense and sociological explanations.
American Journal of Sociology 120: 313­351.
Watts DJ and Strogatz SH (1998) Collective dynamics of "small-
world" networks. Nature 393: 440­442.
Wild F (2015) LAS: Latent Semantic Analysis. Available at: https://
cran.r-project.org/web/packages/lsa/index.html
Wimmer A and Lewis K (2010) Beyond and below racial
homophily: ERG models of a friendship network docu-
mented on Facebook. American Journal of Sociology 116:
583­642.
Author biographies
Raphael H. Heiberger is a postdoc at the Institute for Sociology
at the University of Bremen. His primary research interests are in
social network analysis, statistical computing, and econophysics.
Jan R. Riebling is a doctoral student at the chair of theoretical soci-
ology at the university of Bamberg. His main research interests are
computational models of social symbols, mathematical sociology
and network analysis.
