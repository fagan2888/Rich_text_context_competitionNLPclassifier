VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 191
An Intelligent Project
Management Maturity
Model for Moroccan
Engineering Companies
Oussama Marrouni Alami, Otmane Bouksour, and Zitouni Beidouri
R E S E A R C H
KEY WORDS
Balanced Project Decision
Analysis Process
Maturity Model
Project Management
Project-based Organization
Moroccan Engineering
Sector
includes research articles
that focus on the analysis and
resolution of managerial and
academic issues based on
analytical and empirical or
case research
Engineering companies (ECs), operating mainly through projects, have acquired
considerable importance in the Moroccan economy for they serve as a one-stop
consultancy offering for all the services necessary for definition, production, and
project management (PM). They play an important role in supporting government
and investors' decision as well as in knowledge transfer to local businesses.
Engineering projects are managed in an environment often characterized by turbu-
lence, complexity, and crucial need for flexibility and high quality information. The
success or failure of these projects depends on decisions made during their life cycle.
The burden of a bad decision in general and in the engineering sector, in particular,
where business is generally run through projects, is becoming very overwhelming
and these companies are urged to change the way they make decisions. They have
to base their decisions more and more on high quality information, effective knowl-
edge management (KM), and competitive intelligence (CI), tools. More importantly,
they have to use an effective decision analysis process to avoid mental bias that is
the most important reason behind bad decisions. Furthermore, such a project deci-
sion analysis process should reinforce the strategic alignment of the organization
in order to achieve the desired decision strategic impact. However, the conjunction
and harmonization of all these processes and systems require smooth and careful
implementation, allowing for effective change management and high levels of
maturity in project decision-making capabilities and competencies. Accordingly,
the ECs need to climb suitable maturity levels, leading to both agility and flexi-
bility. While agility relies on strong and adaptive processes covering the three main
components of enterprise intelligence, namely business intelligence, CI and KM,
flexibility for a project-based organization means a combination in a proper dosage
of effective organizational PM processes, on the one hand, and balanced project
decision processes, on the other.
In this backdrop, this article reviews literature, analyses different processes and
models proposed in the last 10 years and develops an intelligent PM maturity model
for the Moroccan ECs. The proposed model, grounded on strong theoretical foun-
dations and participatory design approach, is a hybrid between staged and system-
based models. It balances between rigidity and stability ensured by staged models
and flexibility provided by the system-based models.
VIKALPA
The Journal for Decision Makers
40(2) 191­208
© 2015 Indian Institute of
Management, Ahmedabad
SAGE Publications
sagepub.in/home.nav
DOI: 10.1177/0256090915590329
http://vik.sagepub.com
Executive
Summary
192 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
Project-based organizations (PBOs) adopt a busi-
ness model that combines intelligent systems
with a set of project management (PM) processes.
Besides, they have to harmonize these efforts with
effective project decision analysis processes (PDAPs)
(Bresnen, Goussevskaia, & Swan, 2004; Vakkayil, 2010).
Intelligent systems ensure agility and project knowl-
edge capitalization and PM processes guarantee a
consistent and methodical approach when framing
and implementing project decisions (Virine & Trumper,
2008). According to the statistics published by FMCI
(2011), the Moroccan engineering market counts more
than 600 engineering companies (ECs) and employs
about 6,000 employees with 400 million euro turn-
over. More than 70 per cent of these companies are
located between Rabat, the administrative capital, and
Casablanca, the economic capital. While intervening in
more than 80 per cent of the total undertaken projects,
they serve only 40 per cent of the market, and the rest 60
per cent is satisfied by international ECs. The principal
engineering services are: construction, infrastructure,
water and environment, agriculture (including fishing
and forestry), industries and mines (Alami, Beidouri &
Bouksour, 2013c).
The engineering market is very competitive with
volatile business patterns, low barriers to entry and
strong impact of political decision-making (FIDIC,
2012). Accordingly, intelligent systems, continuously
improved PM processes, and effective decision anal-
ysis processes are among the urgent needs for ECs to
survive in today's tougher competition (FMCI, 2011).
This research aims at developing and proposing a
useful and practical prescriptive intelligent project
management maturity model (IP3M) that will serve
as an action plan for a gradual and methodical imple-
mentation of such combined systems in the case of
Moroccan engineering sector (MES).
Inspired by the extensive literature on intelligence
maturity models (MMs), project management matu-
rity model (PMMM) and project decision-making,
and an in-depth analysis of their strengths and weak-
nesses, this article aims at developing and testing a
prescriptive IP3M, applicable first to MES and poten-
tially extendable to PBOs in Morocco and abroad. The
construction of this IP3M is mainly based on a mixed
methods research, combining quantitative and qualita-
tive methods.
PROJECT DECISION-MAKING
Approaches to Decision-making
Project decision analysis is a branch of the decision
theory, which is the study of how to make better choices
when faced with uncertainties. This theory is handled
by authors in two different types of analyses: Normative
decision theory that describes how people should make
decisions and descriptive decision theory that describes
how people actually make decisions. The Foundation
of this theory can be traced to critical thinking theory
and process literature (McAuliffe, 2005; Safi & Burrell,
2007). These two aspects, with regards to the emotional
bias-critical pitfall (Johnson, 2006; Rombout & Wise,
2007; Wilson, 1998), result in three decision-making
approaches that overlap in decisions (Skinner, 2009):
·
Intuitive approach. The manager may intuitively
think that he/she is making the right decision
even if he/she does not have all the required
information.
·
Advocacy-based approach. In this approach, the
manager tries to follow a methodical decision
process, starting by a decision framing and gath-
ering of the needed information, but at the end,
he/she turns to his/her feeling and intuition
as the main decision argument. If the manager
agrees with the evaluation, he/she will take it
and make a decision. Otherwise, the manager
will request a re-evaluation.
·
Decision analysis approach. This approach aims at
diminishing the impact of intuition and feeling
towards a logical analysis of a correctly struc-
tured problem.
PROJECT DECISION ANALYSIS
Project Decision Analysis Process (PDAP)
The decision analysis process proposes a practical
framework of methods and tools to promote crea-
tivity and help people make better decisions (Keeney,
1982). The main goal of this process is to help project
managers overcome psychological pitfalls through
suitable techniques (Massey, Robinson, & Kaniel, 2006;
Virine & Trumper, 2008).
The PDAP is both practical and effective. It is practical,
as it can be easily integrated into the processes in place,
and does not create an additional level of bureaucracy;
its effectiveness is demonstrated in the next paragraph.
VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 193
The process includes four major phases (Virine &
Trumper, 2008):
1.
Decision framing. Decision framing helps deci-
sion-makers identify potential problems or
opportunities; assess business situations;
determine project objectives, trade-offs and
success criteria, and finally, identify uncertain-
ties. The project manager defines the scope of
the decision.
2.
Modelling the alternatives. A mathematical model
can help to analyse and estimate future events.
3.
Quantitative analysis. After the mathematical
model is ready, the analysis may include a
number of steps, depending on the situation.
4.
Actual performance tracking. It includes implemen-
tation, monitoring, and review of the decisions.
As Figure 1 shows, the scalability and flexibility of the
four phases allow effective feedbacks and adaptability.
Figure 1: Project Decision Analysis Framework
· Identifying potential
· Problems and opportunities
· Assessing business situation
· Determining success criteria
· Identifying uncertainties
· Generating alternatives
·Creating models for each project alternative
·Quantifying the uncertainties
·Determining what is most important
·Quantifying risks associated with the project
·Determining the value of new information
·Deciding on a course of action
·Implementing the best alternatives
·Monitoring the project implementation
·Review of decision experience
Decision
framing
Modelling the
situation
Quantitative
analysis
Actual
performance
tracking
Adaptability
Source: Adapted from Virine and Trumper (2008).
PDAP Effectiveness
Process effectiveness is a metric that assesses the quality
of the process with regard to organizational effective-
ness. It can be captured with several approaches. The
competing value framework (McCartt & Rohrbaugh,
1995; Quinn & Rohrbaugh, 1981, 1983; Rohrbaugh, 2005)
is one of the most widely used approaches. Developed
initially to assess to what extent the studied organiza-
tion is effective, this model was extended (Schilling,
Oeser & Schaub, 2007) to measure the fitness of the
process to the overall organizational effectiveness. It
highlights four dimensions that should be balanced:
·

adequate information (empirical perspective):
referring to the internal process model;
·

clear thinking about this information (rational
perspective): referring to the rational goal model;
·

flexibility and creativity in the process (political
perspective): referring to the human relations
model; and
·

sufficient participation (consensual perspective):
referring to the open system model.
The correlation between PDAP effectiveness and
organizational effectiveness is qualitatively drawn in
Figure 2.
Figure 2: Correlation between PDAP Effectiveness and
Organizational Effectiveness in Competing Values Framework
Flexibility
Control
External
Internal
Human relations
model (flexibility
and creativity)
Modelling
the situation
Decision
framing
Quantitative
Analysis
Internal process
model (adequate
information)
Rational
model (clear
thinking)
Open system
model (sufficient
participation)
Decision
framing
Actual
performance
tracking
Modelling
the situation
Quantitative
analysis
Decision
framing
Quantitative
analysis
Modelling
the situation
Decision
framing
Modelling the
situation
Quantitative
analysis
Actual
performance
tracking
Actual
performance
tracking
Actual
performance
tracking
Source: Adapted from Rohrbaugh (2005).
Broken arrows note the strength of correlation between
PDAP phases and competing values within the
organization.
Balanced PDAP
As defined by Virine and Trumper (2008), PDAP does
not consider strategic alignment when implementing
and tracking decisions. Therefore, it seems very bene-
ficial to reinforce PDAP by a suitable tool that allows
strategic alignment of decision-making, especially for
large and sensitive projects. In this regard, balanced
scorecard introduced by Kaplan and Norton (1992;
1996a; 1996b) can be of great help.
194 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
Balanced Scorecard is a performance management
tool that enables a company to translate its vision and
strategy into a tangible set of performance measures.
However, it is more than a measuring device. The score-
card provides an enterprise view of an organization's
overall performance by integrating financial measures
with other key performance indicators around customer
perspectives, internal business processes, and organ-
izational growth, learning, and innovation. (Kaplan &
Norton, 1992; 1996a; 1996b)
In order to ensure a strong link with the organization's
strategy, the last phase of PDAP, namely actual
performance tracking will serve as an information
preparation phase for Balanced Scorecard (BSC) in
which the adequacy of the decision's impact is tested
and analyzed with regards to the four perspectives (see
Figure 3). So far, a decision is either accepted or rejected
and feedbacks are used to improve and develop a more
balanced decision (see Figure 4).
Figure 3: Project Balanced Scorecard
Financial perspective
If a project succeeds, how does the
organization look to stakeholders?
Customer perspective
How should the project look to the client for the
organization to achieve its vision?
Internal perspective
Which project processes must be excelled in to satisfy the client?
Organizational learning perspective
How must the project contribute to organizational learning and improvement?
Vision
Source: Adapted from Barclay (2008) and Niebecker et al. (2008).
Thus, PDAP success will be achieved and sustained
only if
·

high quality information is available and acces-
sible easily and systematically;
·

the knowledge gained from projects is capitalized;
·

competitor's knowledge is taken permanently
into account;
·

project managers (deciders), whatever their
decision styles are (directive, analytical, concep-
tual or behavioural) (Rowe & Mason, 1987), are
trained and accustomed to the process; and
·

this process is integrated into a suitable PM
process.
Figure 4: Balanced PDAP
Decision framing
Modelling the situation
Quantitative analysis
Actual performance tracking
Financial perspective Customer perspective
Internal perspective
Organizational learning
perspective
Project balanced scorecard
Adaptability
Source: Authors' proposal.
In sum, PDAP will not be able to provide desired results
in terms of project decisions improvement unless an
intelligent PM model is adopted. Such a model will
ensure agility, knowledge capitalization and creation,
and effective PM processes. In this perspective, the
intelligent project-based organization model (IPBOM),
proposed by Alami, Beidouri, and Bouksour (2013a)
can serve as a ground for a further MM aiming at
implementing, gradually and effectively, an intelligent
PM business model (see Figure 5).
In the next sections, we will try to review intelligence
and PMMM literature and propose a methodical, useful
and practical IP3M that fits MES.
MATURITY MODELS: LITERATURE REVIEW
Concept and Origin
Based on the assumption of predictable patterns,
MMs represent theories about how organizational
capabilities evolve in a stage-by-stage manner along
an anticipated, desired or logical maturation path
(Gottschalk, 2009). They are also termed stages-
of-growth models, stage models or stage theories
(Rajteri, 2010).
VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 195
The development of MMs is viewed as a matter of
design science research by some Information Systems
(IS) researchers (Becker, Knackstedt, & Pöppelbuß, 2009;
Mettler & Rohner, 2009). Design science research seeks to
create innovative artefacts that are useful for coping with
human and organizational challenges (Hevner, March,
Park, & Ram, 2004).
Design of MMs
The usefulness of MMs is rarely debated in the literature
despite the popularity of MMs. A few studies refer to
the process of MM design, and some others to qualities
and components of MMs as design products. We will
focus on the design process of MMs.
Design Process
As for the process of MM design, De Bruin, Rosemann,
Freeze, and Kulkarni (2005) and Becker, Knackstedt,
and Pöppelbuß (2009) suggest procedure models.
De Bruin, Rosemann, Freeze, and Kulkarni (2005)
propose six phases intended to guide the design of a
descriptive MM and its advancement for prescriptive
and comparative purposes. Becker, Knackstedt, and
Pöppelbuß (2009) derive requirements and procedure
model from Hevner et al.'s (2004) design science
guidelines; they distinguish eight phases that provide
`a manual for the theoretically founded development
and evaluation of maturity models'. Actually, Becker,
Knackstedt, and Pöppelbuß (2009) propose a similar
process emphasizing the use of existing MMs and an
iterative development:
1. Scope. The scope phase defines the focus and iden-
tifies the relevant stakeholders and targeted audi-
ences. It determines the balance between complex
reality and model simplicity.
2. Design. The design phase addresses the require-
ments-based design and outlines the principal
concept of maturity, structure of levels, dimensions
and sub-dimensions (the meta-model).
3. Populate. In the populate phase, the corresponding
characteristics are determined and the maturity
assessment is defined, which includes the specifica-
tion of assessment instruments.
4. Test. The constructed model is tested on content
completeness and intended model scope accuracy
and the assessment instrument is tested for validity
and reliability.
Figure 5: Intelligent Project-based Organization Model (IPBOM) 
External Data/Information
Business intelligence system
Refinement
integration
transformation
DM &
KD
BA
Collection
Informati
on
Reporti
ng
Informati
on
Intelligence
Feedback and monitor
impact of action taken
Collection
Conversion
Communication
Countering
Requirements
Intelligence
Governance
Project
management
Project portfolio
selection
adaptability
Lessons Learned
Intelligence
Strategy
Optimization and
adaptability
Decisions
Internal data/Information
t
Acquisition
Refinement
Storage
/Retrieval
Distribution
Presentation
Optimization and
Source: Alami, Beidouri and Bouksour (2013a).
196 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
5. Deploy. The model is deployed to the initial stake-
holders and to an independent community.
6. Maintain. Once deployed, the model needs to be
kept in use and for a sufficient period of time--say,
a couple of years to ensure its evolution.
For designing and populating MMs, different
exploratory research methods and combinations of
these methods are proposed. Commonly mentioned
methods are literature analysis, Delphi and case studies
and focus groups (Becker, Knackstedt, & Pöppelbuß,
2009; Negash & Gray, 2008). Quantitative methods
are less frequently used for constructing MMs 
(Fraser,
Moultrie, & Gregory, 2002), as these models require a
sound theoretical foundation. Testing is also mostly
done qualitatively. The choice of the relevant research
method is influenced by the scope, stakeholders, and
targeted audiences (Lahrmann & Marx, 2010).
Comparison and Evaluation of Most Widely
Used MMs
Methodical Analysis of MMs
Mettler and Rohner (2009) propose a classification
scheme based on three different dimensions, namely
general model attributes, MM design and MM
use. These dimensions contain 16 attributes that
characterize an MM. For the specificity of this work,
only the following attributes are considered: origin,
maturity concept, reliability, and assessment. Some
other attributes are added for their relevance: structure,
primary focus, assessor (self-assessment or third-party
assessment), assessment, decision-making, culture and
strategic alignment concerns. The structure attribute
classifies the model into process-based, staged-based
and system-based categories (McBride, Henderson-
Sellers, & Zowghi, 2004). Staged models require total
master of a process before moving forward while
system-based models are mainly based on continuous
improvement approach in which maturity is obtained,
in addition to the implementation of new processes, by
the improvement of already established processes.
Project Management Maturity Models (PMMMs)
Table 1 provides a quick summary of the most popular
project management MMs found in literature and
examined by this research:
Limitations of Existing Frameworks
In general, the existing PMMMs suffer from the
following limitations:
· The models add bureaucratic red tape to their
management (Kerzner, 2001; 2004; 2005; 2006).
· Although aimed at increasing PM maturity, the
models seem to pay little attention to project
knowledge capitalization and how learning from
past experience can help improve PM processes.
When mentioned in the models, project knowledge
management is to be carried out to appropriately
close a project from an administrative point of view.
In most models, project reviews are in place only at
the highest levels of maturity.
Intelligent MMs
Table 2 provides a summary of the most popular intelli-
gent MMs found in literature and their evaluation.
Evaluation
Some researchers argue that MMs oversimplify reality
and lack empirical foundation (Benbasat, Dexter,
Drury, & Goldstein, 1984; De Bruin, Rosemann, Freeze
& Kulkarni, 2005; King & Kraemer, 1984; McCormack,
et al., 2009), while others (e.g., Mettler & Rohner, 2009)
propose adding a configurability aspect to MMs for the
necessary flexibility required to overcome internal and
external changes. King and Kraemer (1984) postulate
that MMs should focus on factors driving evolution
and change rather than a sequence of levels towards a
predefined `end state'. Intelligence MMs are generally
process-based models.
Comparison of PMMMs and Intelligent MMs
Table 3 summarizes the comparison of MMs with
regard to its main attributes.
BUILDING THE INTELLIGENT PROJECT
MANAGEMENT MATURITY MODEL (IP3M)
Why a New Project Management Maturity Model?
The need for a PMMM is derived from the need of a
new intelligent business model that combines flexi-
bility and agility for MECs. Major benefits of I3PM are
VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 197
Table 2: A Literature Review and Evaluation of Intelligence MMs
Name Author Structure Evaluation
Gartner's maturity
model (E)
(Rayner &
Schlegel,
2008)
It defines five levels (with generic labels like
unaware, tactical, focused, strategic and
pervasive) that are described textually.
·
Does not define dimensions, but gives textual hints
concerning sponsoring, organizational structure, scope
of BI initiative and metrics. The maturity concept is
object centric.
·
Reliability is not documented.
·
Application needs third-party assistance.
BIMM (business
information
maturity model) (F)
(Williams
& Williams,
2007)
Concentrates on three success factors
(alignment and governance, leverage and
delivery) and seven key process areas.
·
Focuses on the management perspective especially from
the cultural perspective.
·
Well documented with the series of questionnaires to
assist the users to perform self-evaluation (Rajteri, 2010).
·
However, criteria to evaluate the maturity level are not
well defined.
BIDM (business
intelligence
development
model) (G)
(Sacu &
Spruit, 2010)
Concentrates on three perspectives: people,
process and technology.
Six stages: predefined reporting, data marts,
enterprise-wide data warehouse, predictive
analytics, operational BI and business
performance management (BPM).
·
Used for business intelligence development rather than
business intelligence implementation.
·
Not well documented and criteria to evaluate the
maturity level are not well defined.
·
Concentrates on the technical aspects rather than
business point of view.
Table 1: Structure and Evaluation of PMMMs cited in the Literature
MM Authors Structure Evaluation
Capability maturity
model for software
(CMM® or CMM-
SW®) (A)
(Paulk, Curtis,
Chris, & Weber,
1993)
A staged model with five maturity levels
(initial, repeatable, defined, managed and
optimizing). Each maturity level is composed
of key process areas (KPAs) which when
performed collectively identify requirements
for achieving each maturity level.
CMM is often considered too voluminous (over 500
pages) and complex in nature.
Requires large investment amounts and needs a long
training time.
There is little emphasis on lessons learned from ongoing
retrospective evaluation of the project management
processes.
Project management
maturity model
(PMMM) (B)
(Kerzner, 2001;
2004; 2005;
2006)
A system based model with five maturity
levels (common knowledge, common
processes, singular methodology,
benchmarking and continuous improvement).
Its generality and descriptive nature offer little assistance
as to how an organization can actually move up
the maturity curve; except for use in benchmarking
information to improve the PM methodology, there is no
consideration of project knowledge management.
Organization project
management maturity
model OPM3 (C)
(PMI, 2008a;
2008b; 2013)
A system-based model with five main
components:
 · Directory of best practices
 · Directory of capabilities
 · List of observable outcomes
 · List of key performance indicators
 · Improvement plan directory
Although many implementations have been successful,
this model seems to be complicated and needs
important training effort and must be managed by a
well-established project management office (PMO).
Projects in controlled
environments
(PRINCE2) (D)
(OGC, 2009a,
2009b)
Defines four key attributes of each project. It
is divided into stages, each being considered a
distinct unit for management purposes.
A stage is compartmentalized into sub-
processes and has well-defined activities, finite
lifespan and organizational structure.
The deliveries of the stage products indicate
the completion of that stage. The project
stages correspond to the steps in a typical
project life cycle.
Despite several benefits, this model offers--sequential
and logical roadmap and well-documented
methodology--it is not an assessment tool and does
not measure PM on a maturity scale. It lacks details
with regard to all PM knowledge areas. Also, it does not
address the issue of how organizations can continuously
improve their PM processes.
Source: Authors' compilation.
Table 2 continued
198 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
EBIM (the
enterprise business
intelligence maturity
model) (H)
(Chee-Sok,
Yee-Wai, &
William, 2011)
This model consists of five core maturity levels
and four key dimensions, namely information
quality, master data management, warehousing
architecture and analytics.
·
It is relatively new and not well documented with best
practices and feedbacks from previous experiences.
·
Reliability is documented.
·
Does not consider knowledge issues.
IPBOMM (intelligent
project based
organizations
maturity model) (I)
(Alami,
(Beidouri, &
Bouksour,
2013b)
Developed to assist companies operating in
engineering sector so that they can acquire
agility and flexibility.
It is a five-staged model and each stage is
defined through specific key process areas.
·
It is relatively new and not well documented with best
practices and feedbacks from previous experiences.
·
Reliability is documented.
Source: Authors' compilation.
Table 2 continued
Table 3: Comparison of Intelligent MMs
MM Origin Maturity Concept Primary Focus Assessor Assessment Concerns
(1) Practice and
academic
Process Software industry Self-assessment Unclear Strategic alignment
culture
(2) Practice and
academic
Process Project-driven
organizations
Self-assessment Questionnaire Strategic alignment
culture
(3) Practice and
academic
Process Project-driven
organizations
Self-assessment­
Third-party
assessment
Unclear Strategic alignment
culture
decision-making
(4) Practice and
academic
Process Project-driven
organizations
Self-assessment Unclear Unclear
(5) Practice Object General Third-party assisted Unclear Strategic alignment
(6) Academic Object IT industry Unclear Questionnaire Unclear
(7) Practice Process IT industry Self-assessment Unclear Strategic alignment
culture
decision-making
(8) Academic People
and Process
Unclear Unclear Questionnaire Unclear
(9) Academic People and Process Project-based
organizations
Self-assessment Unclear Strategic alignment
decision-making
Source: Authors' compilation.
summarized in Table 4. These benefits are derived from
IPBOMM model (Alami, Beidouri, & Bouksour, 2013b)
and reinforced mainly by the introduction of the PM
methodology.
Except for IPBOMM, MMs analysed above do not
combine PM maturity and intelligence maturity, and
only a few of them present clear guidance towards
desired maturity. These reviewed models are either
stable but rigid process-based models or flexible with
a considerable risk of instability, especially for devel-
oping countries' businesses. In addition, they are
perceived as complicated and adding to bureaucracy
levels rather than being flexible. An effective MM
should rather reflect the actual concerns of the activity
with regard to its constraints and challenges.
To this effect, authors propose an IP3M based on a
typical case study analysis in order to take into consid-
eration, as far as possible, the specificities of MES. IP3M
is intended to balance between rigidity and stability,
ensured by staged models and flexibility provided by
the system-based models.
IP3M CONSTRUCTION
Methodology
The purpose of this section is to follow MMs' design
process presented earlier to come up with the expected
IP3M. This process includes six major phases: scope,
design, populate, test, deploy, and maintain phases.
Authors are more concerned about the first four
VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 199
phases, as deployment and maintenance wil llikely
take several years.
Mixed methods research is applied to these phases.
`Mixed methods research is an approach that combines
quantitative and qualitative research methods in the
same research inquiry. Such work can help develop
rich insights into various phenomena of interest that
cannot be fully understood using only a quantita-
tive or a qualitative method' (Viswanath, Susan, &
Hillol, 2013).
Table 5 exhibits methods and methods' type used to
develop design process phases.
Table 5: Methods and Methods' Type Used to Develop Design
Process Phases
Phase Method
Method's
Type
Scope,
Design and
Populate
A case study of a typical Moroccan
engineering company (MEC)
Qualitative
A sample of 15 project managers­
experts working in MEC and having
capitalized an average of 15 years'
experience within 12 different activities
Quantitative
Analytic generalization Qualitative
Test
(validation)
A sample of 13 experts working in 12
different MECs
Quantitative
Double-round experts (projects
managers) interviews
Qualitative
Source: Adapted from Alami, Beidouri, and Bouksour (2013c).
Table 4: Major Benefits of New Intelligent Business Model Dimensions
Model
Dimensions
Benefits
Strategic
Management
Critical
Success
Factors
Risk
Management
Improvement
of Value
Creation
Competitive
intelligence
*Adequate and quick response to external opportunities and
threats.
*Effective management of customers' explicit, implicit and
latent expectations.
*Diversification of MEC's book order.
*Updated external information for opportunity decision
analysis.
+++ ++ ++ +
Business
intelligence
*Business analytic and real-time approaches to optimize
project and general resource allocation.
*Strong basis for opportunity decision analysis.
*High quality-reliable accurate and comprehensive
information for decision analysis.
*Gathering information from different sources and ensuring
mastery in cost.
*Projects portfolio identification and optimization.
+ +++ ++ +++
Knowledge
management
*Technical and theoretical knowledge development.
*Help establish a corporate memory that will serves as basis
for organizational learning.
++ ++ ++ +++
Project
management
*Monitors projects risks.
*Focuses on relevant projects in terms of quality,
productivity, client satisfaction, supply chain and internal
organization.
*Strengthens leadership image.
*Optimizes managerial and commercial efforts.
+ + ++ +++
Governance *Effective information sharing policy.
*Transparent accountability framework.
*Enables project managers to make informed decision through
more decentralized decisions.
*Modernizes management tools and techniques.
+++ +++ ++ +++
Source: Adapted from Alami, Beidouri, and Bouksour (2013c).
Notes: `+'stands for little positive impact, `++' for moderate positive impact and `+++' for important positive impact.
200 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
Relevance of Case Study Research Method
Acase study is a research strategy that empirically exam-
ines a concrete example in its actual environment. It can
involve a combination of qualitative and quantitative
analyses, whereby the specific procedure depends on the
characteristics of each case study (Rejc, 2005).
Case study research excels at bringing to us an under-
standing of a complex issue or object and can extend
experience or add strength to what is already known
through previous research. Case studies emphasize
detailed contextual analysis of a limited number of
events or conditions and their relationships.
Researcher Robert K. Yin defines the case study
research method as an empirical inquiry that inves-
tigates a contemporary phenomenon within its real-
life context; when the boundaries between phenom-
enon and context are not clearly evident and in which
multiple sources of evidence are used (Yin, 2009; 2011).
Critics of the case study method believe that the study
of a small number and the uniqueness of studied
cases can offer no grounds for establishing reliability
or generality of findings. Others feel that the intense
exposure to study of the case biases the findings. Some
dismiss case study research as useful only as an explor-
atory tool. Yet, researchers craft studies of real-life situ-
ations, issues and problems.
In this research, the uniqueness of the case study
research method will be reinforced by an analytic gener-
alization of the key findings in the context of Moroccan
project-based companies as well as in companies dedi-
cating a department for project governance.
Generalization Method
Eisenhardt (1989) and Eisenhardt and Graebner
(2007) argue that binding the emergent theory
with the existing literature strengthens the internal
validity, generalization (external validity) and the
level of theory building from case study research.
Internal validity demonstrates a causal relationship,
in which certain conditions lead to other conditions;
and external validity tests whether a study's find-
ings could be generalized beyond the immediate case
study (Yin, 2009; 2011).
There are two kinds of generalization from case to theo-
ry: statistical generalization and analytic generalization
(Yin, 2009; 2011). In statistics, generalization is
established by an inference made about a population on
the basis of empirical data collected about a sample (Yin,
2009; 2011). However, statistical generalization should
not be considered to be the method of generalizing the
results of the case study (Yin, 2009; 2011).
Analytic generalization, established by the process
as an existing theory, is employed as a framework
with which to collate the empirical results of the case
study; then, when more cases appear to support the
same theory, replication can be claimed (Mccutcheon
& Meredith, 1993). Analytic generalization can be
used in either single case or multiple case studies (Yin,
2009; 2011).
This study employs analytic generalization in a single
case study design. A single case study (i.e., MEC) is
used for advocating or refining existing theories. Then,
the theory established from the case study could extend
to other ECs.
Statistical Generalization
While quantitative methods are used in scope, design,
and populate sequences to strengthen the findings of
MEC case study with a sample of 15 project manag-
ers-experts working in MEC and having capitalized
an average of 15 years' experience within 12 different
activities, their main use is in validation sequence.
In this sequence, a sample of 13 experts working in
12 different MECs --members of the Federation of
Moroccan Engineering and Consulting Companies
(FMCI)--were contacted and interviewed.
Analytic Generalization
Table 6 summaries the analytic generalization of MEC's
findings to large and small ECs in Morocco.
Scope of IP3M
MES is chosen for its relevance to the economy and
because it represents the majority of Moroccan PBOs.
Case study research method is followed to develop a
suitable MM for the MES. The organization used in the
case study is a large-sized company operating in the
MES called MEC for confidentiality consideration. Data
used in this case is collected from:
·

available public information in company's offi-
cial websites;
VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 201
·

published activity reports of the company and
the holding;
· notes of information, presentations, publications,
and published statistics of FMCI; and
· 
national conferences, studies, and workshops
held on engineering sector strategic development.
MEC Case Study
The Moroccan multi-disciplinary EC (called MEC for
confidentiality reasons) operates across four different
business units: construction, water and urban plan-
ning, large infrastructure and development. It is the
nationally recognized leader in the marketplace. The
company has a commitment to service, quality, and
Table 6: Analytic Generalization of MEC's Findings for MES
Case Study
Main Points
MEC
Large Engineering
Companies
Small Engineering
Companies
Stakeholders Sovereign fund
Large national and international
companies
Private
Size More than 600 More than 50 Less than 50
Human resource qualification
More than two engineers per three
technicians
+ +
Activities Multi-disciplinary + Specialized
Strategic Management
Location Between Rabat and Casablanca + +
Mission Investment optimization + +
Vision
General studies, project management
activities and training
+ +
Objectives
Regional leadership, exportation and
strategic alignment with holding
+ A reasonable market share
Strategies
Diversification, development of new
high value-added services, alliance, etc.
+ +
Political factors + + +
Environmental factors + + +
Social factors + + +
Technical factors + + +
Critical success factors
Knowledge, cash flow, cost reduction
and modernization
+ +
Business Design
Organization + + +
Culture + + ­
Knowledge issues + + +
Information system + + ­
Quality management system + + ­
Value Chain
Commercial process + + +
Support process + + +
Project management process + + ­
Management process + + ­
Source: Adapted from Alami, Beidouri, and Bouksour (2013c).
Notes: + is used for similarity and ­ for difference.
202 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
Table 7: The Intelligent Project-based Organization Maturity Model (IPBOMM)
Level 4
(competitive leverage)
Optimization and Adaptability
Level 3 (intelligence
utilization)
Decision-making and
problem-solving
Decision-making and problem-solving Project
teams competency
development
Generalization to all projects
(100%)
Generalization to all projects 
(100%) 
Application to most relevant
projects
Application to most relevant
projects
Project managers'
competency
development (100%) 
Level 2 (intelligence
awareness)
Generalization to all
projects
Application to most relevant
projects
Application to most relevant
projects Support staff
competency
development (100%) 
BI processes (100%)  CI processes (100%) 
Level 1 (intelligence
asset identification)
Application to most
relevant projects
(60%)
Data governance (100%) Environmental mapping
(100%) 
Project intelligence
centre
Knowledge
management (KM)
processes (100%)
Level 0 (unawareness)
No data governance
Competitors' information is not (or rarely) considered
Data are dispersed within multitude data sources
Required quality of information is not documented
No (or individual) project knowledge capitalization initiatives
Levels KM BI CI Governance
Source: Alami, Beidouri, and Bouksour (2013b).
high standards of safety and business ethics (sustain-
able development chart). MEC is a national sovereign
fund subsidiary that has a good standing with regards
to project owners.
MEC carried out more than 3,000 projects in Morocco
and abroad. It follows a matrix management structure
with a Board of Directors, and consists of a branch, five
divisions, 11 technical departments and four supply
departments. It employs 600 people including 202
engineers, 227 technicians and 103 administrative exec-
utives. It secures staff loyalty by promoting responsi-
bility and teamwork while fostering innovation and
improving technical skills.
IP3M Design
The intelligent PBOMM (IPBOMM), already developed
by Alami, Beidouri and Bouksour (2013b) (see Table 7),
is introduced to a sample of 15 project managers--
experts working in MEC and having capitalized an
average of 15 years' experience within 12 different
activities: building, urban planning, energy, agriculture,
PM services and environment and software develop-
ment. In order to develop an initial version of MM that
considers the challenges faced through several projects
they managed, experts were asked to propose an adap-
tation of IPBOMM to include PM maturity dimensions.
They were also asked to review IPBOMM components
and transition conditions. Actually, this first task was
somewhat easy, as IPBOMM is a staged model tailored
for a sector in which companies and different contribu-
tors are accustomed to PM terminology.
This first step resulted in the following five levels of
IP3M (see Table 8).
· Level 0 (unawareness). The organization is not aware
of the crucial role of high quality information and
accordingly intelligence initiatives are either indi-
vidual or non-existent. No PM process is defined
and documented; however, there may be isolated
initiatives to establish particular processes like
project initiation and closure processes.
VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 203
Table 8: IP3M Initially Proposed by Experts
Level 4
(competitive
leverage)
Optimization and Adaptability
Level 3
(intelligence
utilization)
PM processes of all
projects (100%) are
controlled
Decision-making and
problem-solving
Decision-making and problem-solving
Project teams competency
development
Generalization to all
projects (100%)
Generalization to all
projects (100%)
Application to most
relevant projects
Application to most
relevant projects
Project managers
competency development 
(100%)
Level 2
(intelligence
awareness)
PM processes of most
relevant projects (60%)
are controlled Generalization to all
projects
Application to most
relevant projects
Application to most
relevant projects
Support staff competency
development (100%)
PM processes are
standardized (100%)
BI processes (100%) CI processes (100%)
Level 1
(intelligence
asset identifica-
tion)
Application of PM
processes to most relevant
projects (60%)
Application to most
relevant projects
(60%) Data governance
(100%)
Environmental
mapping (100%)
Project intelligence centre
Defined PM processes
(100%)
KM processes
(100%)
Level 0
(unawareness)
No data governance
Competitors' information is not (or rarely) considered
Data are dispersed within multitude data sources
Required quality of information is not documented
No (or individual) project knowledge capitalization initiatives
No (or ad hoc) PM processes
Levels PM KM BI CI Governance
Source: Authors' compilation.
· Level 1 (project intelligence asset identification).
Intelligence awareness journey begins with capi-
talization of the maximum of project knowledge
through the establishment of adequate processes.
Internal and external data sources are identified and
PM processes are defined and applied to the most
relevant project with regard to an adequate indi-
cator chosen by the organization (e.g., turnover). A
project intelligence centre should manage the matu-
rity journey and begin by a suitable competencies
development policy. (In some PBOs, this task can be
handled by a PM office.)
· Level 2 (project intelligence awareness). Intelligence
process and systems are finalized and knowledge
management (KM) and PM processes are extended
to cover the entire project portfolio. Simultaneously,
the project processes controlling activities are started
by the most relevant projects. Besides, support staff
is ready to utilize BI and CI processes in a significant
portion of the projects.
· Level 3 (project intelligence utilization). Project
managers and project teams are empowered by
intelligent decision supportive tools and well-
established PM processes. Accordingly, they start
to base their decisions on high quality internal
and external information as they have already
developed the necessary know-how.
· Level 4(competitive leverage). More familiar with the
use of intelligence, project manager, project teams
and support staff begin to search for ways to sustain
a real competitive advantage through an agile
optimization and adaptation effort with regard to
competitors, stakeholders, and economic framework.
204 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
IP3M Populate Phase
The IP3M in Table 8 proposes some key process areas
(KPAs),namelyPMprocesses,KMprocesses,competitive
intelligence (CI) processes, business intelligence (BI)
processes,governancepolicyandestablishmentofproject
intelligence centre with their related Key Performance
Indicators (KPI) and the required percentage of
completion. Some KPAs are deliberately omitted
(decision-making, problem-solving, optimization and
adaptability) to ensure necessary flexibility to succeed in
the implementation and adaptation of the model. It is
up to the project intelligence centre to define the exact
meaning of 100 per cent of completion of each KPA.
Also, it is up to the top management, through the project
intelligence centre, to adopt the suitable set of processes
that fits at best with organization culture and ambitions.
Furthermore, this model is supposed to be easy to use,
scalable and can use processes defined in an already
existing Intelligent MM or PMMM.
The transition from one level to another is conditioned
by the completion of related KPAs.
Finally, the assessment of percentage of completion of
every KPA will result in maturity-level assessment.
IP3M Test
In order to test the applicability, validity and relia-
bility of the proposed model, 12 double-round inter-
views were conducted by authors with a sample of 13
experts working in 12 different ECs in Morocco with
almost the same characteristics in terms of experience
and activities. This approach is the most suitable test
method in the case of MECs as the latter are neither
familiar with MM terminology nor with intelligent
system use.
Firstly, experts were asked to comment on the
IP3M presented in Table 8. Then, they had to debate
and comment on the proposed MM in terms of its
components, transition conditions and the relevance
of governance in developing soft skills competencies.
They agreed upon the four essential needs of PBOs
operating in engineering sector: project knowledge
management, internal and external high quality infor-
mation and, finally, effective project governance.
The final version of IP3M had considered experts'
remarks and recommendations (see Table 9).
FINDINGS
Main Remarks and Recommendations
Experts agreed upon the relevance of such model in
assessing agility of ECs. However, they recommended
a gradual application of KM, BI, and CI processes
to projects, starting with the most relevant projects
before generalizing to the rest of the projects. They
also proposed `forecasted turnover' and projects
strategic ranking as criteria for selecting the most
relevant projects. Besides that, they agreed on the
importance of feedback to ensure partial continuous
improvement especially in establishing and general-
izing PM and KM processes. With regard to transi-
tion conditions, experts recognized the importance
of fulfilment of different KPAs before moving to the
upper level. With regard to governance maturity, they
recommended the completion of the establishment of
project intelligence centre before moving to project
intelligence asset identification level. Finally, they
recommended adding the following points to IP3M
levels description:
· Level 1 (project intelligence asset identification):
° 
Process definitions overlap with partial applica-
tion to take account of feedback.
° PM intelligence centre is established.
· Level 2 (project intelligence awareness):
° 
Process standardization overlap with partial
control to take account of feedback.
° 
Support staff competency development (basic
and necessary competencies).
· Level 3 (project intelligence utilization):
° 
Process control is put in place and applied to
relevant project.
° 
Project managers' competency develop-
ment is fully completed (basic and necessary
competencies).
° 
Project teams' competency development (basic
and necessary competencies).
° 
Use of project knowledge and information in
making informed and intelligent decision.
VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 205
° 
Project managers start using balanced PDAP in
relevant decisions with regards to a given criteria.
· Level 4 (competitive leverage):
° 
Balanced PADP is generalized to almost rele-
vant projects.
° 
Process control and generalization concepts are
reframed and revisited based on lessons learned
from project decisions.
Limitations of IP3M
The first and common limitation to all kinds of MMs
is that they are often viewed as inflexible because of
the disciplinary steps they embrace for improvement.
They are feared to add to an organization's
bureaucratic red tape, making it difficult for an
organization to find creative solutions to technical
problems (Herbsleb, Zubrow, Goldenson, Hayes, &
Paulk, 1997).
Table 9: Intelligent Project-based Organization Maturity Model
Level 4
(competitive
leverage)
Optimization and Adaptability (definition, generalization and control)
Project
Intelligence
Use
PDAP is applied to all project decisions
Level 3 (project
intelligence
utilization)
Decision-making and problem-solving (PDAP applied to most relevant decisions 20%)
PM processes of all
projects (100%) are
controlled
KM processes
of all projects
(100%) are
controlled
BI processes of all projects (100%) are
controlled

CI processes of all projects
(100%) are controlled
Project teams'
competency
development
(100%)
Project
managers'
competency
development
(100%)
Level 2 (project
intelligence
awareness)
PM processes of most
relevant projects (60%)
are controlled
KM processes
of most relevant
projects (60%)
are controlled
BI processes of most relevant projects
(60%) are controlled
CI processes of most
relevant projects (60%)
are controlled
PM processes are
standardized (100%)
KM processes
generalization
to all projects
(100%)
BI processes applied to most relevant
projects (60%)
CI processes generalized
to all projects (100%)
Support staff
competency
development 
(100%)
BI processes defined 
(100%)
Data governance processes generalized
to allprojects (100%)
Level 1 (project
intelligence
asset
identification)
Defined
PM
processes
(100%)
Application
of PM
processes
to most
relevant
projects
(60%)
KM processes
defined
(100%)
Application
of KM
processes
to most
relevant
projects
(60%)
Data
governance
processes
defined
(100%)
Data
governance
processes
applied
to most
relevant
projects
(60%)
CI
processes
 defined
(100%)
CI processes
applied to
most relevant
projects (60%)
Project
management
intelligence
centre
Environmental mapping
(100%)
Level 0
(unawareness)
No data governance
Competitors' information is not (or rarely) considered
Data are dispersed within multitude data sources
Required quality of information is not documented
No (or individual) project knowledge capitalization initiatives
No (or ad hoc) PM processes
Levels PM KM BI CI Governance
Source: Authors' compilation.
206 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
REFERENCES
Alami, M. O., Beidouri, Z., & Bouksour, O. (2013a). Towards
an intelligent project based model (IPBOM). International
Journal of Computer Science Issues, 10(1), 44­50.
Alami, M. O., Beidouri, Z., & Bouksour, O. (2013b). An
intelligent project based organization maturity model
(IPBOMM) for Moroccan engineering companies. Asian
Journal of Management Research, 3(2), 430­445.
Alami, M. O., Beidouri, Z., & Bouksour, O. (2013c).
Opportunity analysis of an intelligent project based
organization model (IPBOM) for Moroccan project based
organizations: Application to engineering sector. Asian
Journal of Management Research, 4(1), 176­196.
Barclay, C. (2008). Towards An integrated measurement of
information system project performance: The project
performance scorecard. Information Systems Frontiers,
10(May), 331­345.
Becker, J., Knackstedt, R., & Pöppelbuß, J. (2009). Developing
maturity models for IT management: A procedure model
and its application. Business and Information Systems
Engineering (BISE), 1(3), 213­222.
Benbasat, I., Dexter, A. S., Drury, D. H., & Goldstein, R. C.
(1984). A critque of the stage hypothesis: Theory and
empirical evidence. Communications of the ACM, 27(5),
476­485.
With regard to the test method, experts with an
average of 15 years' experience but representing
just about 9 per cent of the PM professionals were
interviewed, and that raised serious questions
about the deployment and professionals' adherence
to such organizational change (Alami, Beidouri, &
Bouksour, 2013b).
Furthermore, as the IP3M is in the deploying phase
in MEC and as Moroccan businesses are not that
familiar with the maturity terminology, reaping IP3M
benefits may take a long time. Meanwhile, because
the results take time to be witnessed and the models
can be expensive to implement, some organizations
might not perceive their benefits (Alami, Beidouri, &
Bouksour, 2013b).
Finally, the risk pointed out by Herbsleb, Zubrow,
Goldenson, Hayes, and Paulk (1997) stipulating that
`Some organizations by becoming "mature" fear that
they will also develop into risk adverse entities, afraid
to take risky endeavours (but potentially high pay-off)
because they may lose their high maturity rating' can
be a serious limitation of MM.
CONCLUSION
This article proposes and tests a prescriptive IP3M for
companies working in MES. Researchers first adapted a
balanced PDAP and then used it in designing method-
ically a hybrid MM--IP3M that balances between
rigidity and stability, ensured by staged models and
flexibility provided by system-based models.
In addition to a deep literature analysis, authors used
an agreed-upon MM development methodology with a
typical case study and multi-round experts' interview
to propose, test and validate the model. A Moroccan
large-sized EC has served for developing the IP3M
while experts' interviews methodology was adopted
for testing and validating findings.
The combination of case study research method and
experts' interview technique is supposed to reinforce
usefulness and applicability of the model in the case of
MES. However, a more general quantitative test ques-
tionnaire, targeting a large range of project managers
working in a large sample of MES, can be conducted
to investigate the perception of future users all the way
with the potential model deployment constraints.
Bresnen, M., Goussevskaia, A., & Swan, J. (2004). Embedding
new management knowledge in project-based organiza-
tions. Organization Studies, 25(9), 1535­1555.
Chee-Sok, T.,Yee-Wai, S., & William,Y. (2011).Amaturity model
of enterprise business intelligence. IBIMA (International
Business Information Management Association), 2011, Article
ID 417812, Communications of the IBIMA.
De Bruin, T., Rosemann, M., Freeze, R., & Kulkarni, U. (2005).
Understanding the main phases of developing a matu-
rity assessment model. Proceedings of the Australasian
Conference on Information Systems (ACIS), Sydney.
Eisenhardt, K. M. (1989). Building theories from case
study research. Academy of Management Review, 14(4),
532­550.
Eisenhardt, K. M., & Graebner, M. E. ( 2007). Theory building
from cases: Opportunities and challenges. Academy of
Management Journal, 50(1), 25­32.
FIDIC (International Federation of Consulting Engineers).
(2012). State of the World Report 2012: Sustainable
infrastructure. FIDIC. Retrieved 31 March, 2013 from
http://fidic.org/sites from http://fidic.org/sites/
default/files/sow2012-0822-electronic.pdf
FMCI (Moroccan Federation of Consulting and Engineering).
(2011). Annuaire des adhérents-Rabat (FMCI ed.).
VIKALPA · VOLUME 40 · ISSUE 2 · APRIL-JUNE 2015 207
McBride, T., Henderson-Sellers, B., & Zowghi, D. (2004).
Project management capability levels: An empir-
ical study. Proceedings of the 11th Asia-Pacific Software
Engineering Conference (APSEC'04), Busan, South Korea,
(30 November­03 December), 56­63.
McCartt, A. T., & Rohrbaugh, J. (1995). Managerial openness
to change and the introduction of GDSS: Explaining
initial success and failure in decision conferencing.
Organization Science, 6(5) 569­583.
McCormack, K., Willems, J., van den Bergh, J.,
Deschoolmeester, D., Willaert, P., Stemberger, M. I., et
al. 
(2009). A global investigation of key turning points in
business process maturity. Business Process Management
Journal, 15(5), 792­815.
Mccutcheon, D. M., & Meredith, J. R. (1993). Conducting
case study research in operations management. Journal
of Operations Management, 11(3), 239­256.
Mettler, T., & Rohner, P. (2009). Situational maturity models
as instrumental artifacts for organizational design.
Proceedings of DESRIST, New York.
Negash, S., & Gray, P. (2008). Business intelligence. In F.
Burstein & C. W. Holsapple (Eds), Handbook on deci-
sion support systems 2 (pp. 175­193). Berlin, Heidelberg:
Springer.
Niebecker, K., Eager, D., & Kubitza, K. (2008). Improving
cross-company management performance with a collab-
orative project scorecard. International Journal of Managing
Projects In Business, 1(3), 368­386.
OGC (Office of Government Commerce). (2009a). Managing
successful projects with PRINCE2TM, TSO. UK: The
Stationery Office.
OGC (Office of Government Commerce) (2009b). Directing
successful projects with PRINCE2TM, TSO. UK: The
Stationery Office.
Paulk, M. C., Curtis, B., Chris, M. B., & Weber, C. (1993).
Capability maturity model for software (Version 1.1)
(CMU/SEI Report Number: CMU/SEI-93-TR-24).
Software Engineering Institute. Retrieved 15 January,
2013 from http://resources.sei.cmu.edu/asset_files/
TechnicalReport/1993_005_001_16211.pdf
Project Management Institute (PMI). (2008a). Organizational
project management maturity model (OPM3) (2nd ed.).
Newtown Square, PA: Project Management Institute.
Project Management Institute (PMI). (2008b). A guide to the
project management body of knowledge: PMBOK Guide (4th
ed.). Newtown Square, PA: Project Management Institute.
Project Management Institute (PMI). (2013). A guide to the
project management body of knowledge: PMBOK Guide (5th
ed.). Newtown Square, PA: Project Management Institute.
Quinn, R. E., & Rohrbaugh, J. A. (1981). A competing
values approach to organizational effectiveness. Public
Productivity Review, 5(2), 122­144.
Fraser, P., Moultrie, J., & Gregory, M. (2002). The use of matu-
rity models/grids as a tool in assessing product devel-
opment capability. Proceedings of the IEEE International
Engineering Management Conference, Cambridge, UK,
244­249.
Gottschalk, P. (2009). Maturity levels for interoperability in
digital government. Government Information Quarterly,
26(1), 75­81.
Herbsleb, J., Zubrow, D., Goldenson, D., Hayes, W., &
Paulk, M. (1997). Software quality and the capability
maturity model. Association for Computing Machinery.
Communications of the ACM, 40(6), 30­40.
Hevner, A. R., March, S. T., Park, J., & Ram, S. (2004). Design
science in information systems research. MIS Quarterly,
28(1), 75­105.
Johnson, J. (2006). My life is failure. West Yarmouth, MA: The
Standish Group, International.
Kaplan, R. S., & Norton, D. P. (1992). The balanced score-
card: Measures that drive performance. Harvard Business
Review, 70(1), 71­79.
Kaplan, R. S., & Norton, D. P. (1996a). Using the balanced
scorecard as a strategic management system. Harvard
Business Review, 74(1), 75.
Kaplan, R. S., & Norton, D. P. (1996b). Balanced scorecard:
Translating strategy into action. Boston, MA: Harvard
Business School Press.
Keeney, R. L. (1982). Decision analysis: An overview.
Operations Research, 30(5), 803­838.
Kerzner, H. (2001). Strategic planning for project management
using a project management maturity model. New York:
John Wiley and Sons.
Kerzner, H. (2004). Project management best practices: Achieving
global excellence (1st ed.). Hoboken, NJ: John Wiley &
Sons.
Kerzner, H. (2005). Using the project management maturity
model: Strategic planning for project management (2nd ed.).
Hoboken, NJ: John Wiley & Sons.
Kerzner, H. (2006). A systems approach to planning, scheduling
and controlling (9th ed.). Hoboken, NJ: John Wiley & Sons,
Inc.
King, J. L., & Kraemer, K. L. (1984). Evolution and organiza-
tional information systems: An assessment of Nolan's
stage model. Communications of the ACM, 27(5), 466­475.
Lahrmann, G., & Marx, F. (2010). Systematization of matu-
rity model extensions. Proceedings of DESRIST 2010, St.
Gallen, Springer, 522­525.
Massey, C., Robinson, D., & Kaniel, R. (2006). Can't wait to
look in the mirror: The impact of experience on better-
than-average effect. Paper presented at INFORM Annual
Meeting, Pittsburgh, PA (November 5­8).
McAuliffe, T. P. (2005). The 90 % solution: A consistent approach
to optimal business decisions. LosAngles, CA:Authorhouse.
208 AN INTELLIGENT PROJECT MANAGEMENT MATURITY MODEL FOR MOROCCAN ENGINEERING COMPANIES
Quinn, J. B., & Rohrbaugh, J. (1983). A spatial model of effec-
tiveness criteria: Towards a competing values approach to
organizationalanalysis.ManagementScience,29(3),363­377.
Rajteri, I. H. (2010). Overview of business intelligence matu-
rity models. International Journal of Human Science, 15(1),
47­67.
Rayner, N., & Schlegel, K. (2008). Maturity model overview
for business intelligence and performance management.
Stamford: Gartner.
Rejc, B. (2005). A complete methodology for measuring of
investments in information technology (in Slovenian).
Applied Informatics (Uporabna Informatika), 13(4), 223­229.
Rohrbaugh, J. (2005). Assessing the effectiveness of group
decision processes. In S. Schuman (Ed.), The lAF hand-
book of group facilitation (pp. 449­455). San Francisco:
Jossey-Bass.
Rombout, S., & Wise, D. (2007). Failure to launch: Has poor
estimating compromised your project? Proceedings of the
2007 PMI College of Scheduling Conference (April l5­18),
Vancouver, BC.
Rowe, A. J., & Mason, R. O. (1987). Managing with style: A
guide to understanding, assessing, and improving decision
making. San Francisco, California: Jossey Bass.
Sacu, C., & Spruit, M. (2010). BIDM: The business intelligence
development model. Proceedings of the 12th International
Conference on Enterprise Information Systems, Funchal,
Madeira-Portugal.
Safi, A., & Burrell, D. (2007). Developing advanced deci-
sion-making skills in international leaders and managers.
Vikalpa: The Journal for Decision Makers, 32(3), 1­8.
Schilling, M., Oeser, N., & Schaub, C. (2007). How effective
are decision analyses? Assessing decision process and
group alignment effects. Decision Analysis, 4(4), 227­242.
Skinner, D. C. (2009). Introduction to decision analysis (3rd ed.),
Gainesville, Florida: Probabilistic Publishing.
Vakkayil D. J. (2010). Activity theory: A useful framework
for analysing project-based organizations. Vikalpa: The
Journal for Decision Makers, 35(3), 1­18.
Virine, L., & Trumper, M. (2008). Project decisions: The art and
science. Vienna: Management Concepts.
Viswanath, V., Susan, A. B., & Hillol, B. (2013). Bridging
the qualitative-quantitative divide: Guidelines for
conducting mixed methods research in information
systems. MIS Quaterly, 37(1), 21­54.
Williams, S., & Williams, N. (2007). The profit impact of business
intelligence. San Francisco, CA: Morgan Kaufmann.
Wilson, S. (1998). Failed IT projects (the human factor).
Retrieved 20 November, 2006 from http:/ I faculty.
ed.umuc.edu/ ~meinkej/inss690/wilson.htm
Yin, R. K. (2009). Case study research: Study and methods (4th
ed.). Thousand Oaks, CA: SAGE.
Yin, R.K. (2011). Qualitative research from start to finish. New
York: Guilford.
Oussama Marrouni Alami is the Head of project manage-
ment office in NOVEC--a leading large-sized Moroccan
engineering company. He has a PhD in Industrial
Engineering from University Hassan II and has Masters
in Industrial Engineering and Business Administration
(MBA), besides a project management professional (PMP)
certificate. He has taught in many engineering schools as a
temporary professor of project management, business intel-
ligence and global performance management. His research
interests are in the areas of decision-making, project
management, enterprise intelligence, and strategic manage-
ment. He is especially interested in designing maturity
models for intelligent systems implementation in the
context of developing countries. He has published in many
refereed academic journals like Asian Journal of Management
Research and International Journal of Computer Sciences Issues.
e-mail: oussama.alami@gmail.com
Otmane Bouksour is a Professor at Mechanical, CIM and
Industrial Engineering Laboratory (LMPGI), University
Hassan II Casablanca, High School of Technology,
Morocco.
e-mail: boukso@yahoo.com
Zitouni Beidouri is a Professor at Mechanical, CIM and
Industrial Engineering Laboratory (LMPGI), University
Hassan II Casablanca, High School of Technology,
Morocco.
e-mail: zbeidouri@gmail.com
