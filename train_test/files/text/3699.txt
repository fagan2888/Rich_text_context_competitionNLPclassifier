SAGE Open
April-June 2016: 1
­9
© The Author(s) 2016
DOI: 10.1177/2158244016650240
sgo.sagepub.com
Creative Commons CC-BY: This article is distributed under the terms of the Creative Commons Attribution 3.0 License
(http://www.creativecommons.org/licenses/by/3.0/) which permits any use, reproduction and distribution of
the work without further permission provided the original work is attributed as specified on the SAGE and Open Access pages
(https://us.sagepub.com/en-us/nam/open-access-at-sage).
Article
Introduction
Emotional intelligence (EI) is defined as the ability to per-
ceive, express, understand, motivate, control, and regulate
emotion (Goleman, 1995, 1998; Myers, 2005; Salovey &
Mayer, 1996). Previous studies have shown that EI is a deter-
minant of success in various occupational settings (Gazzard,
2002; Habibah etal., 2007). Research has also indicated that
EI predicts social relationships, family relationships, work
performance, academic performance, physical health, and
psychological well-being (Mayer, Roberts, & Barsade,
2008).
In the medical education context, studies have found that
high EI is positively associated with doctor­patient relation-
ships, interpersonal skills, communication skills, teamwork,
empathy, organizational commitment abilities, stress man-
agement, and examination performance on specific areas
such as clinical, diagnostic, and prognostic abilities (Arora
etal., 2010). In addition, results from a prospective study
indicated an association between preadmission EI and the
psychological health of medical students during first-year
medical training (Yusoff, Esa, MatPa, Mey, & Aziz, 2013).
Grewal and Davidson (2008) reported that the doctor's EI is
positively associated with the patient's trust, which in turn
results in a better doctor­patient relationship and treatment
compliance, as well as improved patient satisfaction with the
doctor and hospital. They also found a significant association
between the health care team's EI and the team's effective-
ness. In short, EI plays important roles that are closely related
to medical doctors' competency.
There are three theoretical approaches to EI: the specific-
ability approach, the integrative-model approach, and the
mixed-model approach (Mayer etal., 2008). The specific-
ability approach focuses on specific skills that are considered
fundamental to EI. Examples of inventories based on this
approach include the Diagnostic Analysis of Nonverbal
Accuracy 2, the Japanese and Caucasian Brief Affect
Recognition Test, and the Levels of Emotional Awareness
Scale. The integrative-model approach combines a number
of relevant abilities to obtain an overall sense of EI. Examples
650240
SGOXXX10.1177/2158244016650240SAGE OpenArifin andYusoff
research-article2016
1Universiti Sains Malaysia, Kubang Kerian, Kelantan, Malaysia
Corresponding Author:
Wan Nor Arifin, Unit of Biostatistics and Research Methodology, School
of Medical Sciences, Universiti Sains Malaysia, 16150 Kubang Kerian,
Kelantan, Malaysia.
Email: wnarifin@usm.my
Confirmatory Factor Analysis of the
Universiti Sains Malaysia Emotional
Quotient Inventory Among Medical
Students in Malaysia
Wan Nor Arifin1 and Muhamad Saiful Bahri Yusoff1
Abstract
The Universiti Sains Malaysia Emotional Quotient Inventory (USMEQ-i) is a Malay-language emotional intelligence (EI)
inventory that was based on a mixed-model approach of EI. It was specifically developed and validated for use among medical
course applicants. However, evidence to support its use among medical students is inadequate. This study aims to provide
further construct validity evidence for the USMEQ-i among medical students through confirmatory factor analysis (CFA).
A cross-sectional study was carried out on a sample of 479 medical students in Universiti Sains Malaysia (USM). After a
preliminary analysis, data from only 317 respondents were found suitable for inclusion in CFA. CFA was performed using the
maximum likelihood estimation method with bootstrapping due to the nonnormality of items at the multivariate level. The
results of the analysis support the two-factor model of the EI component and the one-factor model of the faking component.
However, the USMEQ-i should be administered with caution until further cross-validation studies are conducted among
students in other medical schools in Malaysia.
Keywords
confirmatory factor analysis, emotional intelligence, faking, medical students, mixed-model approach
2 SAGE Open
of inventories based on this approach include the Emotion
Knowledge Test, the Mayer­Salovey­Caruso Emotional
Intelligence Scale, and the Multibranch Emotional
Intelligence Scale. The mixed-model approach uses a broad
definition of EI, which includes noncognitive capability,
competency, or skill; emotionally and socially intelligent
conduct; and personality dispositions. The approach encom-
passes diverse psychological traits, abilities, styles, and other
characteristics of EI. The Emotional Quotient Inventory
(EQ-i), Self-Report Emotional Intelligence Test (SREIT),
and Multidimensional Emotional Intelligence Assessment
(MEIA) are examples of inventories based on this approach.
The Universiti Sains Malaysia Emotional Quotient
Inventory (USMEQ-i) is a Malay-language EI inventory that
was based on the mixed-model approach. It was developed
to measure EI among medical course applicants in Malaysia
(Yusoff, Rahim, & Esa, 2010). The USMEQ-i also under-
went a validation process by means of exploratory factor
analysis (EFA; Yusoff etal., 2011) and confirmatory factor
analysis (CFA; Arifin, Yusoff, & Naing, 2012). In a prelimi-
nary validation study among medical students, Yusoff (2012)
reported that the USMEQ-i has good test­retest and internal
consistency reliabilities. However, this evidence is still inad-
equate to support the construct validity of the USMEQ-i
among students. Stronger evidence of its validity can be pro-
vided by CFA.
CFA is superior to EFA and simple reliability analysis
(test­retest and internal consistency reliabilities) in many
respects. CFA is a type of structural equation modeling
(SEM) that is concerned with measurement models (Brown,
2006). It is advantageous to use CFA to verify the relation-
ships between items and their respective factors because it
allows the fixing of these relationships in the measurement
model and provides ways to assess the fit of the proposed
theoretical model to the collected data (Brown, 2006;
Stevens, 2009). Thus, CFA is considered an indispensable
tool for validation in social and behavioral sciences (Brown,
2006).
Given the advantage of CFA, this study aims to provide
further evidence for the construct validity of the USMEQ-i
among medical students through an evaluation of its mea-
surement model validity by CFA.
Method
Study Population
A cross-sectional study was carried out among medical stu-
dents of the School of Medical Sciences at the Universiti
Sains Malaysia (USM) from March to May 2011. In the
school, study years are divided into three phases: Phase I
(first and second years), Phase II (third and fourth years), and
Phase III (fifth year). The first-, third-, and fifth-year medical
students in 2011 were taken as a sampling frame because they
were considered representative of each phase. Second- and
fourth-year medical students were intentionally excluded
because those years have been found to be a stressful period
for students (Yusoff, Rahim, & Yaacob, 2010). Thus, data
from these students might not reflect a stable mental state
among the students.
Sample Size and Sampling Method
A total of 460 students were required for a CFA of 46 items
in the inventory, following Bentler and Chou's (1987) sug-
gestion for a minimum subjects-to-item ratio of 10:1. The
required sample size was inflated to 512 students to factor in
a 10% drop-out rate. Stratified random sampling was applied,
with the phases and students' gender as the stratification
variables (Table 1). These strata were chosen because the
stratum-specific proportions varied between student intakes
over the years.
Measurement Tool
A preliminary version of the USMEQ-i was used in this
study. This version was construct validated by EFA (Yusoff
etal., 2011), as opposed to the final version of the USMEQ-i
that was construct validated by CFAin a study byArifin etal.
(2012). In view of the possibility that the remaining items as
validated among medical students might differ from the
remaining items as validated among medical course appli-
cants after CFA, the preliminary version with a larger pool of
items was deemed preferable in this validation study.
The inventory has two distinct components: the EI com-
ponent and the faking component. The EI component con-
sists of 39 items that are clustered under seven factors:
control, maturity, conscientiousness, awareness, commit-
ment, fortitude, and expression. Alternatively, based on the
confirmatory study, the items could be clustered under two
factors: personal competence and social competence (Arifin
et
al., 2012). The faking component is a unidimensional
component that is meant to measure the tendency of respon-
dents to overrate themselves (Yusoff, Rahim, & Esa, 2010).
Table 1. Strata Size and Required Sample Size.
Phase gender
Percentage of
all phases
Sample size
required per strata
Phase I
Male 13.2 67
Female 26.6 136
Phase II
Male 17.3 89
Female 25.4 130
Phase III
Male 7.2 37
Female 10.3 53
Total 100 512
Arifin and Yusoff 3
It consists of seven items that are clustered under the faking
index. Each item in the inventory was rated on a 5-point
Likert-type scale (0 = not like me, 1 = a bit like me, 2 = quite
like me, 3 = a lot like me, and 4 = totally like me). All the
items have factor loadings of more than 0.3, and the
Cronbach's alpha values for the factors range from .603 to
.899 (Yusoff etal., 2011).
An overview of the factors and items under the EI and
faking components is presented in Table 2. Detailed descrip-
tions of each factor and a list of items are included in the
online manual of the inventory (see the link provided in the
Authors' Note). The seven-factor model (EI-VII) and two-
factor model (EI-II) of the EI component and the one-factor
model (FI) of the faking component were evaluated for mea-
surement model validity.
Data Collection Procedures
USMEQ-i forms were administered to all first-, third-, and
fifth-year medical students in examination halls after they
completed all end-of-phase examinations. Informed consent
was obtained from the students prior to the collection of forms.
Data Management and Preliminary Analysis
Data management and preliminary analysis were done using
IBM SPSS Statistics version 20 and SPSS Amos version 19.
For the purpose of statistical analysis, the ordinal
responses of the USMEQ-i were treated as continuous data.
The use of maximum likelihood (ML) estimation for ordinal
data is reasonable if the number of ordinal categories exceeds
3 (Byrne, 2010; Rhemtulla, Brosseau-Liard, & Savalei,
2012).
The multivariate normality of the items was assessed at
the univariate, bivariate, and multivariate levels (Kline,
2011). The univariate normality of each item was assessed
visually by inspecting a histogram with normality curve,
box-and-whisker plot, and Q­Q plot, and statistically by the
Kolmogorov­Smirnov and Shapiro­Wilk tests of normality
and skewness and kurtosis to their standard error ratios (ratio
< 3 for normality). The bivariate normality was assessed
through an evaluation of the linearity and homoscedasticity
of residuals of bivariate correlations for a number of selected
pairs of items (Kline, 2011). The multivariate normality of
the items was assessed by component, visually by plotting
the chi-square versus the Mahalanobis distance plot
(Burdenski, 2000) and statistically by Mardia's normalized
estimate of multivariate kurtosis in the form of critical ratio
of kurtosis in Amos. Critical ratio of kurtosis < 5.0 indicates
multivariate normality (Bentler, 2006). Multivariate outliers
were identified through an evaluation of the Mahalanobis
distance and its respective p1 and p2 values in Amos.
A multivariate collinearity assessment allows the identifica-
tion of redundant items among a group of variables. Tolerance <
0.10 or variance inflation factor (VIF) > 10 indicates the multi-
variate collinearity of the affected item (Kline, 2011). These
values were obtained from a multiple linear regression analysis
in SPSS by assigning a dummy variable (ID was used) as the
dependent variable and the items as the independent variables.
CFA
CFA was performed in Amos to evaluate the measurement
model validity of the proposed EI-VII, EI-II, and FI models.
The validity was evaluated through an assessment of model
fit indices and other evidence of construct validity of the pro-
posed and revised measurement models. The marker indica-
tor approach was used to scale the factors to their respective
items, as the approach is preferred whenever bootstrapping is
used (Arbuckle, 2010). Items with the largest unit of discrim-
ination were chosen as marker indicators, and their factor
loadings were fixed to 1.0.
Table 2. Model Factors and Items.
Models Factors Number of items Items
Emotional
intelligence (EI-
VII)
I. Control 9 Q4, Q7, Q10, Q11, Q12, Q25, Q32, Q38, Q44
II. Maturity 8 Q14, Q23, Q30, Q33, Q34, Q37, Q42, Q43
III. Conscientiousness 5 Q5, Q9, Q17, Q20, Q26
IV. Awareness 5 Q22, Q28, Q29, Q40, Q41
V. Commitment 4 Q15, Q16, Q36, Q45
VI. Fortitude 4 Q1, Q3, Q31, Q46
VII. Expression 4 Q2, Q8, Q19, Q35
Emotional
intelligence (EI-II)
I. Personal competence 34 Q1, Q2, Q3, Q4, Q5, Q7, Q8, Q9, Q10, Q11, Q12, Q14,
Q15, Q16, Q17, Q19, Q20, Q23, Q25, Q26, Q30, Q31,
Q32, Q33, Q34, Q35, Q36, Q37, Q38, Q42, Q43, Q44,
Q45, Q46
II. Social competence 5 Q22, Q28, Q29, Q40, Q41
Faking (FI) I. Faking index 7 FQ6, FQ13, FQ18, FQ21, FQ24, FQ27, FQ39
Note. EI-VII = seven-factor model of emotional intelligence component; EI-II = two-factor model of emotional intelligence component; Q = question
number; FQ = faking question number.
4 SAGE Open
Following Brown's (2006) recommendation, the follow-
ing categories of fit indices were considered in this study:
absolute fit (chi-square goodness-of-fit [2], standardized
root mean square residual [SRMR]), parsimony-corrected fit
(root mean square error of approximation [RMSEA]), and
comparative fit (Tucker­Lewis fit index [TLI], comparative
fit index [CFI]). The following cutoff values were used to
indicate model fit: 2 p> .05, TLI and CFI  0.95 (Brown,
2006; Schreiber, Nora, Stage, Barlow, & King, 2006),
RMSEAand its upper 90% confidence limit  0.08, RMSEA's
close fit p > .05, and SRMR  0.08 (Brown, 2006).
For model-to-model comparison of nonnested models, the
Akaike information criterion (AIC) and expected cross-
validation index (ECVI) were used. Models with the lowest
AIC and ECVI values were judged to fit the data better in
comparison with other tested models (Brown, 2006;
Schreiber etal., 2006).
Further assessment of construct validity involved an
assessment of the main components of construct validity,
namely, convergent validity and discriminant validity.
Convergent validity was evaluated through an assessment of
item factor loadings and their statistical significance, fol-
lowed by an assessment of the factors' average variance
extracted (AVE) and construct reliabilities (CRs). Convergent
validity was indicated by an item factor loading  0.5 and
p < .05 (Hair, Black, Babin, &Anderson, 2009), AVE  0.5,
and CR  0.7 (Fornell & Larcker, 1981). AVE and CR values
were calculated according to the following equations given
by Fornell and Larcker (1981):
CR 1
2
1
2
1
=
























=
= =

 


i
i
n
i
i
n
i
i
n
+ e
,
AVE
2
1
2
1 1
=
+
=
= =

 


i
i
n
i
i
n
i
i
n
e
,
where 
i
is the factor loading for item i under a particular
construct, and e
i
is the error variance for the item.
Raykov (1997, 1998) described a procedure to obtain bet-
ter estimates of the CR values and confidence intervals in the
context of SEM, as demonstrated by Fan (2003) in the Amos
software environment. The procedure was performed as
follows:
1. A latent reliability variable (RV) was created for each
factor.
2. Directional paths were added from the items to the
respective RVs.
3. The regression weights for these additional paths
were all set to 1.
4. The square of the correlation coefficient between a
particular factor and its RV is the composite reliabil-
ity coefficient for that factor.
Next, discriminant validity was evaluated by comparing
factor AVE values with shared variances (SVs) between the
factors, which are the squared correlations between any two
factors. The factors were considered discriminant when the
AVE values were greater than the SV values (Fornell &
Larcker, 1981).
Model revisions were done based on assessments of fac-
tor loadings, standardized residuals (SRs), and modification
indices (MIs), while maintaining the congenericity of the
measurement model within the theoretical framework. Items
with factor loadings < 0.5 were considered for removal (Hair
et
al., 2009). The researchers also considered items with
loadings that had bootstrapped lower 95% confidence inter-
vals below this cutoff value for removal. Items with SR >
2.58 were considered problematic items, which were further
evaluated before removal (Brown, 2006). In this study, MI
values were only used to identify potential cross-loading
items (Hair etal., 2009) without setting any particular cutoff
values, as the decision based on SR values was given more
importance.
Ethical Approval
Ethical approval to conduct this study was obtained from the
USM Research Ethics Committee (Human). The USM
Research Ethics Committee required informed consent forms
and approved the collection of data only as required by the
analysis, as the USMEQ-i forms also included other personal
information.
Results
Preliminary Analysis
A total of 576 medical students from the first, third, and fifth
years gave their consent to participate in the study. A sample
of 479 students was then obtained from this list of students
through stratified random sampling. The sample size was
smaller than the target sample size, as the male strata of
Phases I and II were underrepresented due to the small par-
ticipation rate within the strata.
During the initial data screening process, 160 respondents
were dropped: one respondent for wrong entry, 38 respon-
dents for not responding to all items, 36 respondents for not
responding to more than five items consecutively (e.g., miss-
ing responses from Q1 to Q6), and 85 respondents for having
a predictable pattern of responses (e.g., repetitive responses
"343434 . . ." or "444444 . . ."). The researchers considered the
last two conditions as dishonest responses, hence justifying
Arifin and Yusoff 5
their removal from the sample. After the screening process,
319 respondents remained in the sample.
In this remaining sample (n = 319), there were 11 respon-
dents with one missing response, four respondents with two
missing responses, and one respondent with three missing
responses, for an overall rate of missing values of 0.15%.
The missingness mechanism was determined as missing at
random based on a significant Little's (1988) test, 2 (df) =
675.1 (534), p < .001.
The missing values were imputed with the prior knowl-
edge imputation method (Tabachnick & Fidell, 2007). The
missing responses for these 16 respondents were imputed
with a value of 2, which is the middle value on the Likert-
type scale, representing the "quite like me" option. The deci-
sion was made after a discussion with the inventory developer
(M. S. B. Yusoff, personal communication, October 15,
2012). The developer considered the middle value as accu-
rately representing the missing response. Other options of
imputation were not considered in this study given the negli-
gible percentage of missing values; most imputation meth-
ods will give similar results with a minimum bias in estimates
at this percentage of missingness regardless of the mecha-
nisms (Scheffer, 2002; Tabachnick & Fidell, 2007).
All items except Q11 were not normally distributed at the
univariate level. At the bivariate level, seven items from the
EI component were randomly selected to form 21 bivariate
correlations, all of which were not normally distributed.
Seven items from the faking component formed 21 bivariate
correlations. Similarly, all the correlations were not normally
distributed. At the multivariate level, items from both com-
ponents were not normally distributed (EI component: multi-
variate kurtosis = 527.4, critical ratio of kurtosis = 83.28;
faking component: multivariate kurtosis = 33.39, critical
ratio of kurtosis = 26.56). Upon close inspection of 30 multi-
variate outliers from both components, two more respon-
dents were excluded for having a predictable pattern of
responses, as described earlier. However, no improvement in
multivariate normality was noted after excluding these two
respondents. None of the items had multivariate collinearity
based on tolerance and VIF.
After this preliminary analysis, only 317 (66%) respon-
dents out of 479 from the initial sample were included in the
CFA. The demographic characteristics of the respondents
and dropped cases are presented in Table 3.
CFA
In Amos, the main estimation method used is ML, which is
dependent on the multivariate normality assumption. As the
items were not normally distributed at the multivariate level,
available options in Amos for non­multivariate normal data
are the unweighted least squares (ULS), asymptotically dis-
tribution free (ADF), and bootstrapped ML estimation meth-
ods (Blunch, 2008; Brown, 2006; Byrne, 2010). However,
ULS is not asymptotically efficient; thus, chi-square test and
other fit indices that rely on chi-square cannot be obtained.
On the contrary, ADF requires a very large sample size that
is quoted in thousands (Blunch, 2008; Brown, 2006; Byrne,
2010). Thus, the ML estimation method with bootstrapping
was used to obtain an accurate estimation of standard errors
(Byrne, 2010) as reflected in p values and confidence inter-
vals. Bootstrap samples were set at 250, as recommended by
Nevitt and Hancock (2001). The bias-corrected confidence
interval was set at the 95% confidence level. In addition, the
Bollen­Stine bootstrap p was used as an appropriate alterna-
tive to the 2 p whenever the bootstrapping method was used
(Bollen & Stine, 1992). A cutoff of p> .05 was considered
indicative of model fit.
EI component. EI-VII was specified as a reflective measure-
ment model that consisted of seven first-order latent factors,
39 items (Table 1), and 21 interfactor correlations. The anal-
ysis of EI-VII indicated that the solution was not admissible
due to a nonpositive definite covariance matrix. The model
was not revised in view of the study among applicants (Ari-
fin etal., 2012), in which EI-VII also faced a similar issue.
Next, EI-II was specified as a reflective measurement
model that consisted of two first-order latent factors, 39 items
(Table 1), and a correlation between social competence and
personal competence. EI-II had poor model fit as indicated by
all fit indices except SRMR. To obtain a good-fitting model,
EI-II was revised iteratively as described below.
Initially, six items (Q2, Q3, Q8, Q9, Q11, and Q31) with
factor loadings of less than 0.5 were removed from personal
competence. This was followed by the removal of an addi-
tional 13 items (Q1, Q4, Q5, Q10, Q16, Q17, Q19, Q25, Q35,
Q44, Q43, Q45, and Q46) with factor loadings of less than 0.6,
Table 3. Demographic Characteristics of Respondents and
Dropped Cases.
Variables
Respondents
(n = 317)
Dropped cases
(n = 162)
n (%) n (%)
Age (years) 21 (2)a 20 (2)a
Gender
Male 130 (41.0) 47 (29.0)
Female 187 (59.0) 115 (71.0)
Race
Malay 174 (54.9) 92 (56.8)
Chinese 108 (34.1) 53 (32.7)
Indian 27 (8.5) 16 (9.9)
Others 6 (1.9) 1 (0.6)
Missing 2 (0.6) 0 (0.0)
Phase
I 90 (28.4) 87 (53.7)
II 169 (53.3) 43 (26.5)
III 58 (18.3) 32 (19.8)
aMedian (interquartile range). Age was not normally distributed.
6 SAGE Open
except Q7 (factor loading = 0.596), which was retained
because the value was very close to 0.6. The researchers set a
higher cutoff value of 0.6 for personal competence, consider-
ing the large number of items (34) and the researchers' aim to
reduce the number of items under this factor. In addition, the
factor loadings of all the items had a lower 95% confidence
interval below 0.5, signifying the need to remove the items.As
for social competence, only Q29 was removed from the factor
at this stage due to low factor loading (0.398).
After these 20 items were removed, Q28 was noted to
cross-load on personal competence based on an MI value of
15.30. Judging from the item content, Q28 appeared to fit the
definition of personal competence; thus, it was relocated to
that factor, leaving social competence with only three items.
Next, Q14, Q12, and Q32 were removed because their
factor loadings had a lower 95% confidence interval of less
than 0.5. Q32 was also removed for its high SR (Q32, Q38 =
3.67). At this point, the model still did not have a satisfying
fit based on the fit indices (Bollen­Stine bootstrap p = .032,
SRMR = 0.048, RMSEA = 0.061, TLI = 0.935, CFI = 0.945,
AIC = 288.989, and ECVI = 0.915).
To improve the model further, Q28, Q36, and Q15, which
had relatively high SRs with Q22 (2.18, 2.29, and 2.25,
respectively), were considered for removal, although the SRs
were lower than the 2.58 cutoff point. Q22 itself was not con-
sidered for removal as it belonged to social competence,
which was left with only three items. The researchers tried to
keep three or more items per factor to maintain a reasonable
number of representative items. Q36 was removed, which
resulted in the best improvement to the model (Bollen­Stine
bootstrap p = .060, AIC = 253.173, and ECVI = 0.801) as
compared with the removal of the other two items. However,
TLI and CFI values were still not satisfactory (TLI = 0.939,
CFI = 0.949). Last, Q38 was removed because its factor
loading had a lower 95% confidence interval of less than 0.5.
Overall, 25 items were removed from both factors. The
resulting model was a two-factor model (revised; EI-IIr) con-
sisting of three items under social competence and 11 items
under personal competence (Figure 1). The model fit well, as
indicated by the fit indices, and showed model improvement
as indicated by the reduction in AIC and ECVI values. Fit
indices for EI-VII, EI-II, and EI-IIr are presented in Table 4.
The convergent validity of EI-IIr was indicated by high
factor loadings (Table 5), acceptable AVE values, and high
CR values (Table 6). The discriminant validity of the model
was also indicated by the AVE values, all of which exceeded
the respective SV values (Table 6).
Faking component.FI was specified as a unidimensional
reflective measurement model consisting of seven items
(Table 1). FI had poor model fit, as indicated by the RMSEA
and Bollen­Stine bootstrap. FI was revised to obtain a good-
fitting model, in which three items (FQ27, FQ24, and FQ39)
were removed due to relatively low factor loadings. This
revision resulted in a unidimensional model (FIr) consisting
of four items (Figure 2); the model fit well based on most of
the fit indices except RMSEA and showed a remarkable
reduction in AIC and ECVI values. Fit indices for both FI
and FIr are presented in Table 4. FIr had good convergent
validity, as indicated by the high factor loadings (Table 5),
acceptable AVE value, and high CR value (Table 6).
Discussion
EI Component
The proposed two-factor model of EI fit well after an extensive
revision wherein 25 out of 39 items (64%) were removed and
one item was relocated to another factor. The extent of the revi-
sion is comparable with the revision done in the confirmatory
study of a sample of medical course applicants, in which 26 out
of 39 items (67%) were removed (Arifin etal., 2012). In the
study by Arifin et
al. (2012), the extensive removal of items
could be attributed to the carrying over of several items with low
factor loadings from the EFAstage. The remaining items by fac-
tor in the current study are different from those retained in the
study among applicants (Arifin etal., 2012). This finding signi-
fies the use of different sets of items in the EI component of the
USMEQ-i for medical students and medical course applicants.
The two-factor model is consistent with Goleman's (1998)
emotional competence framework, which was based on the
mixed-model approach of EI. In the framework, emotional com-
petence is divided into personal competence and social compe-
tence. Essentially, personal competence deals with managing
oneself, whereas social competence deals with handling relation-
ships with others (Goleman, 1998). The validity of the model
also confirms the results from the confirmatory study of the
USMEQ-i among medical course applicants (Arifin etal., 2012).
The Emotional and Social Competency Inventory, which was
based on a similar approach to EI, also includes personal and
social factors (Boyatzis, 2007). In contrast, the model is not con-
sistent with models from other inventories that were based on a
similar approach, namely, the one-factor model of the EQ-i
(Petrides & Furnham, 2001), the one-factor model of the SREIT
(Petrides & Furnham, 2000), and the three-factor model of the
MEIA(Tett & Fox, 2006), all of which were validated by CFA.
Faking Component
The proposed unidimensional model of the faking compo-
nent fit well after the removal of three out of seven items
(43%). This could also be attributed to the carrying over of
items with relatively low factor loadings from the EFA stage
(Arifin etal., 2012).
The unidimensionality of the faking component in the cur-
rent study is comparable with that in the study among appli-
cants (Arifin etal., 2012). However, the studies differ in the
remaining items after CFA; this signifies the use of different
sets of items for students and applicants. Confirmatory valida-
tion studies of other inventories measuring the faking concept
Arifin and Yusoff 7
have also shown its unidimensionality.ACFAof the Marlowe­
Crowne Social Desirability Scale (MCSDS) indicated the uni-
dimensionality of the short forms of MCSDS (Fischer & Fick,
1993; Leite & Beretvas, 2005). Another inventory, the Paulhus
Deception Scales, was also found to be unidimensional
(Lanyon & Carle, 2007) after a minor revision.
Limitations and Future Research
In the current study, the USMEQ-i was validated among medi-
cal students in the USM Medical School. The inventory may
also be valid among medical students from other medical
schoolsinMalaysia,asthesettingsarealmostsimilar.However,
the USMEQ-i should be administered with caution until cross-
validation studies are conducted in other medical schools.
Because a large number of items were removed during the
model revisions, a revalidation study is needed on a new
sample of medical students. Hair etal. (2009) recommended
the collection of a new sample upon removal of more than
20% of the items. A low cutoff value of 0.3 for item factor
loading was set during the EFA stage of USMEQ-i validation
(Yusoff etal., 2011), which resulted in a number of poor
quality items in the preliminary version used in this study. In
view of the findings of the current study and those of Arifin
etal. (2012), setting a higher cutoff value of 0.5 would be
more practical (Hair etal., 2009) to ensure that only good
items are carried over to the CFA stage of validation.
The evidence of construct validity of the USMEQ-i in this
study was only provided by CFA. Matthews, Zeidner, and
Roberts (2007) pointed out that evidence of the convergent
Figure 1. Two-factor model of emotional intelligence component (revised).
Table 4. Fit Indices of EI and FI Measurement Models.
Models 2 (df), p
Bollen­Stine
bootstrap p SRMR RMSEA (90% CI), CFit p TLI CFI AIC ECVI
EI-VII Solution was not admissible
EI-II 2,105.353 (701), <.001 .004 0.074 0.080 [0.076, 0.084], <.001 0.722 0.737 2,263.353 7.163
EI-IIr 156.145 (76), <.001 .076 0.046 0.058 [0.045, 0.071], .155 0.948 0.957 214.145 0.678
FI 49.333 (14), <.001 .024 0.047 0.089 [0.063, 0.117], .008 0.905 0.937 77.333 0.245
FIr 7.043 (2), .030 .151 0.027 0.089 [0.024, 0.165], .133 0.952 0.984 23.043 0.073
Note. The revised models are highlighted in bold. EI = emotional intelligence; FI = one-factor model of faking component; SRMR = standardized root mean square residual;
RMSEA = root mean square error of approximation; CI = confidence interval; CFit = close fit; TLI = Tucker­Lewis fit index; CFI = comparative fit index; AIC = Akaike
information criterion; ECVI = expected cross-validation index; EI-VII = seven-factor model of emotional intelligence component; EI-II = two-factor model of emotional
intelligence component; EI-IIr = two-factor model of emotional intelligence component (revised); FIr = one-factor model of faking component (revised).
8 SAGE Open
validity of an EI inventory is commonly established in rela-
tion to other available EI inventories. However, there is no
other EI inventory in the Malay language, making it impos-
sible to provide evidence of convergent validity.
Acknowledgments
We are especially grateful to the School of Medical Sciences at
Universiti Sains Malaysia for the support to conduct this study, the
Department of Medical Education staff for their help in distributing
the forms to medical students, and the medical students for their
participation in this study.
Authors' Note
The manual for this inventory is available online (https://www.
researchgate.net/publication/200640433_The_USM_Emotional_
Quotient_Inventory_%28USMEQ-i%29_Manual).
Declaration of Conflicting Interests
The author(s) declared no potential conflicts of interest with respect
to the research, authorship, and/or publication of this article.
Funding
The author(s) disclosed receipt of the following financial support
for the research and/or authorship of this article: This study was
funded by Universiti Sains Malaysia (Short-Term Research Grant
304/PPSP/6139071).
References
Arbuckle, J. L. (2010). Amos 19 reference guide. Crawfordville,
FL: Amos Development Corporation.
Arifin, W. N., Yusoff, M. S. B., & Naing, N. N. (2012). Confirmatory
factor analysis (CFA) of USM Emotional Quotient Inventory
(USMEQ-i) among medical degree program applicants in
Universiti Sains Malaysia (USM). Education in Medicine Journal,
4(2), e26-e44.
Arora, S., Ashrafian, H., Davis, R., Athanasiou, T., Darzi, A., &
Sevdalis, N. (2010). Emotional intelligence in medicine: A sys-
tematic review through the context of the ACGME competen-
cies. Medical Education, 44, 749-764.
Bentler, P. M. (2006). EQS 6 structural equations program manual.
Encino, CA: Multivariate Software.
Bentler, P. M., & Chou, C. P. (1987). Practical issues in structural
modeling. Sociological Methods & Research, 16, 78-117.
Blunch, N. J. (2008). Introduction to structural equation modelling
using SPSS and Amos. London, England: SAGE.
Bollen, K. A., & Stine, R. A. (1992). Bootstrapping goodness-of-fit
measures in structural equation models. Sociological Methods
& Research, 21, 205-229.
Boyatzis, R. (2007). The creation of the Emotional and Social
Competency Inventory (ESCI). Boston, MA: Hay Group.
Brown, T. A. (2006). Confirmatory factor analysis for applied
research. New York, NY: Guilford Press.
Burdenski, T. (2000). Evaluating univariate, bivariate, and multi-
variate normality using graphical and statistical procedures.
Multiple Linear Regression Viewpoints, 26(2), 15-28.
Byrne, B. M. (2010). Structural equation modeling with Amos:
Basic concepts, applications, and programming (2nd ed.).
New York, NY: Taylor & Francis Group.
Table 6. CR and AVE of EI-IIr and FIr.
Models Factors
Number
of items CR CR(R) [95% CI] AVE
EI-IIra Social
competence
3 0.816 0.815 [0.776, 0.859] 0.600
Personal
competence
11 0.896 0.895 [0.869, 0.916] 0.441
FIr Faking index 4 0.767 0.757 [0.692, 0.805] 0.457
Note. CR = construct reliability; AVE = average variance extracted; EI-IIr = two-
factor model of emotional intelligence component (revised); FIr = one-factor model
of faking component (revised); CR(R) = construct reliability (Raykov's);
CI = confidence interval.
aShared variance between social competence and personal competence is 0.438.
Figure 2. One-factor model of faking component.
Note. FQ = faking question number.
Table 5. Factor Loadings and Correlation for EI-IIr and FIr.
Models Factors Items
Factor loadings
(95% CI) p
EI-IIra Social
competence
Q22 0.632 [0.487, 0.746] .006
Q40 0.844 [0.788, 0.911] .004
Q41 0.830 [0.763, 0.884] .007
Personal
competence
Q7 0.599 [0.512, 0.685] .004
Q15 0.643 [0.523, 0.720] .012
Q20 0.651 [0.564, 0.726] .005
Q23 0.685 [0.600, 0.770] .006
Q26 0.712 [0.640, 0.781] .004
Q28 0.600 [0.522, 0.697] .003
Q30 0.674 [0.557, 0.749] .010
Q33 0.707 [0.618, 0.778] .007
Q34 0.694 [0.611, 0.771] .006
Q37 0.658 [0.555, 0.745] .006
Q42 0.670 [0.546, 0.746] .008
FIr Faking
index
FQ6 0.816 [0.712, 0.895] .011
FQ13 0.688 [0.584, 0.797] .004
FQ18 0.635 [0.503, 0.736] .007
FQ21 0.534 [0.386, 0.663] .007
Note. EI-IIr = two-factor model of emotional intelligence component
(revised); FIr = one-factor model of faking component (revised); CI =
confidence interval.
aCorrelation between social competence and personal competence,
r = .662 (95% CI = [0.534, 0.794]), p = .004.
Arifin and Yusoff 9
Fan, X. (2003). Using commonly available software for boot-
strapping in both substantive and measurement analyses.
Educational and Psychological Measurement, 63, 24-50.
Fischer, D. G., & Fick, C. (1993). Measuring social desirability:
Short forms of the Marlowe-Crowne Social Desirability Scale.
Educational and Psychological Measurement, 53, 417-424.
Fornell, C., & Larcker, D. F. (1981). Evaluating structural equation
models with unobservable variables and measurement error.
Journal of Marketing Research, 18, 39-50.
Gazzard, A. (2002). Emotional intelligence, the witness, and educa-
tion. Education for Meaning and Social Justice, 15(4), 20-29.
Goleman, D. (1995). Emotional intelligence. New York, NY:
Bantam Books.
Goleman, D. (1998). Working with emotional intelligence. New
York, NY: Bantam Books.
Grewal, D., & Davidson, H. A. (2008). Emotional intelligence and
graduate medical education. Journal of the American Medical
Association, 300, 1200-1202.
Habibah, E., Rahil, M., Maria, C. A., Samsilah, R., Nooreen, N.,
& Omar, F. (2007). Emotional intelligence of at risk students
in Malaysian secondary children. The International Journal of
Learning, 14(8), 51-56.
Hair, J. F., Jr., Black, W. C., Babin, B. J., & Anderson, R. E. (2009).
Multivariate data analysis (7th ed.). Upper Saddle River, NJ:
Pearson Prentice Hall.
Kline, R. B. (2011). Principles and practice of structural equation
modeling (3rd ed.). New York, NY: Guilford Press.
Lanyon, R. I., & Carle, A. C. (2007). Internal and external validity of
scores on the Balanced Inventory of Desirable Responding and
the Paulhus Deception Scales. Educational and Psychological
Measurement, 67, 859-876.
Leite, W. L., & Beretvas, S. N. (2005). Validation of scores
on the Marlowe-Crowne Social Desirability Scale and the
Balanced Inventory of Desirable Responding. Educational and
Psychological Measurement, 65, 140-154.
Little, R. J. A. (1988). A test of missing completely at random for
multivariate data with missing values. Journal of the American
Statistical Association, 83, 1198-1202.
Matthews, G., Zeidner, M., & Roberts, R. D. (2007). Emotional
intelligence: Consensus, controversies, and questions. In G.
Matthews, M. Zeidner, & R. D. Roberts (Eds.), The science of
emotional intelligence: Knowns and unknowns (pp. 3-48). New
York, NY: Oxford University Press.
Mayer, J. D., Roberts, R. D., & Barsade, S. G. (2008). Human abili-
ties: Emotional intelligence. Annual Review of Psychology, 59,
507-536.
Myers, D. G. (2005). Exploring psychology (6th ed.). New York,
NY: Worth Publishers.
Nevitt, J., & Hancock, G. R. (2001). Performance of bootstrap-
ping approaches to model test statistics and parameter standard
error estimation in structural equation modeling. Structural
Equation Modeling, 8, 353-377.
Petrides, K., & Furnham, A. (2000). On the dimensional structure of
emotional intelligence. Personality and Individual Differences,
29(2), 313-320.
Petrides, K., & Furnham, A. (2001). Trait emotional intelligence:
Psychometric investigation with reference to established trait
taxonomies. European Journal of Personality, 15, 425-448.
Raykov, T. (1997). Estimation of composite reliability for con-
generic measures. Applied Psychological Measurement, 21,
173-184.
Raykov, T. (1998). A method for obtaining standard errors and con-
fidence intervals of composite reliability for congeneric items.
Applied Psychological Measurement, 21, 173-184.
Rhemtulla, M., Brosseau-Liard, P. É., & Savalei, V. (2012). When
can categorical variables be treated as continuous? A com-
parison of robust continuous and categorical SEM estimation
methods under suboptimal conditions. Psychological Methods,
17, 354-373.
Salovey, P., & Mayer, J. D. (1996). Emotional intelligence.
Imagination, Cognition and Personality, 9, 185-211.
Scheffer, J. (2002). Dealing with missing data. Research Letters in
the Information and Mathematical Sciences, 3, 153-160.
Schreiber, J. B., Nora, A., Stage, F. K., Barlow, E. A., & King,
J. (2006). Reporting structural equation modeling and con-
firmatory factor analysis results: A review. The Journal of
Educational Research, 99, 323-338.
Stevens, J. P. (2009). Applied multivariate statistics for the social
sciences (5th ed.). New York, NY: Taylor & Francis Group.
Tabachnick, B. G., & Fidell, L. S. (2007). Using multivariate statis-
tics (5th ed.) Boston, MA: Pearson Education.
Tett, R. P., & Fox, K. E. (2006). Confirmatory factor structure of
trait emotional intelligence in student and worker samples.
Personality and Individual Differences, 41, 1155-1168.
Yusoff, M. S. B. (2012). Stability of USMEQ-i in measuring emo-
tional intelligence in medical students. ASEAN Journal of
Psychiatry, 13(1), 1-6.
Yusoff, M. S. B., Esa, A. R., Mat Pa, M. N., Mey, S. C., & Aziz, R.
A. (2013). A longitudinal study of relationships between previ-
ous academic achievement, emotional intelligence and person-
ality traits with psychological health of medical students during
stressful periods. Education for Health, 26(1), 39-47.
Yusoff, M. S. B., Rahim, A. F. A., & Esa, A. R. (2010). The USM
Emotional Quotient Inventory (USMEQ-i) manual. Malaysia:
KKMED Publications.
Yusoff, M. S. B., Rahim, A. F. A., Mat Pa, M. N., Mey, S. C.,
Ja'afar, R., & Esa, A. R. (2011). The validity and reliability of
the USM Emotional Quotient Inventory (USMEQ-i): Its use to
measure Emotional Quotient (EQ) of future medical students.
International Medical Journal, 18, 293-299.
Yusoff, M. S. B., Rahim, A. F. A, & Yaacob, M. J. (2010).
Prevalence and sources of stress among Universiti Sains
Malaysia Medical Students. The Malaysian Journal of Medical
Sciences, 17(1), 30-37.
Author Biographies
Wan Nor Arifin is a faculty member of the Unit of Biostatistics
and Research Methodology at the School of Medical Sciences of
the Universiti Sains Malaysia. His current research focuses on
development and validation of questionnaires for use in clinical
context.
Muhamad Saiful Bahri Yusoff, PhD, is the Head of the Department
of Medical Education at the School of Medical Sciences of the
Universiti Sains Malaysia. His current research focuses on medical
education, student assessment, student well-being and psychometrics.
